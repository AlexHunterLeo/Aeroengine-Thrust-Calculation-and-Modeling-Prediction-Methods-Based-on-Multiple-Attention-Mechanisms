{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "import math\n",
    "import os\n",
    "import warnings\n",
    "from typing import Optional, Tuple, Union\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.nn import CrossEntropyLoss\n",
    "from torch.utils.checkpoint import checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_tf_weights_in_t5(model, tf_checkpoint_path):\n",
    "    \"\"\"Load tf checkpoints in a pytorch model.\"\"\"\n",
    "    try:\n",
    "        import re\n",
    "\n",
    "        import numpy as np\n",
    "        import tensorflow as tf\n",
    "    except ImportError:\n",
    "        logger.error(\n",
    "            \"Loading a TensorFlow model in PyTorch, requires TensorFlow to be installed. Please see \"\n",
    "            \"https://www.tensorflow.org/install/ for installation instructions.\"\n",
    "        )\n",
    "        raise\n",
    "    tf_path = os.path.abspath(tf_checkpoint_path)\n",
    "    logger.info(f\"Converting TensorFlow checkpoint from {tf_path}\")\n",
    "    # Load weights from TF model\n",
    "    init_vars = tf.train.list_variables(tf_path)\n",
    "    names = []\n",
    "    tf_weights = {}\n",
    "    for name, shape in init_vars:\n",
    "        logger.info(f\"Loading TF weight {name} with shape {shape}\")\n",
    "        array = tf.train.load_variable(tf_path, name)\n",
    "        names.append(name)\n",
    "        tf_weights[name] = array\n",
    "\n",
    "    for txt_name in names:\n",
    "        name = txt_name.split(\"/\")\n",
    "        # adam_v and adam_m are variables used in AdamWeightDecayOptimizer to calculated m and v\n",
    "        # which are not required for using pretrained model\n",
    "        if any(\n",
    "            n in [\"adam_v\", \"adam_m\", \"AdamWeightDecayOptimizer\", \"AdamWeightDecayOptimizer_1\", \"global_step\"]\n",
    "            for n in name\n",
    "        ):\n",
    "            logger.info(f\"Skipping {'/'.join(name)}\")\n",
    "            tf_weights.pop(txt_name, None)\n",
    "            continue\n",
    "        if \"_slot_\" in name[-1]:\n",
    "            logger.info(f\"Skipping {'/'.join(name)}\")\n",
    "            tf_weights.pop(txt_name, None)\n",
    "            continue\n",
    "        pointer = model\n",
    "        array = tf_weights[txt_name]\n",
    "\n",
    "        for m_name in name:\n",
    "            if re.fullmatch(r\"[A-Za-z]+_\\d+\", m_name):\n",
    "                scope_names = re.split(r\"_(\\d+)\", m_name)\n",
    "            else:\n",
    "                scope_names = [m_name]\n",
    "            if scope_names[0] in [\"kernel\", \"scale\", \"embedding\"]:\n",
    "                pointer = getattr(pointer, \"weight\")\n",
    "            elif scope_names[0] == \"self_attention\":\n",
    "                pointer = getattr(pointer, \"layer\")\n",
    "                pointer = pointer[0]\n",
    "            elif scope_names[0] == \"enc_dec_attention\":\n",
    "                pointer = getattr(pointer, \"layer\")\n",
    "                pointer = pointer[1]\n",
    "            elif scope_names[0] == \"dense_relu_dense\":\n",
    "                pointer = getattr(pointer, \"layer\")\n",
    "                pointer = pointer[2]\n",
    "            elif scope_names[0] == \"rms_norm\":\n",
    "                if hasattr(pointer, \"layer_norm\"):\n",
    "                    pointer = getattr(pointer, \"layer_norm\")\n",
    "                elif hasattr(pointer, \"final_layer_norm\"):\n",
    "                    pointer = getattr(pointer, \"final_layer_norm\")\n",
    "            elif scope_names[0] == \"scale\":\n",
    "                pointer = getattr(pointer, \"weight\")\n",
    "            elif scope_names[0] == \"output_bias\" or scope_names[0] == \"beta\":\n",
    "                pointer = getattr(pointer, \"bias\")\n",
    "            elif scope_names[0] == \"squad\":\n",
    "                pointer = getattr(pointer, \"classifier\")\n",
    "            elif scope_names[0] == \"decoder\" and name[1] == \"logits\":\n",
    "                continue\n",
    "            elif scope_names[0] == \"logits\":\n",
    "                pointer = getattr(pointer, \"lm_head\")\n",
    "            elif scope_names[0] == \"wi\" and len(scope_names) > 1 and scope_names[1].isdigit():\n",
    "                pointer = getattr(pointer, f\"wi_{scope_names[1]}\")\n",
    "                continue\n",
    "            else:\n",
    "                try:\n",
    "                    pointer = getattr(pointer, scope_names[0])\n",
    "                except AttributeError:\n",
    "                    logger.info(f\"Skipping {'/'.join(name)}\")\n",
    "                    continue\n",
    "            if len(scope_names) >= 2:\n",
    "                num = int(scope_names[1])\n",
    "                pointer = pointer[num]\n",
    "        if scope_names[0] not in [\"kernel\", \"scale\", \"embedding\"]:\n",
    "            pointer = getattr(pointer, \"weight\")\n",
    "        if scope_names[0] != \"embedding\":\n",
    "            logger.info(f\"Transposing numpy weight of shape {array.shape} for {name}\")\n",
    "            array = np.transpose(array)\n",
    "        try:\n",
    "            assert (\n",
    "                pointer.shape == array.shape\n",
    "            ), f\"Pointer shape {pointer.shape} and array shape {array.shape} mismatched\"\n",
    "        except AssertionError as e:\n",
    "            e.args += (pointer.shape, array.shape)\n",
    "            raise\n",
    "        logger.info(f\"Initialize PyTorch weight {name}\")\n",
    "        pointer.data = torch.from_numpy(array.astype(np.float32))\n",
    "        tf_weights.pop(txt_name, None)\n",
    "\n",
    "    logger.info(f\"Weights not copied to PyTorch model: {', '.join(tf_weights.keys())}.\")\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class T5LayerNorm(nn.Module):\n",
    "    def __init__(self, hidden_size, eps=1e-6):\n",
    "        \"\"\"\n",
    "        Construct a layernorm module in the T5 style. No bias and no subtraction of mean.\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.weight = nn.Parameter(torch.ones(hidden_size))\n",
    "        self.variance_epsilon = eps\n",
    "\n",
    "    def forward(self, hidden_states):\n",
    "        # T5 uses a layer_norm which only scales and doesn't shift, which is also known as Root Mean\n",
    "        # Square Layer Normalization https://arxiv.org/abs/1910.07467 thus varience is calculated\n",
    "        # w/o mean and there is no bias. Additionally we want to make sure that the accumulation for\n",
    "        # half-precision inputs is done in fp32\n",
    "\n",
    "        variance = hidden_states.to(torch.float32).pow(2).mean(-1, keepdim=True)\n",
    "        hidden_states = hidden_states * torch.rsqrt(variance + self.variance_epsilon)\n",
    "\n",
    "        # convert into half-precision if necessary\n",
    "        if self.weight.dtype in [torch.float16, torch.bfloat16]:\n",
    "            hidden_states = hidden_states.to(self.weight.dtype)\n",
    "\n",
    "        return self.weight * hidden_states\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class T5DenseActDense(nn.Module):\n",
    "    def __init__(self, d_model, d_ff, dropout_rate):\n",
    "        super().__init__()\n",
    "        self.wi = nn.Linear(d_model, d_ff, bias=False)\n",
    "        self.wo = nn.Linear(d_ff, d_model, bias=False)\n",
    "        self.dropout = nn.Dropout(dropout_rate)\n",
    "        self.act = nn.GELU()\n",
    "\n",
    "    def forward(self, hidden_states):\n",
    "        hidden_states = self.wi(hidden_states)\n",
    "        hidden_states = self.act(hidden_states)\n",
    "        hidden_states = self.dropout(hidden_states)\n",
    "        if (\n",
    "            isinstance(self.wo.weight, torch.Tensor)\n",
    "            and hidden_states.dtype != self.wo.weight.dtype\n",
    "            and self.wo.weight.dtype != torch.int8\n",
    "        ):\n",
    "            hidden_states = hidden_states.to(self.wo.weight.dtype)\n",
    "        hidden_states = self.wo(hidden_states)\n",
    "        return hidden_states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class T5DenseGatedActDense(nn.Module):\n",
    "    def __init__(self, d_model, d_ff, dropout_rate):\n",
    "        super().__init__()\n",
    "        self.wi_0 = nn.Linear(d_model, d_ff, bias=False)\n",
    "        self.wi_1 = nn.Linear(d_model, d_ff, bias=False)\n",
    "        self.wo = nn.Linear(d_ff, d_model, bias=False)\n",
    "        self.dropout = nn.Dropout(dropout_rate)\n",
    "        self.act = nn.GELU()\n",
    "\n",
    "    def forward(self, hidden_states):\n",
    "        hidden_gelu = self.act(self.wi_0(hidden_states))\n",
    "        hidden_linear = self.wi_1(hidden_states)\n",
    "        hidden_states = hidden_gelu * hidden_linear\n",
    "        hidden_states = self.dropout(hidden_states)\n",
    "\n",
    "        # To make 8bit quantization work for google/flan-t5-xxl, self.wo is kept in float32.\n",
    "        # See https://github.com/huggingface/transformers/issues/20287\n",
    "        # we also make sure the weights are not in `int8` in case users will force `_keep_in_fp32_modules` to be `None``\n",
    "        if (\n",
    "            isinstance(self.wo.weight, torch.Tensor)\n",
    "            and hidden_states.dtype != self.wo.weight.dtype\n",
    "            and self.wo.weight.dtype != torch.int8\n",
    "        ):\n",
    "            hidden_states = hidden_states.to(self.wo.weight.dtype)\n",
    "\n",
    "        hidden_states = self.wo(hidden_states)\n",
    "        return hidden_states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class T5LayerFF(nn.Module):\n",
    "    def __init__(self, d_model, d_ff, dropout_rate, layer_norm_epsilon=1e-6, \n",
    "                 is_gated_act=True):\n",
    "        super().__init__()\n",
    "        if is_gated_act:\n",
    "            self.DenseReluDense = T5DenseGatedActDense(d_model, d_ff, dropout_rate)\n",
    "        else:\n",
    "            self.DenseReluDense = T5DenseActDense(d_model, d_ff, dropout_rate)\n",
    "\n",
    "        self.layer_norm = T5LayerNorm(d_model, eps=layer_norm_epsilon)\n",
    "        self.dropout = nn.Dropout(dropout_rate)\n",
    "\n",
    "    def forward(self, hidden_states):\n",
    "        forwarded_states = self.layer_norm(hidden_states)\n",
    "        forwarded_states = self.DenseReluDense(forwarded_states)\n",
    "        hidden_states = hidden_states + self.dropout(forwarded_states)\n",
    "        return hidden_states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class T5Attention(nn.Module):\n",
    "    def __init__(self, d_model, num_heads, d_kv, dropout_rate, relative_attention_num_buckets, \n",
    "                 relative_attention_max_distance, is_decoder, has_relative_attention_bias=False):\n",
    "        super().__init__()\n",
    "        self.is_decoder = is_decoder\n",
    "        self.has_relative_attention_bias = has_relative_attention_bias\n",
    "        self.relative_attention_num_buckets = relative_attention_num_buckets\n",
    "        self.relative_attention_max_distance = relative_attention_max_distance\n",
    "        self.d_model = d_model\n",
    "        self.key_value_proj_dim = d_kv\n",
    "        self.n_heads = num_heads\n",
    "        self.dropout = dropout_rate\n",
    "        self.inner_dim = self.n_heads * self.key_value_proj_dim\n",
    "\n",
    "        # Mesh TensorFlow initialization to avoid scaling before softmax\n",
    "        self.q = nn.Linear(self.d_model, self.inner_dim, bias=False)\n",
    "        self.k = nn.Linear(self.d_model, self.inner_dim, bias=False)\n",
    "        self.v = nn.Linear(self.d_model, self.inner_dim, bias=False)\n",
    "        self.o = nn.Linear(self.inner_dim, self.d_model, bias=False)\n",
    "\n",
    "        if self.has_relative_attention_bias:\n",
    "            self.relative_attention_bias = nn.Embedding(self.relative_attention_num_buckets, self.n_heads)\n",
    "        self.pruned_heads = set()\n",
    "        self.gradient_checkpointing = False\n",
    "\n",
    "    def prune_heads(self, heads):\n",
    "        if len(heads) == 0:\n",
    "            return\n",
    "        heads, index = find_pruneable_heads_and_indices(\n",
    "            heads, self.n_heads, self.key_value_proj_dim, self.pruned_heads\n",
    "        )\n",
    "        # Prune linear layers\n",
    "        self.q = prune_linear_layer(self.q, index)\n",
    "        self.k = prune_linear_layer(self.k, index)\n",
    "        self.v = prune_linear_layer(self.v, index)\n",
    "        self.o = prune_linear_layer(self.o, index, dim=1)\n",
    "        # Update hyper params\n",
    "        self.n_heads = self.n_heads - len(heads)\n",
    "        self.inner_dim = self.key_value_proj_dim * self.n_heads\n",
    "        self.pruned_heads = self.pruned_heads.union(heads)\n",
    "\n",
    "    @staticmethod\n",
    "    def _relative_position_bucket(relative_position, bidirectional=True, num_buckets=32, max_distance=128):\n",
    "        \"\"\"\n",
    "        Adapted from Mesh Tensorflow:\n",
    "        https://github.com/tensorflow/mesh/blob/0cb87fe07da627bf0b7e60475d59f95ed6b5be3d/mesh_tensorflow/transformer/transformer_layers.py#L593\n",
    "        Translate relative position to a bucket number for relative attention. The relative position is defined as\n",
    "        memory_position - query_position, i.e. the distance in tokens from the attending position to the attended-to\n",
    "        position. If bidirectional=False, then positive relative positions are invalid. We use smaller buckets for\n",
    "        small absolute relative_position and larger buckets for larger absolute relative_positions. All relative\n",
    "        positions >=max_distance map to the same bucket. All relative positions <=-max_distance map to the same bucket.\n",
    "        This should allow for more graceful generalization to longer sequences than the model has been trained on\n",
    "        Args:\n",
    "            relative_position: an int32 Tensor\n",
    "            bidirectional: a boolean - whether the attention is bidirectional\n",
    "            num_buckets: an integer\n",
    "            max_distance: an integer\n",
    "        Returns:\n",
    "            a Tensor with the same shape as relative_position, containing int32 values in the range [0, num_buckets)\n",
    "        \"\"\"\n",
    "        relative_buckets = 0\n",
    "        if bidirectional:\n",
    "            num_buckets //= 2\n",
    "            relative_buckets += (relative_position > 0).to(torch.long) * num_buckets\n",
    "            relative_position = torch.abs(relative_position)\n",
    "        else:\n",
    "            relative_position = -torch.min(relative_position, torch.zeros_like(relative_position))\n",
    "        # now relative_position is in the range [0, inf)\n",
    "\n",
    "        # half of the buckets are for exact increments in positions\n",
    "        max_exact = num_buckets // 2\n",
    "        is_small = relative_position < max_exact\n",
    "\n",
    "        # The other half of the buckets are for logarithmically bigger bins in positions up to max_distance\n",
    "        relative_position_if_large = max_exact + (\n",
    "            torch.log(relative_position.float() / max_exact)\n",
    "            / math.log(max_distance / max_exact)\n",
    "            * (num_buckets - max_exact)\n",
    "        ).to(torch.long)\n",
    "        relative_position_if_large = torch.min(\n",
    "            relative_position_if_large, torch.full_like(relative_position_if_large, num_buckets - 1)\n",
    "        )\n",
    "\n",
    "        relative_buckets += torch.where(is_small, relative_position, relative_position_if_large)\n",
    "        return relative_buckets\n",
    "\n",
    "    def compute_bias(self, query_length, key_length, device=None):\n",
    "        \"\"\"Compute binned relative position bias\"\"\"\n",
    "        if device is None:\n",
    "            device = self.relative_attention_bias.weight.device\n",
    "        context_position = torch.arange(query_length, dtype=torch.long, device=device)[:, None]\n",
    "        memory_position = torch.arange(key_length, dtype=torch.long, device=device)[None, :]\n",
    "        relative_position = memory_position - context_position  # shape (query_length, key_length)\n",
    "        relative_position_bucket = self._relative_position_bucket(\n",
    "            relative_position,  # shape (query_length, key_length)\n",
    "            bidirectional=(not self.is_decoder),\n",
    "            num_buckets=self.relative_attention_num_buckets,\n",
    "            max_distance=self.relative_attention_max_distance,\n",
    "        )\n",
    "        values = self.relative_attention_bias(relative_position_bucket)  # shape (query_length, key_length, num_heads)\n",
    "        values = values.permute([2, 0, 1]).unsqueeze(0)  # shape (1, num_heads, query_length, key_length)\n",
    "        return values\n",
    "\n",
    "    def forward(\n",
    "        self,\n",
    "        hidden_states,\n",
    "        mask=None,\n",
    "        key_value_states=None,\n",
    "        position_bias=None,\n",
    "        past_key_value=None,\n",
    "        layer_head_mask=None,\n",
    "        query_length=None,\n",
    "        use_cache=False,\n",
    "        output_attentions=False,\n",
    "    ):\n",
    "        \"\"\"\n",
    "        Self-attention (if key_value_states is None) or attention over source sentence (provided by key_value_states).\n",
    "        \"\"\"\n",
    "        # Input is (batch_size, seq_length, dim)\n",
    "        # Mask is (batch_size, key_length) (non-causal) or (batch_size, key_length, key_length)\n",
    "        # past_key_value[0] is (batch_size, n_heads, q_len - 1, dim_per_head)\n",
    "        batch_size, seq_length = hidden_states.shape[:2]\n",
    "\n",
    "        real_seq_length = seq_length\n",
    "\n",
    "        if past_key_value is not None:\n",
    "            assert (\n",
    "                len(past_key_value) == 2\n",
    "            ), f\"past_key_value should have 2 past states: keys and values. Got { len(past_key_value)} past states\"\n",
    "            real_seq_length += past_key_value[0].shape[2] if query_length is None else query_length\n",
    "\n",
    "        key_length = real_seq_length if key_value_states is None else key_value_states.shape[1]\n",
    "\n",
    "        def shape(states):\n",
    "            \"\"\"projection\"\"\"\n",
    "            return states.view(batch_size, -1, self.n_heads, self.key_value_proj_dim).transpose(1, 2)\n",
    "\n",
    "        def unshape(states):\n",
    "            \"\"\"reshape\"\"\"\n",
    "            return states.transpose(1, 2).contiguous().view(batch_size, -1, self.inner_dim)\n",
    "\n",
    "        def project(hidden_states, proj_layer, key_value_states, past_key_value):\n",
    "            \"\"\"projects hidden states correctly to key/query states\"\"\"\n",
    "            if key_value_states is None:\n",
    "                # self-attn\n",
    "                # (batch_size, n_heads, seq_length, dim_per_head)\n",
    "                hidden_states = shape(proj_layer(hidden_states))\n",
    "            elif past_key_value is None:\n",
    "                # cross-attn\n",
    "                # (batch_size, n_heads, seq_length, dim_per_head)\n",
    "                hidden_states = shape(proj_layer(key_value_states))\n",
    "\n",
    "            if past_key_value is not None:\n",
    "                if key_value_states is None:\n",
    "                    # self-attn\n",
    "                    # (batch_size, n_heads, key_length, dim_per_head)\n",
    "                    hidden_states = torch.cat([past_key_value, hidden_states], dim=2)\n",
    "                elif past_key_value.shape[2] != key_value_states.shape[1]:\n",
    "                    # checking that the `sequence_length` of the `past_key_value` is the same as\n",
    "                    # the provided `key_value_states` to support prefix tuning\n",
    "                    # cross-attn\n",
    "                    # (batch_size, n_heads, seq_length, dim_per_head)\n",
    "                    hidden_states = shape(proj_layer(key_value_states))\n",
    "                else:\n",
    "                    # cross-attn\n",
    "                    hidden_states = past_key_value\n",
    "            return hidden_states\n",
    "\n",
    "        # get query states\n",
    "        query_states = shape(self.q(hidden_states))  # (batch_size, n_heads, seq_length, dim_per_head)\n",
    "\n",
    "        # get key/value states\n",
    "        key_states = project(\n",
    "            hidden_states, self.k, key_value_states, past_key_value[0] if past_key_value is not None else None\n",
    "        )\n",
    "        value_states = project(\n",
    "            hidden_states, self.v, key_value_states, past_key_value[1] if past_key_value is not None else None\n",
    "        )\n",
    "\n",
    "        # compute scores\n",
    "        scores = torch.matmul(\n",
    "            query_states, key_states.transpose(3, 2)\n",
    "        )  # equivalent of torch.einsum(\"bnqd,bnkd->bnqk\", query_states, key_states), compatible with onnx op>9\n",
    "\n",
    "        if position_bias is None:\n",
    "            if not self.has_relative_attention_bias:\n",
    "                position_bias = torch.zeros(\n",
    "                    (1, self.n_heads, real_seq_length, key_length), device=scores.device, dtype=scores.dtype\n",
    "                )\n",
    "                if self.gradient_checkpointing and self.training:\n",
    "                    position_bias.requires_grad = True\n",
    "            else:\n",
    "                position_bias = self.compute_bias(real_seq_length, key_length, device=scores.device)\n",
    "\n",
    "            # if key and values are already calculated\n",
    "            # we want only the last query position bias\n",
    "            if past_key_value is not None:\n",
    "                position_bias = position_bias[:, :, -hidden_states.size(1) :, :]\n",
    "\n",
    "            if mask is not None:\n",
    "                position_bias = position_bias + mask  # (batch_size, n_heads, seq_length, key_length)\n",
    "\n",
    "        if self.pruned_heads:\n",
    "            mask = torch.ones(position_bias.shape[1])\n",
    "            mask[list(self.pruned_heads)] = 0\n",
    "            position_bias_masked = position_bias[:, mask.bool()]\n",
    "        else:\n",
    "            position_bias_masked = position_bias\n",
    "\n",
    "        scores += position_bias_masked\n",
    "        attn_weights = nn.functional.softmax(scores.float(), dim=-1).type_as(\n",
    "            scores\n",
    "        )  # (batch_size, n_heads, seq_length, key_length)\n",
    "        attn_weights = nn.functional.dropout(\n",
    "            attn_weights, p=self.dropout, training=self.training\n",
    "        )  # (batch_size, n_heads, seq_length, key_length)\n",
    "\n",
    "        # Mask heads if we want to\n",
    "        if layer_head_mask is not None:\n",
    "            attn_weights = attn_weights * layer_head_mask\n",
    "\n",
    "        attn_output = unshape(torch.matmul(attn_weights, value_states))  # (batch_size, seq_length, dim)\n",
    "        attn_output = self.o(attn_output)\n",
    "\n",
    "        present_key_value_state = (key_states, value_states) if (self.is_decoder and use_cache) else None\n",
    "        outputs = (attn_output,) + (present_key_value_state,) + (position_bias,)\n",
    "\n",
    "        if output_attentions:\n",
    "            outputs = outputs + (attn_weights,)\n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class T5LayerSelfAttention(nn.Module):\n",
    "    def __init__(self, d_model, num_heads, d_kv, dropout_rate, relative_attention_num_buckets, \n",
    "                 relative_attention_max_distance, is_decoder, layer_norm_epsilon=1e-6, has_relative_attention_bias=False):\n",
    "        super().__init__()\n",
    "        self.SelfAttention = T5Attention(d_model, num_heads, d_kv, dropout_rate, relative_attention_num_buckets, \n",
    "                 relative_attention_max_distance, is_decoder, has_relative_attention_bias)\n",
    "        self.layer_norm = T5LayerNorm(d_model, eps=layer_norm_epsilon)\n",
    "        self.dropout = nn.Dropout(dropout_rate)\n",
    "\n",
    "    def forward(\n",
    "        self,\n",
    "        hidden_states,\n",
    "        attention_mask=None,\n",
    "        position_bias=None,\n",
    "        layer_head_mask=None,\n",
    "        past_key_value=None,\n",
    "        use_cache=False,\n",
    "        output_attentions=False,\n",
    "    ):\n",
    "        normed_hidden_states = self.layer_norm(hidden_states)\n",
    "        attention_output = self.SelfAttention(\n",
    "            normed_hidden_states,\n",
    "            mask=attention_mask,\n",
    "            position_bias=position_bias,\n",
    "            layer_head_mask=layer_head_mask,\n",
    "            past_key_value=past_key_value,\n",
    "            use_cache=use_cache,\n",
    "            output_attentions=output_attentions,\n",
    "        )\n",
    "        hidden_states = hidden_states + self.dropout(attention_output[0])\n",
    "        outputs = (hidden_states,) + attention_output[1:]  # add attentions if we output them\n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class T5LayerCrossAttention(nn.Module):\n",
    "    def __init__(self, d_model, num_heads, d_kv, dropout_rate, relative_attention_num_buckets, \n",
    "                 relative_attention_max_distance, is_decoder, layer_norm_epsilon=1e-6, has_relative_attention_bias=False):\n",
    "        super().__init__()\n",
    "        self.EncDecAttention = T5Attention(d_model, num_heads, d_kv, dropout_rate, relative_attention_num_buckets, \n",
    "                 relative_attention_max_distance, is_decoder, has_relative_attention_bias)\n",
    "        self.layer_norm = T5LayerNorm(d_model, eps=layer_norm_epsilon)\n",
    "        self.dropout = nn.Dropout(dropout_rate)\n",
    "\n",
    "    def forward(\n",
    "        self,\n",
    "        hidden_states,\n",
    "        key_value_states,\n",
    "        attention_mask=None,\n",
    "        position_bias=None,\n",
    "        layer_head_mask=None,\n",
    "        past_key_value=None,\n",
    "        use_cache=False,\n",
    "        query_length=None,\n",
    "        output_attentions=False,\n",
    "    ):\n",
    "        normed_hidden_states = self.layer_norm(hidden_states)\n",
    "        attention_output = self.EncDecAttention(\n",
    "            normed_hidden_states,\n",
    "            mask=attention_mask,\n",
    "            key_value_states=key_value_states,\n",
    "            position_bias=position_bias,\n",
    "            layer_head_mask=layer_head_mask,\n",
    "            past_key_value=past_key_value,\n",
    "            use_cache=use_cache,\n",
    "            query_length=query_length,\n",
    "            output_attentions=output_attentions,\n",
    "        )\n",
    "        layer_output = hidden_states + self.dropout(attention_output[0])\n",
    "        outputs = (layer_output,) + attention_output[1:]  # add attentions if we output them\n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class T5Block(nn.Module):\n",
    "    def __init__(self, d_model, d_ff, num_heads, d_kv, dropout_rate, relative_attention_num_buckets, \n",
    "                 relative_attention_max_distance, is_decoder, layer_norm_epsilon=1e-6, is_gated_act=True, \n",
    "                 has_relative_attention_bias=False):\n",
    "        super().__init__()\n",
    "        self.is_decoder = is_decoder\n",
    "        self.layer = nn.ModuleList()\n",
    "        self.layer.append(T5LayerSelfAttention(d_model, num_heads, d_kv, dropout_rate, relative_attention_num_buckets, \n",
    "                 relative_attention_max_distance, is_decoder, layer_norm_epsilon, has_relative_attention_bias))\n",
    "        if self.is_decoder:\n",
    "            self.layer.append(T5LayerCrossAttention(d_model, num_heads, d_kv, dropout_rate, relative_attention_num_buckets, \n",
    "                 relative_attention_max_distance, is_decoder, layer_norm_epsilon, has_relative_attention_bias))\n",
    "\n",
    "        self.layer.append(T5LayerFF(d_model, d_ff, dropout_rate, layer_norm_epsilon, is_gated_act))\n",
    "\n",
    "    def forward(\n",
    "        self,\n",
    "        hidden_states,\n",
    "        attention_mask=None,\n",
    "        position_bias=None,\n",
    "        encoder_hidden_states=None,\n",
    "        encoder_attention_mask=None,\n",
    "        encoder_decoder_position_bias=None,\n",
    "        layer_head_mask=None,\n",
    "        cross_attn_layer_head_mask=None,\n",
    "        past_key_value=None,\n",
    "        use_cache=False,\n",
    "        output_attentions=False,\n",
    "        return_dict=True,\n",
    "    ):\n",
    "        if past_key_value is not None:\n",
    "            if not self.is_decoder:\n",
    "                logger.warning(\"`past_key_values` is passed to the encoder. Please make sure this is intended.\")\n",
    "            expected_num_past_key_values = 2 if encoder_hidden_states is None else 4\n",
    "\n",
    "            if len(past_key_value) != expected_num_past_key_values:\n",
    "                raise ValueError(\n",
    "                    f\"There should be {expected_num_past_key_values} past states. \"\n",
    "                    f\"{'2 (past / key) for cross attention. ' if expected_num_past_key_values == 4 else ''}\"\n",
    "                    f\"Got {len(past_key_value)} past key / value states\"\n",
    "                )\n",
    "\n",
    "            self_attn_past_key_value = past_key_value[:2]\n",
    "            cross_attn_past_key_value = past_key_value[2:]\n",
    "        else:\n",
    "            self_attn_past_key_value, cross_attn_past_key_value = None, None\n",
    "\n",
    "        self_attention_outputs = self.layer[0](\n",
    "            hidden_states,\n",
    "            attention_mask=attention_mask,\n",
    "            position_bias=position_bias,\n",
    "            layer_head_mask=layer_head_mask,\n",
    "            past_key_value=self_attn_past_key_value,\n",
    "            use_cache=use_cache,\n",
    "            output_attentions=output_attentions,\n",
    "        )\n",
    "        hidden_states, present_key_value_state = self_attention_outputs[:2]\n",
    "        attention_outputs = self_attention_outputs[2:]  # Keep self-attention outputs and relative position weights\n",
    "\n",
    "        # clamp inf values to enable fp16 training\n",
    "        if hidden_states.dtype == torch.float16:\n",
    "            clamp_value = torch.where(\n",
    "                torch.isinf(hidden_states).any(),\n",
    "                torch.finfo(hidden_states.dtype).max - 1000,\n",
    "                torch.finfo(hidden_states.dtype).max,\n",
    "            )\n",
    "            hidden_states = torch.clamp(hidden_states, min=-clamp_value, max=clamp_value)\n",
    "\n",
    "        do_cross_attention = self.is_decoder and encoder_hidden_states is not None\n",
    "        if do_cross_attention:\n",
    "            # the actual query length is unknown for cross attention\n",
    "            # if using past key value states. Need to inject it here\n",
    "            if present_key_value_state is not None:\n",
    "                query_length = present_key_value_state[0].shape[2]\n",
    "            else:\n",
    "                query_length = None\n",
    "\n",
    "            cross_attention_outputs = self.layer[1](\n",
    "                hidden_states,\n",
    "                key_value_states=encoder_hidden_states,\n",
    "                attention_mask=encoder_attention_mask,\n",
    "                position_bias=encoder_decoder_position_bias,\n",
    "                layer_head_mask=cross_attn_layer_head_mask,\n",
    "                past_key_value=cross_attn_past_key_value,\n",
    "                query_length=query_length,\n",
    "                use_cache=use_cache,\n",
    "                output_attentions=output_attentions,\n",
    "            )\n",
    "            hidden_states = cross_attention_outputs[0]\n",
    "\n",
    "            # clamp inf values to enable fp16 training\n",
    "            if hidden_states.dtype == torch.float16:\n",
    "                clamp_value = torch.where(\n",
    "                    torch.isinf(hidden_states).any(),\n",
    "                    torch.finfo(hidden_states.dtype).max - 1000,\n",
    "                    torch.finfo(hidden_states.dtype).max,\n",
    "                )\n",
    "                hidden_states = torch.clamp(hidden_states, min=-clamp_value, max=clamp_value)\n",
    "\n",
    "            # Combine self attn and cross attn key value states\n",
    "            if present_key_value_state is not None:\n",
    "                present_key_value_state = present_key_value_state + cross_attention_outputs[1]\n",
    "\n",
    "            # Keep cross-attention outputs and relative position weights\n",
    "            attention_outputs = attention_outputs + cross_attention_outputs[2:]\n",
    "\n",
    "        # Apply Feed Forward layer\n",
    "        hidden_states = self.layer[-1](hidden_states)\n",
    "\n",
    "        # clamp inf values to enable fp16 training\n",
    "        if hidden_states.dtype == torch.float16:\n",
    "            clamp_value = torch.where(\n",
    "                torch.isinf(hidden_states).any(),\n",
    "                torch.finfo(hidden_states.dtype).max - 1000,\n",
    "                torch.finfo(hidden_states.dtype).max,\n",
    "            )\n",
    "            hidden_states = torch.clamp(hidden_states, min=-clamp_value, max=clamp_value)\n",
    "\n",
    "        outputs = (hidden_states,)\n",
    "\n",
    "        if use_cache:\n",
    "            outputs = outputs + (present_key_value_state,) + attention_outputs\n",
    "        else:\n",
    "            outputs = outputs + attention_outputs\n",
    "\n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class T5Stack(nn.Module):\n",
    "    def __init__(self, num_layers, d_model, d_ff, num_heads, d_kv, dropout_rate, relative_attention_num_buckets, \n",
    "                 relative_attention_max_distance, is_decoder, use_cache, output_attentions, output_hidden_states, \n",
    "                 use_return_dict, layer_norm_epsilon=1e-6, is_gated_act=True, has_relative_attention_bias=False, \n",
    "                 embed_tokens=None):\n",
    "        super().__init__()\n",
    "\n",
    "        self.embed_tokens = embed_tokens\n",
    "        self.is_decoder = is_decoder\n",
    "\n",
    "        self.block = nn.ModuleList(\n",
    "            [T5Block(d_model, d_ff, num_heads, d_kv, dropout_rate, relative_attention_num_buckets, \n",
    "                 relative_attention_max_distance, is_decoder, layer_norm_epsilon=1e-6, is_gated_act=True, \n",
    "                 has_relative_attention_bias=bool(i == 0)) for i in range(num_layers)]\n",
    "        )\n",
    "        self.final_layer_norm = T5LayerNorm(d_model, eps=layer_norm_epsilon)\n",
    "        self.dropout = nn.Dropout(dropout_rate)\n",
    "\n",
    "        # Initialize weights and apply final processing\n",
    "        \n",
    "        # Model parallel\n",
    "        self.model_parallel = False\n",
    "        self.device_map = None\n",
    "        self.gradient_checkpointing = False\n",
    "        \n",
    "        self.num_layers = num_layers\n",
    "        self.use_cache = use_cache\n",
    "        self.output_attentions = output_attentions\n",
    "        self.output_hidden_states = output_hidden_states\n",
    "        self.use_return_dict = use_return_dict\n",
    "\n",
    "    def parallelize(self, device_map=None):\n",
    "        warnings.warn(\n",
    "            \"`T5Stack.parallelize` is deprecated and will be removed in v5 of Transformers, you should load your model\"\n",
    "            \" with `device_map='balanced'` in the call to `from_pretrained`. You can also provide your own\"\n",
    "            \" `device_map` but it needs to be a dictionary module_name to device, so for instance {'block.0': 0,\"\n",
    "            \" 'block.1': 1, ...}\",\n",
    "            FutureWarning,\n",
    "        )\n",
    "        # Check validity of device_map\n",
    "        self.device_map = (\n",
    "            get_device_map(len(self.block), range(torch.cuda.device_count())) if device_map is None else device_map\n",
    "        )\n",
    "        assert_device_map(self.device_map, len(self.block))\n",
    "        self.model_parallel = True\n",
    "        self.first_device = \"cpu\" if \"cpu\" in self.device_map.keys() else \"cuda:\" + str(min(self.device_map.keys()))\n",
    "        self.last_device = \"cuda:\" + str(max(self.device_map.keys()))\n",
    "        # Load onto devices\n",
    "        for k, v in self.device_map.items():\n",
    "            for layer in v:\n",
    "                cuda_device = \"cuda:\" + str(k)\n",
    "                self.block[layer] = self.block[layer].to(cuda_device)\n",
    "\n",
    "        # Set embed_tokens to first layer\n",
    "        self.embed_tokens = self.embed_tokens.to(self.first_device)\n",
    "        # Set final layer norm to last device\n",
    "        self.final_layer_norm = self.final_layer_norm.to(self.last_device)\n",
    "\n",
    "    def deparallelize(self):\n",
    "        warnings.warn(\n",
    "            \"Like `parallelize`, `deparallelize` is deprecated and will be removed in v5 of Transformers.\",\n",
    "            FutureWarning,\n",
    "        )\n",
    "        self.model_parallel = False\n",
    "        self.device_map = None\n",
    "        self.first_device = \"cpu\"\n",
    "        self.last_device = \"cpu\"\n",
    "        for i in range(len(self.block)):\n",
    "            self.block[i] = self.block[i].to(\"cpu\")\n",
    "        self.embed_tokens = self.embed_tokens.to(\"cpu\")\n",
    "        self.final_layer_norm = self.final_layer_norm.to(\"cpu\")\n",
    "        torch.cuda.empty_cache()\n",
    "\n",
    "    def get_input_embeddings(self):\n",
    "        return self.embed_tokens\n",
    "\n",
    "    def set_input_embeddings(self, new_embeddings):\n",
    "        self.embed_tokens = new_embeddings\n",
    "\n",
    "    def forward(\n",
    "        self,\n",
    "        input_ids=None,\n",
    "        attention_mask=None,\n",
    "        encoder_hidden_states=None,\n",
    "        encoder_attention_mask=None,\n",
    "        inputs_embeds=None,\n",
    "        head_mask=None,\n",
    "        cross_attn_head_mask=None,\n",
    "        past_key_values=None,\n",
    "        use_cache=None,\n",
    "        output_attentions=None,\n",
    "        output_hidden_states=None,\n",
    "        return_dict=None,\n",
    "    ):\n",
    "        # Model parallel\n",
    "        if self.model_parallel:\n",
    "            torch.cuda.set_device(self.first_device)\n",
    "            self.embed_tokens = self.embed_tokens.to(self.first_device)\n",
    "        use_cache = use_cache if use_cache is not None else self.use_cache\n",
    "        output_attentions = output_attentions if output_attentions is not None else self.output_attentions\n",
    "        output_hidden_states = (\n",
    "            output_hidden_states if output_hidden_states is not None else self.output_hidden_states\n",
    "        )\n",
    "        return_dict = return_dict if return_dict is not None else self.use_return_dict\n",
    "\n",
    "        if input_ids is not None and inputs_embeds is not None:\n",
    "            err_msg_prefix = \"decoder_\" if self.is_decoder else \"\"\n",
    "            raise ValueError(\n",
    "                f\"You cannot specify both {err_msg_prefix}input_ids and {err_msg_prefix}inputs_embeds at the same time\"\n",
    "            )\n",
    "        elif input_ids is not None:\n",
    "            input_shape = input_ids.size()\n",
    "            input_ids = input_ids.view(input_shape[0], input_shape[1], input_shape[2])\n",
    "        elif inputs_embeds is not None:\n",
    "            input_shape = inputs_embeds.size()[:-1]\n",
    "        else:\n",
    "            err_msg_prefix = \"decoder_\" if self.is_decoder else \"\"\n",
    "            raise ValueError(f\"You have to specify either {err_msg_prefix}input_ids or {err_msg_prefix}inputs_embeds\")\n",
    "\n",
    "        if inputs_embeds is None:\n",
    "            assert self.embed_tokens is not None, \"You have to initialize the model with valid token embeddings\"\n",
    "            inputs_embeds = input_ids\n",
    "\n",
    "        batch_size, seq_length = input_shape[0], input_shape[1]\n",
    "\n",
    "        # required mask seq length can be calculated via length of past\n",
    "        mask_seq_length = past_key_values[0][0].shape[2] + seq_length if past_key_values is not None else seq_length\n",
    "\n",
    "        if use_cache is True:\n",
    "            assert self.is_decoder, f\"`use_cache` can only be set to `True` if {self} is used as a decoder\"\n",
    "\n",
    "        if attention_mask is None:\n",
    "            attention_mask = torch.ones(batch_size, mask_seq_length, device=inputs_embeds.device)\n",
    "        if self.is_decoder and encoder_attention_mask is None and encoder_hidden_states is not None:\n",
    "            encoder_seq_length = encoder_hidden_states.shape[1]\n",
    "            encoder_attention_mask = torch.ones(\n",
    "                batch_size, encoder_seq_length, device=inputs_embeds.device, dtype=torch.long\n",
    "            )\n",
    "\n",
    "        # initialize past_key_values with `None` if past does not exist\n",
    "        if past_key_values is None:\n",
    "            past_key_values = [None] * len(self.block)\n",
    "\n",
    "        # We can provide a self-attention mask of dimensions [batch_size, from_seq_length, to_seq_length]\n",
    "        # ourselves in which case we just need to make it broadcastable to all heads.\n",
    "        extended_attention_mask = None\n",
    "        #extended_attention_mask = self.get_extended_attention_mask(attention_mask, input_shape)\n",
    "\n",
    "        # If a 2D or 3D attention mask is provided for the cross-attention\n",
    "        # we need to make broadcastable to [batch_size, num_heads, seq_length, seq_length]\n",
    "        if self.is_decoder and encoder_hidden_states is not None:\n",
    "            encoder_batch_size, encoder_sequence_length, _ = encoder_hidden_states.size()\n",
    "            encoder_hidden_shape = (encoder_batch_size, encoder_sequence_length)\n",
    "            if encoder_attention_mask is None:\n",
    "                encoder_attention_mask = torch.ones(encoder_hidden_shape, device=inputs_embeds.device)\n",
    "            encoder_extended_attention_mask = None\n",
    "            #encoder_extended_attention_mask = self.invert_attention_mask(encoder_attention_mask)\n",
    "        else:\n",
    "            encoder_extended_attention_mask = None\n",
    "\n",
    "        if self.gradient_checkpointing and self.training:\n",
    "            if use_cache:\n",
    "                logger.warning_once(\n",
    "                    \"`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\"\n",
    "                )\n",
    "                use_cache = False\n",
    "\n",
    "        # Prepare head mask if needed\n",
    "        head_mask = None\n",
    "        #head_mask = self.get_head_mask(head_mask, self.num_layers)\n",
    "        cross_attn_head_mask = None\n",
    "        #cross_attn_head_mask = self.get_head_mask(cross_attn_head_mask, self.num_layers)\n",
    "        present_key_value_states = () if use_cache else None\n",
    "        all_hidden_states = () if output_hidden_states else None\n",
    "        all_attentions = () if output_attentions else None\n",
    "        all_cross_attentions = () if (output_attentions and self.is_decoder) else None\n",
    "        position_bias = None\n",
    "        encoder_decoder_position_bias = None\n",
    "\n",
    "        hidden_states = self.dropout(inputs_embeds)\n",
    "\n",
    "        for i, (layer_module, past_key_value) in enumerate(zip(self.block, past_key_values)):\n",
    "            layer_head_mask = None\n",
    "            cross_attn_layer_head_mask = None\n",
    "            \n",
    "            #layer_head_mask = head_mask[i]\n",
    "            #cross_attn_layer_head_mask = cross_attn_head_mask[i]\n",
    "            # Model parallel\n",
    "            if self.model_parallel:\n",
    "                torch.cuda.set_device(hidden_states.device)\n",
    "                # Ensure that attention_mask is always on the same device as hidden_states\n",
    "                if attention_mask is not None:\n",
    "                    attention_mask = attention_mask.to(hidden_states.device)\n",
    "                if position_bias is not None:\n",
    "                    position_bias = position_bias.to(hidden_states.device)\n",
    "                if encoder_hidden_states is not None:\n",
    "                    encoder_hidden_states = encoder_hidden_states.to(hidden_states.device)\n",
    "                if encoder_extended_attention_mask is not None:\n",
    "                    encoder_extended_attention_mask = encoder_extended_attention_mask.to(hidden_states.device)\n",
    "                if encoder_decoder_position_bias is not None:\n",
    "                    encoder_decoder_position_bias = encoder_decoder_position_bias.to(hidden_states.device)\n",
    "                if layer_head_mask is not None:\n",
    "                    layer_head_mask = layer_head_mask.to(hidden_states.device)\n",
    "                if cross_attn_layer_head_mask is not None:\n",
    "                    cross_attn_layer_head_mask = cross_attn_layer_head_mask.to(hidden_states.device)\n",
    "            if output_hidden_states:\n",
    "                all_hidden_states = all_hidden_states + (hidden_states,)\n",
    "\n",
    "            if self.gradient_checkpointing and self.training:\n",
    "\n",
    "                def create_custom_forward(module):\n",
    "                    def custom_forward(*inputs):\n",
    "                        return tuple(module(*inputs, use_cache, output_attentions))\n",
    "\n",
    "                    return custom_forward\n",
    "\n",
    "                layer_outputs = checkpoint(\n",
    "                    create_custom_forward(layer_module),\n",
    "                    hidden_states,\n",
    "                    extended_attention_mask,\n",
    "                    position_bias,\n",
    "                    encoder_hidden_states,\n",
    "                    encoder_extended_attention_mask,\n",
    "                    encoder_decoder_position_bias,\n",
    "                    layer_head_mask,\n",
    "                    cross_attn_layer_head_mask,\n",
    "                    None,  # past_key_value is always None with gradient checkpointing\n",
    "                )\n",
    "            else:\n",
    "                layer_outputs = layer_module(\n",
    "                    hidden_states,\n",
    "                    attention_mask=extended_attention_mask,\n",
    "                    position_bias=position_bias,\n",
    "                    encoder_hidden_states=encoder_hidden_states,\n",
    "                    encoder_attention_mask=encoder_extended_attention_mask,\n",
    "                    encoder_decoder_position_bias=encoder_decoder_position_bias,\n",
    "                    layer_head_mask=layer_head_mask,\n",
    "                    cross_attn_layer_head_mask=cross_attn_layer_head_mask,\n",
    "                    past_key_value=past_key_value,\n",
    "                    use_cache=use_cache,\n",
    "                    output_attentions=output_attentions,\n",
    "                )\n",
    "\n",
    "            # layer_outputs is a tuple with:\n",
    "            # hidden-states, key-value-states, (self-attention position bias), (self-attention weights), (cross-attention position bias), (cross-attention weights)\n",
    "            if use_cache is False:\n",
    "                layer_outputs = layer_outputs[:1] + (None,) + layer_outputs[1:]\n",
    "\n",
    "            hidden_states, present_key_value_state = layer_outputs[:2]\n",
    "\n",
    "            # We share the position biases between the layers - the first layer store them\n",
    "            # layer_outputs = hidden-states, key-value-states (self-attention position bias), (self-attention weights),\n",
    "            # (cross-attention position bias), (cross-attention weights)\n",
    "            position_bias = layer_outputs[2]\n",
    "            if self.is_decoder and encoder_hidden_states is not None:\n",
    "                encoder_decoder_position_bias = layer_outputs[4 if output_attentions else 3]\n",
    "            # append next layer key value states\n",
    "            if use_cache:\n",
    "                present_key_value_states = present_key_value_states + (present_key_value_state,)\n",
    "\n",
    "            if output_attentions:\n",
    "                all_attentions = all_attentions + (layer_outputs[3],)\n",
    "                if self.is_decoder:\n",
    "                    all_cross_attentions = all_cross_attentions + (layer_outputs[5],)\n",
    "\n",
    "            # Model Parallel: If it's the last layer for that device, put things on the next device\n",
    "            if self.model_parallel:\n",
    "                for k, v in self.device_map.items():\n",
    "                    if i == v[-1] and \"cuda:\" + str(k) != self.last_device:\n",
    "                        hidden_states = hidden_states.to(\"cuda:\" + str(k + 1))\n",
    "\n",
    "        hidden_states = self.final_layer_norm(hidden_states)\n",
    "        hidden_states = self.dropout(hidden_states)\n",
    "\n",
    "        # Add last layer\n",
    "        if output_hidden_states:\n",
    "            all_hidden_states = all_hidden_states + (hidden_states,)\n",
    "\n",
    "        if not return_dict:\n",
    "            return tuple(\n",
    "                v\n",
    "                for v in [\n",
    "                    hidden_states,\n",
    "                    present_key_value_states,\n",
    "                    all_hidden_states,\n",
    "                    all_attentions,\n",
    "                    all_cross_attentions,\n",
    "                ]\n",
    "                if v is not None\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class T5Model(nn.Module):\n",
    "    _keys_to_ignore_on_load_missing = [\n",
    "        r\"encoder.embed_tokens.weight\",\n",
    "        r\"decoder.embed_tokens.weight\",\n",
    "    ]\n",
    "    _keys_to_ignore_on_load_unexpected = [\n",
    "        r\"decoder.block.0.layer.1.EncDecAttention.relative_attention_bias.weight\",\n",
    "    ]\n",
    "\n",
    "    def __init__(self, vocab_size, num_layers, num_decoder_layers, d_model, d_ff, num_heads, d_kv, dropout_rate, relative_attention_num_buckets, \n",
    "                 relative_attention_max_distance, output_attentions, output_hidden_states, use_cache, use_return_dict, layer_norm_epsilon, \n",
    "                 is_gated_act, has_relative_attention_bias):\n",
    "        super().__init__()\n",
    "        self.shared = nn.Embedding(vocab_size, d_model)\n",
    "        \n",
    "        self.encoder_is_decoder=False\n",
    "        self.encoder_use_cache=False\n",
    "\n",
    "        self.encoder = T5Stack(num_layers, d_model, d_ff, num_heads, d_kv, dropout_rate, relative_attention_num_buckets, \n",
    "                 relative_attention_max_distance, self.encoder_is_decoder, self.encoder_use_cache, output_attentions, output_hidden_states, \n",
    "                 use_return_dict, layer_norm_epsilon, is_gated_act, has_relative_attention_bias, self.shared)\n",
    "\n",
    "        self.decoder_is_decoder=True\n",
    "        self.decoder_use_cache=True\n",
    "        \n",
    "        self.decoder = T5Stack(num_decoder_layers, d_model, d_ff, num_heads, d_kv, dropout_rate, relative_attention_num_buckets, \n",
    "                 relative_attention_max_distance, self.decoder_is_decoder, self.decoder_use_cache, output_attentions, output_hidden_states, \n",
    "                 use_return_dict, layer_norm_epsilon, is_gated_act, has_relative_attention_bias, self.shared)\n",
    "\n",
    "        # Initialize weights and apply final processing\n",
    "\n",
    "        # Model parallel\n",
    "        self.model_parallel = False\n",
    "        self.device_map = None\n",
    "        \n",
    "        self.num_layers = num_layers\n",
    "        self.num_decoder_layers = num_decoder_layers\n",
    "        self.use_cache = use_cache\n",
    "        self.output_attentions = output_attentions\n",
    "        self.output_hidden_states = output_hidden_states\n",
    "        self.use_return_dict = use_return_dict\n",
    "        self.W = nn.Linear(d_model, 1)\n",
    "\n",
    "    def parallelize(self, device_map=None):\n",
    "        warnings.warn(\n",
    "            \"`T5Model.parallelize` is deprecated and will be removed in v5 of Transformers, you should load your model\"\n",
    "            \" with `device_map='balanced'` in the call to `from_pretrained`. You can also provide your own\"\n",
    "            \" `device_map` but it needs to be a dictionary module_name to device, so for instance {'encoder.block.0':\"\n",
    "            \" 0, 'encoder.block.1': 1, ...}\",\n",
    "            FutureWarning,\n",
    "        )\n",
    "        self.device_map = (\n",
    "            get_device_map(len(self.encoder.block), range(torch.cuda.device_count()))\n",
    "            if device_map is None\n",
    "            else device_map\n",
    "        )\n",
    "        assert_device_map(self.device_map, len(self.encoder.block))\n",
    "        self.encoder.parallelize(self.device_map)\n",
    "        self.decoder.parallelize(self.device_map)\n",
    "        self.model_parallel = True\n",
    "\n",
    "    def deparallelize(self):\n",
    "        warnings.warn(\n",
    "            \"Like `parallelize`, `deparallelize` is deprecated and will be removed in v5 of Transformers.\",\n",
    "            FutureWarning,\n",
    "        )\n",
    "        self.encoder.deparallelize()\n",
    "        self.decoder.deparallelize()\n",
    "        self.encoder = self.encoder.to(\"cpu\")\n",
    "        self.decoder = self.decoder.to(\"cpu\")\n",
    "        self.model_parallel = False\n",
    "        self.device_map = None\n",
    "        torch.cuda.empty_cache()\n",
    "\n",
    "    def get_input_embeddings(self):\n",
    "        return self.shared\n",
    "\n",
    "    def set_input_embeddings(self, new_embeddings):\n",
    "        self.shared = new_embeddings\n",
    "        self.encoder.set_input_embeddings(new_embeddings)\n",
    "        self.decoder.set_input_embeddings(new_embeddings)\n",
    "\n",
    "    def get_encoder(self):\n",
    "        return self.encoder\n",
    "\n",
    "    def get_decoder(self):\n",
    "        return self.decoder\n",
    "\n",
    "    def _prune_heads(self, heads_to_prune):\n",
    "        \"\"\"\n",
    "        Prunes heads of the model. heads_to_prune: dict of {layer_num: list of heads to prune in this layer} See base\n",
    "        class PreTrainedModel\n",
    "        \"\"\"\n",
    "        for layer, heads in heads_to_prune.items():\n",
    "            self.encoder.layer[layer].attention.prune_heads(heads)\n",
    "\n",
    "    def forward(\n",
    "        self,\n",
    "        input_ids: Optional[torch.LongTensor] = None,\n",
    "        attention_mask: Optional[torch.FloatTensor] = None,\n",
    "        decoder_input_ids: Optional[torch.LongTensor] = None,\n",
    "        decoder_attention_mask: Optional[torch.BoolTensor] = None,\n",
    "        head_mask: Optional[torch.FloatTensor] = None,\n",
    "        decoder_head_mask: Optional[torch.FloatTensor] = None,\n",
    "        cross_attn_head_mask: Optional[torch.Tensor] = None,\n",
    "        encoder_outputs: Optional[Tuple[Tuple[torch.FloatTensor]]] = None,\n",
    "        past_key_values: Optional[Tuple[Tuple[torch.FloatTensor]]] = None,\n",
    "        inputs_embeds: Optional[torch.Tensor] = None,\n",
    "        decoder_inputs_embeds: Optional[torch.Tensor] = None,\n",
    "        use_cache: Optional[bool] = None,\n",
    "        output_attentions: Optional[bool] = None,\n",
    "        output_hidden_states: Optional[bool] = None,\n",
    "        return_dict: Optional[bool] = None,\n",
    "    ) -> Union[Tuple[torch.FloatTensor]]:\n",
    "        r\"\"\"\n",
    "        Returns:\n",
    "        Example:\n",
    "        ```python\n",
    "        >>> from transformers import AutoTokenizer, T5Model\n",
    "        >>> tokenizer = AutoTokenizer.from_pretrained(\"t5-small\")\n",
    "        >>> model = T5Model.from_pretrained(\"t5-small\")\n",
    "        >>> input_ids = tokenizer(\n",
    "        ...     \"Studies have been shown that owning a dog is good for you\", return_tensors=\"pt\"\n",
    "        ... ).input_ids  # Batch size 1\n",
    "        >>> decoder_input_ids = tokenizer(\"Studies show that\", return_tensors=\"pt\").input_ids  # Batch size 1\n",
    "        >>> # preprocess: Prepend decoder_input_ids with start token which is pad token for T5Model.\n",
    "        >>> # This is not needed for torch's T5ForConditionalGeneration as it does this internally using labels arg.\n",
    "        >>> decoder_input_ids = model._shift_right(decoder_input_ids)\n",
    "        >>> # forward pass\n",
    "        >>> outputs = model(input_ids=input_ids, decoder_input_ids=decoder_input_ids)\n",
    "        >>> last_hidden_states = outputs.last_hidden_state\n",
    "        ```\"\"\"\n",
    "        use_cache = use_cache if use_cache is not None else self.use_cache\n",
    "        return_dict = return_dict if return_dict is not None else self.use_return_dict\n",
    "\n",
    "        # FutureWarning: head_mask was separated into two input args - head_mask, decoder_head_mask\n",
    "        if head_mask is not None and decoder_head_mask is None:\n",
    "            if self.num_layers == self.num_decoder_layers:\n",
    "                warnings.warn(__HEAD_MASK_WARNING_MSG, FutureWarning)\n",
    "                decoder_head_mask = head_mask\n",
    "\n",
    "        # Encode if needed (training, first prediction pass)\n",
    "        if encoder_outputs is None:\n",
    "            encoder_outputs = self.encoder(\n",
    "                input_ids=input_ids,\n",
    "                attention_mask=attention_mask,\n",
    "                inputs_embeds=inputs_embeds,\n",
    "                head_mask=head_mask,\n",
    "                output_attentions=output_attentions,\n",
    "                output_hidden_states=output_hidden_states,\n",
    "                return_dict=return_dict,\n",
    "            )\n",
    "        elif return_dict and not isinstance(encoder_outputs, BaseModelOutput):\n",
    "            encoder_outputs = BaseModelOutput(\n",
    "                last_hidden_state=encoder_outputs[0],\n",
    "                hidden_states=encoder_outputs[1] if len(encoder_outputs) > 1 else None,\n",
    "                attentions=encoder_outputs[2] if len(encoder_outputs) > 2 else None,\n",
    "            )\n",
    "\n",
    "        hidden_states = encoder_outputs[0]\n",
    "\n",
    "        # Set device for model parallelism\n",
    "        if self.model_parallel:\n",
    "            torch.cuda.set_device(self.decoder.first_device)\n",
    "            hidden_states = hidden_states.to(self.decoder.first_device)\n",
    "            if decoder_input_ids is not None:\n",
    "                decoder_input_ids = decoder_input_ids.to(self.decoder.first_device)\n",
    "            if attention_mask is not None:\n",
    "                attention_mask = attention_mask.to(self.decoder.first_device)\n",
    "            if decoder_attention_mask is not None:\n",
    "                decoder_attention_mask = decoder_attention_mask.to(self.decoder.first_device)\n",
    "\n",
    "        # Decode\n",
    "        decoder_outputs = self.decoder(\n",
    "            input_ids=decoder_input_ids,\n",
    "            attention_mask=decoder_attention_mask,\n",
    "            inputs_embeds=decoder_inputs_embeds,\n",
    "            past_key_values=past_key_values,\n",
    "            encoder_hidden_states=hidden_states,\n",
    "            encoder_attention_mask=attention_mask,\n",
    "            head_mask=decoder_head_mask,\n",
    "            cross_attn_head_mask=cross_attn_head_mask,\n",
    "            use_cache=use_cache,\n",
    "            output_attentions=output_attentions,\n",
    "            output_hidden_states=output_hidden_states,\n",
    "            return_dict=return_dict,\n",
    "        )\n",
    "        \n",
    "        decoder_outputs = self.W(torch.sum(decoder_outputs[0],dim=1)/decoder_outputs[0].size(1))\n",
    "\n",
    "        if not return_dict:\n",
    "            return decoder_outputs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_layers = 2\n",
    "num_decoder_layers = 2\n",
    "d_model = 20\n",
    "d_ff = 64\n",
    "num_heads = 2\n",
    "d_kv = 5\n",
    "dropout_rate = 0\n",
    "relative_attention_num_buckets = 32\n",
    "relative_attention_max_distance = 128\n",
    "output_attentions = False\n",
    "output_hidden_states = False\n",
    "use_cache = True\n",
    "use_return_dict = False\n",
    "layer_norm_epsilon = 1e-6\n",
    "is_gated_act = True\n",
    "has_relative_attention_bias = True\n",
    "vocab_size = 512\n",
    "\n",
    "model = T5Model(\n",
    "    vocab_size,\n",
    "    num_layers, \n",
    "    num_decoder_layers, \n",
    "    d_model, \n",
    "    d_ff, \n",
    "    num_heads, \n",
    "    d_kv, \n",
    "    dropout_rate, \n",
    "    relative_attention_num_buckets, \n",
    "    relative_attention_max_distance, \n",
    "    output_attentions, \n",
    "    output_hidden_states,\n",
    "    use_cache,\n",
    "    use_return_dict, \n",
    "    layer_norm_epsilon, \n",
    "    is_gated_act, \n",
    "    has_relative_attention_bias\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_input = torch.rand(5, 21, 20)\n",
    "decoder_input = torch.rand(5, 1, 20)\n",
    "outputs = model(input_ids=encoder_input, decoder_input_ids=decoder_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5, 1])\n",
      "tensor([[-0.5800],\n",
      "        [ 0.4075],\n",
      "        [ 0.0161],\n",
      "        [ 0.1497],\n",
      "        [ 0.5447]], grad_fn=<AddmmBackward0>)\n"
     ]
    }
   ],
   "source": [
    "print(outputs.shape)\n",
    "print(outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import seaborn as sns\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>AOAL</th>\n",
       "      <th>AOAR</th>\n",
       "      <th>PITCH</th>\n",
       "      <th>W</th>\n",
       "      <th>MACH</th>\n",
       "      <th>AIRSPD</th>\n",
       "      <th>TEFLAPL</th>\n",
       "      <th>XIDA</th>\n",
       "      <th>T</th>\n",
       "      <th>...</th>\n",
       "      <th>OPR</th>\n",
       "      <th>OTL</th>\n",
       "      <th>OTR</th>\n",
       "      <th>VIBN1L</th>\n",
       "      <th>VIBN1R</th>\n",
       "      <th>VIBN2L</th>\n",
       "      <th>VIBN2R</th>\n",
       "      <th>FE</th>\n",
       "      <th>TMAX</th>\n",
       "      <th>FS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>-10.55</td>\n",
       "      <td>-4.22</td>\n",
       "      <td>-0.53</td>\n",
       "      <td>63901.05853</td>\n",
       "      <td>0.084</td>\n",
       "      <td>56.3</td>\n",
       "      <td>5</td>\n",
       "      <td>6.855</td>\n",
       "      <td>20.50</td>\n",
       "      <td>...</td>\n",
       "      <td>24</td>\n",
       "      <td>110</td>\n",
       "      <td>110</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.05</td>\n",
       "      <td>23995.070700</td>\n",
       "      <td>24572.967483</td>\n",
       "      <td>577.896783</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>-9.84</td>\n",
       "      <td>-3.87</td>\n",
       "      <td>-0.53</td>\n",
       "      <td>63900.67347</td>\n",
       "      <td>0.087</td>\n",
       "      <td>58.2</td>\n",
       "      <td>5</td>\n",
       "      <td>6.325</td>\n",
       "      <td>20.50</td>\n",
       "      <td>...</td>\n",
       "      <td>26</td>\n",
       "      <td>110</td>\n",
       "      <td>110</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.05</td>\n",
       "      <td>23453.775200</td>\n",
       "      <td>24572.967483</td>\n",
       "      <td>1119.192283</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>-9.14</td>\n",
       "      <td>-3.34</td>\n",
       "      <td>-0.53</td>\n",
       "      <td>63900.23197</td>\n",
       "      <td>0.090</td>\n",
       "      <td>60.1</td>\n",
       "      <td>5</td>\n",
       "      <td>5.710</td>\n",
       "      <td>20.50</td>\n",
       "      <td>...</td>\n",
       "      <td>26</td>\n",
       "      <td>110</td>\n",
       "      <td>110</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.05</td>\n",
       "      <td>22821.215600</td>\n",
       "      <td>24572.967483</td>\n",
       "      <td>1751.751883</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>-8.09</td>\n",
       "      <td>-3.87</td>\n",
       "      <td>-0.35</td>\n",
       "      <td>63899.73805</td>\n",
       "      <td>0.093</td>\n",
       "      <td>62.0</td>\n",
       "      <td>5</td>\n",
       "      <td>5.630</td>\n",
       "      <td>20.50</td>\n",
       "      <td>...</td>\n",
       "      <td>26</td>\n",
       "      <td>110</td>\n",
       "      <td>110</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.05</td>\n",
       "      <td>22738.950900</td>\n",
       "      <td>24572.967483</td>\n",
       "      <td>1834.016583</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>-7.56</td>\n",
       "      <td>-3.87</td>\n",
       "      <td>-0.35</td>\n",
       "      <td>63899.14333</td>\n",
       "      <td>0.096</td>\n",
       "      <td>63.9</td>\n",
       "      <td>5</td>\n",
       "      <td>5.365</td>\n",
       "      <td>20.50</td>\n",
       "      <td>...</td>\n",
       "      <td>26</td>\n",
       "      <td>110</td>\n",
       "      <td>110</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.05</td>\n",
       "      <td>22464.769900</td>\n",
       "      <td>24572.967483</td>\n",
       "      <td>2108.197583</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11519</th>\n",
       "      <td>11544</td>\n",
       "      <td>-2.81</td>\n",
       "      <td>-3.69</td>\n",
       "      <td>-0.70</td>\n",
       "      <td>56378.87869</td>\n",
       "      <td>0.150</td>\n",
       "      <td>56.0</td>\n",
       "      <td>30</td>\n",
       "      <td>3.950</td>\n",
       "      <td>23.75</td>\n",
       "      <td>...</td>\n",
       "      <td>43</td>\n",
       "      <td>98</td>\n",
       "      <td>98</td>\n",
       "      <td>0.09</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.05</td>\n",
       "      <td>7668.487126</td>\n",
       "      <td>18764.344514</td>\n",
       "      <td>11095.857388</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11520</th>\n",
       "      <td>11545</td>\n",
       "      <td>-2.99</td>\n",
       "      <td>-3.69</td>\n",
       "      <td>-0.88</td>\n",
       "      <td>56378.72144</td>\n",
       "      <td>0.150</td>\n",
       "      <td>52.0</td>\n",
       "      <td>30</td>\n",
       "      <td>4.220</td>\n",
       "      <td>23.75</td>\n",
       "      <td>...</td>\n",
       "      <td>31</td>\n",
       "      <td>98</td>\n",
       "      <td>98</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.07</td>\n",
       "      <td>7393.237132</td>\n",
       "      <td>18764.344514</td>\n",
       "      <td>11371.107383</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11521</th>\n",
       "      <td>11546</td>\n",
       "      <td>-2.81</td>\n",
       "      <td>-3.69</td>\n",
       "      <td>-0.88</td>\n",
       "      <td>56378.57427</td>\n",
       "      <td>0.150</td>\n",
       "      <td>49.0</td>\n",
       "      <td>30</td>\n",
       "      <td>4.130</td>\n",
       "      <td>23.75</td>\n",
       "      <td>...</td>\n",
       "      <td>31</td>\n",
       "      <td>98</td>\n",
       "      <td>98</td>\n",
       "      <td>0.13</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.09</td>\n",
       "      <td>7484.958267</td>\n",
       "      <td>18764.344514</td>\n",
       "      <td>11279.386247</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11522</th>\n",
       "      <td>11547</td>\n",
       "      <td>-2.81</td>\n",
       "      <td>-3.69</td>\n",
       "      <td>-0.70</td>\n",
       "      <td>56378.43517</td>\n",
       "      <td>0.150</td>\n",
       "      <td>46.0</td>\n",
       "      <td>30</td>\n",
       "      <td>3.950</td>\n",
       "      <td>24.00</td>\n",
       "      <td>...</td>\n",
       "      <td>31</td>\n",
       "      <td>97</td>\n",
       "      <td>97</td>\n",
       "      <td>0.13</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.18</td>\n",
       "      <td>0.09</td>\n",
       "      <td>7652.561590</td>\n",
       "      <td>18764.344514</td>\n",
       "      <td>11111.782924</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11523</th>\n",
       "      <td>11548</td>\n",
       "      <td>-3.16</td>\n",
       "      <td>-3.69</td>\n",
       "      <td>-0.70</td>\n",
       "      <td>56378.30816</td>\n",
       "      <td>0.150</td>\n",
       "      <td>45.0</td>\n",
       "      <td>30</td>\n",
       "      <td>4.125</td>\n",
       "      <td>24.00</td>\n",
       "      <td>...</td>\n",
       "      <td>31</td>\n",
       "      <td>97</td>\n",
       "      <td>97</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.09</td>\n",
       "      <td>7474.749119</td>\n",
       "      <td>18764.344514</td>\n",
       "      <td>11289.595395</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>11524 rows × 28 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        date   AOAL  AOAR  PITCH            W   MACH  AIRSPD  TEFLAPL   XIDA  \\\n",
       "0          0 -10.55 -4.22  -0.53  63901.05853  0.084    56.3        5  6.855   \n",
       "1          1  -9.84 -3.87  -0.53  63900.67347  0.087    58.2        5  6.325   \n",
       "2          2  -9.14 -3.34  -0.53  63900.23197  0.090    60.1        5  5.710   \n",
       "3          3  -8.09 -3.87  -0.35  63899.73805  0.093    62.0        5  5.630   \n",
       "4          4  -7.56 -3.87  -0.35  63899.14333  0.096    63.9        5  5.365   \n",
       "...      ...    ...   ...    ...          ...    ...     ...      ...    ...   \n",
       "11519  11544  -2.81 -3.69  -0.70  56378.87869  0.150    56.0       30  3.950   \n",
       "11520  11545  -2.99 -3.69  -0.88  56378.72144  0.150    52.0       30  4.220   \n",
       "11521  11546  -2.81 -3.69  -0.88  56378.57427  0.150    49.0       30  4.130   \n",
       "11522  11547  -2.81 -3.69  -0.70  56378.43517  0.150    46.0       30  3.950   \n",
       "11523  11548  -3.16 -3.69  -0.70  56378.30816  0.150    45.0       30  4.125   \n",
       "\n",
       "           T  ...  OPR  OTL  OTR  VIBN1L  VIBN1R  VIBN2L  VIBN2R  \\\n",
       "0      20.50  ...   24  110  110    0.03    0.05    0.05    0.05   \n",
       "1      20.50  ...   26  110  110    0.03    0.05    0.07    0.05   \n",
       "2      20.50  ...   26  110  110    0.03    0.06    0.08    0.05   \n",
       "3      20.50  ...   26  110  110    0.03    0.06    0.08    0.05   \n",
       "4      20.50  ...   26  110  110    0.03    0.06    0.08    0.05   \n",
       "...      ...  ...  ...  ...  ...     ...     ...     ...     ...   \n",
       "11519  23.75  ...   43   98   98    0.09    0.10    0.10    0.05   \n",
       "11520  23.75  ...   31   98   98    0.10    0.10    0.12    0.07   \n",
       "11521  23.75  ...   31   98   98    0.13    0.12    0.12    0.09   \n",
       "11522  24.00  ...   31   97   97    0.13    0.15    0.18    0.09   \n",
       "11523  24.00  ...   31   97   97    0.14    0.15    0.25    0.09   \n",
       "\n",
       "                 FE          TMAX            FS  \n",
       "0      23995.070700  24572.967483    577.896783  \n",
       "1      23453.775200  24572.967483   1119.192283  \n",
       "2      22821.215600  24572.967483   1751.751883  \n",
       "3      22738.950900  24572.967483   1834.016583  \n",
       "4      22464.769900  24572.967483   2108.197583  \n",
       "...             ...           ...           ...  \n",
       "11519   7668.487126  18764.344514  11095.857388  \n",
       "11520   7393.237132  18764.344514  11371.107383  \n",
       "11521   7484.958267  18764.344514  11279.386247  \n",
       "11522   7652.561590  18764.344514  11111.782924  \n",
       "11523   7474.749119  18764.344514  11289.595395  \n",
       "\n",
       "[11524 rows x 28 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "column_names = ['date','AOAL','AOAR','PITCH','W','MACH','AIRSPD','TEFLAPL','XIDA',\n",
    "               'T','ALTSTD','N1L','N1R','N2L','N2R','EGTL','EGTR','OPL','OPR','OTL',\n",
    "               'OTR','VIBN1L','VIBN1R','VIBN2L','VIBN2R','FE','TMAX','FS']\n",
    "\n",
    "input=pd.read_excel('D:\\\\研究生毕设\\\\practice\\\\QAR_xunlian.xlsx',names=column_names)\n",
    "input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_names = ['W','MACH','AIRSPD','TEFLAPL','XIDA',\n",
    "               'T','ALTSTD','N1L','N1R','N2L','N2R','EGTL','EGTR','OPL','OPR','OTL',\n",
    "               'OTR','VIBN1L','VIBN1R','VIBN2L','VIBN2R','FE']\n",
    "\n",
    "df=input[feature_names]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_for_training=df[feature_names].astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11524, 22)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_for_training.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler=StandardScaler()\n",
    "scaler=scaler.fit(df_for_training)\n",
    "df_for_training_scaled=scaler.transform(df_for_training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainX=[]\n",
    "trainY=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_future=1\n",
    "n_past=20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(n_past,len(df_for_training_scaled)-n_future+1):\n",
    "    trainX.append(df_for_training_scaled[i-n_past:i,0:df_for_training.shape[1]])\n",
    "    trainY.append(df_for_training_scaled[i:i+n_future,21])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainX shape==(11504, 20, 22).\n",
      "trainY shape==(11504, 1).\n"
     ]
    }
   ],
   "source": [
    "trainX,trainY=np.array(trainX),np.array(trainY)\n",
    "print('trainX shape=={}.'.format(trainX.shape))\n",
    "print('trainY shape=={}.'.format(trainY.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainX0=np.zeros((trainX.shape[0],22,20))\n",
    "for i in range(0,trainX.shape[0]):\n",
    "    trainX0[i]=trainX[i].T\n",
    "trainX1=np.zeros((trainX.shape[0],21,20))\n",
    "for i in range(0,trainX.shape[0]):\n",
    "    trainX1[i]=trainX0[i][0:21,:]\n",
    "trainX2=np.zeros((trainX.shape[0],1,20))\n",
    "for i in range(0,trainX.shape[0]):\n",
    "    trainX2[i]=trainX0[i][21,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainX1_copy,trainX2_copy,trainY_copy=trainX1.copy(),trainX2.copy(),trainY.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_shuffle(data1,data2,label):\n",
    "    randnum = np.random.randint(0, len(label))\n",
    "    np.random.seed(randnum)\n",
    "    np.random.shuffle(data1)\n",
    "    np.random.seed(randnum)\n",
    "    np.random.shuffle(data2)\n",
    "    np.random.seed(randnum)\n",
    "    np.random.shuffle(label)\n",
    "    return data1,data2,label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "data1,data2,label=random_shuffle(trainX1,trainX2,trainY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a DataLoader for the training data\n",
    "data1 = torch.from_numpy(data1).float()\n",
    "data2 = torch.from_numpy(data2).float()\n",
    "label = torch.from_numpy(label).float()\n",
    "train_dataset = TensorDataset(data1, data2, label)\n",
    "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(model.parameters(), lr=3e-4, weight_decay=1e-5)\n",
    "min_val_acc=1000000000000000\n",
    "scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=50, eta_min=0 )\n",
    "criterion = nn.L1Loss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda3\\lib\\site-packages\\torch\\optim\\lr_scheduler.py:156: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n",
      "  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 Loss: 0.16242924332618713\n",
      "Epoch: 1 Loss: 0.2760135233402252\n",
      "Epoch: 2 Loss: 3.1423087120056152\n",
      "Epoch: 3 Loss: 1.5226991176605225\n",
      "Epoch: 4 Loss: 2.728738307952881\n",
      "Epoch: 5 Loss: 0.11010122299194336\n",
      "Epoch: 6 Loss: 0.08882905542850494\n",
      "Epoch: 7 Loss: 0.4298303723335266\n",
      "Epoch: 8 Loss: 0.5624101161956787\n",
      "Epoch: 9 Loss: 0.7018256783485413\n",
      "Epoch: 10 Loss: 1.8782199621200562\n",
      "Epoch: 11 Loss: 0.08407353609800339\n",
      "Epoch: 12 Loss: 0.2559303939342499\n",
      "Epoch: 13 Loss: 0.8881165981292725\n",
      "Epoch: 14 Loss: 0.9812569618225098\n",
      "Epoch: 15 Loss: 0.5147222280502319\n",
      "Epoch: 16 Loss: 0.053617432713508606\n",
      "Epoch: 17 Loss: 0.2732222378253937\n",
      "Epoch: 18 Loss: 0.18276295065879822\n",
      "Epoch: 19 Loss: 1.2582443952560425\n",
      "Epoch: 20 Loss: 0.16531123220920563\n",
      "Epoch: 21 Loss: 0.1258004903793335\n",
      "Epoch: 22 Loss: 0.8993136882781982\n",
      "Epoch: 23 Loss: 0.26204055547714233\n",
      "Epoch: 24 Loss: 0.4729315936565399\n",
      "Epoch: 25 Loss: 1.2593371868133545\n",
      "Epoch: 26 Loss: 0.991138219833374\n",
      "Epoch: 27 Loss: 0.13211128115653992\n",
      "Epoch: 28 Loss: 0.37963366508483887\n",
      "Epoch: 29 Loss: 0.07755430787801743\n",
      "Epoch: 30 Loss: 0.3775310218334198\n",
      "Epoch: 31 Loss: 1.1812858581542969\n",
      "Epoch: 32 Loss: 1.9444103240966797\n",
      "Epoch: 33 Loss: 0.6209097504615784\n",
      "Epoch: 34 Loss: 0.30942702293395996\n",
      "Epoch: 35 Loss: 0.12697863578796387\n",
      "Epoch: 36 Loss: 0.5350128412246704\n",
      "Epoch: 37 Loss: 0.16488789021968842\n",
      "Epoch: 38 Loss: 0.18193764984607697\n",
      "Epoch: 39 Loss: 0.06943324208259583\n",
      "Epoch: 40 Loss: 0.09558315575122833\n",
      "Epoch: 41 Loss: 1.0376828908920288\n",
      "Epoch: 42 Loss: 0.06019946187734604\n",
      "Epoch: 43 Loss: 0.058946382254362106\n",
      "Epoch: 44 Loss: 0.45876544713974\n",
      "Epoch: 45 Loss: 0.742862343788147\n",
      "Epoch: 46 Loss: 0.30706533789634705\n",
      "Epoch: 47 Loss: 0.1550830751657486\n",
      "Epoch: 48 Loss: 0.21704785525798798\n",
      "Epoch: 49 Loss: 0.6576710343360901\n",
      "Epoch: 50 Loss: 0.19281825423240662\n",
      "Epoch: 51 Loss: 0.4299856424331665\n",
      "Epoch: 52 Loss: 0.12817400693893433\n",
      "Epoch: 53 Loss: 0.21309584379196167\n",
      "Epoch: 54 Loss: 0.06015101447701454\n",
      "Epoch: 55 Loss: 0.5532981157302856\n",
      "Epoch: 56 Loss: 0.1826525330543518\n",
      "Epoch: 57 Loss: 0.15786303579807281\n",
      "Epoch: 58 Loss: 0.18004518747329712\n",
      "Epoch: 59 Loss: 0.06637421250343323\n",
      "Epoch: 60 Loss: 0.19831812381744385\n",
      "Epoch: 61 Loss: 0.11111512035131454\n",
      "Epoch: 62 Loss: 0.16938456892967224\n",
      "Epoch: 63 Loss: 0.29601985216140747\n",
      "Epoch: 64 Loss: 0.10078928619623184\n",
      "Epoch: 65 Loss: 0.1188095286488533\n",
      "Epoch: 66 Loss: 0.0969429612159729\n",
      "Epoch: 67 Loss: 0.04823285713791847\n",
      "Epoch: 68 Loss: 0.47458934783935547\n",
      "Epoch: 69 Loss: 0.085703544318676\n",
      "Epoch: 70 Loss: 0.41326409578323364\n",
      "Epoch: 71 Loss: 0.2282155454158783\n",
      "Epoch: 72 Loss: 0.16104935109615326\n",
      "Epoch: 73 Loss: 0.1884402185678482\n",
      "Epoch: 74 Loss: 0.09554977715015411\n",
      "Epoch: 75 Loss: 0.14690053462982178\n",
      "Epoch: 76 Loss: 0.14081431925296783\n",
      "Epoch: 77 Loss: 0.21779760718345642\n",
      "Epoch: 78 Loss: 0.5730237364768982\n",
      "Epoch: 79 Loss: 0.07100649178028107\n",
      "Epoch: 80 Loss: 0.2590056359767914\n",
      "Epoch: 81 Loss: 0.11616409569978714\n",
      "Epoch: 82 Loss: 0.26844677329063416\n",
      "Epoch: 83 Loss: 0.4066096544265747\n",
      "Epoch: 84 Loss: 0.49988749623298645\n",
      "Epoch: 85 Loss: 0.2491002380847931\n",
      "Epoch: 86 Loss: 0.21687248349189758\n",
      "Epoch: 87 Loss: 0.054094474762678146\n",
      "Epoch: 88 Loss: 0.40763717889785767\n",
      "Epoch: 89 Loss: 0.19933810830116272\n",
      "Epoch: 90 Loss: 0.2981272041797638\n",
      "Epoch: 91 Loss: 0.1224786788225174\n",
      "Epoch: 92 Loss: 0.05652788653969765\n",
      "Epoch: 93 Loss: 0.17969860136508942\n",
      "Epoch: 94 Loss: 0.2513284385204315\n",
      "Epoch: 95 Loss: 0.05611702799797058\n",
      "Epoch: 96 Loss: 0.07260756939649582\n",
      "Epoch: 97 Loss: 0.2594790458679199\n",
      "Epoch: 98 Loss: 0.1782366782426834\n",
      "Epoch: 99 Loss: 0.12040764093399048\n",
      "Epoch: 100 Loss: 0.05700617656111717\n",
      "Epoch: 101 Loss: 0.7077878713607788\n",
      "Epoch: 102 Loss: 0.1760959029197693\n",
      "Epoch: 103 Loss: 0.04806748032569885\n",
      "Epoch: 104 Loss: 0.21728166937828064\n",
      "Epoch: 105 Loss: 0.20069056749343872\n",
      "Epoch: 106 Loss: 0.16314345598220825\n",
      "Epoch: 107 Loss: 0.08308727294206619\n",
      "Epoch: 108 Loss: 0.0796690583229065\n",
      "Epoch: 109 Loss: 0.21620169281959534\n",
      "Epoch: 110 Loss: 0.08937317878007889\n",
      "Epoch: 111 Loss: 0.13954967260360718\n",
      "Epoch: 112 Loss: 0.33833983540534973\n",
      "Epoch: 113 Loss: 0.11552755534648895\n",
      "Epoch: 114 Loss: 0.1542179435491562\n",
      "Epoch: 115 Loss: 0.12058763951063156\n",
      "Epoch: 116 Loss: 0.055830828845500946\n",
      "Epoch: 117 Loss: 0.07766144722700119\n",
      "Epoch: 118 Loss: 0.17549455165863037\n",
      "Epoch: 119 Loss: 0.06575553119182587\n",
      "Epoch: 120 Loss: 0.1061280369758606\n",
      "Epoch: 121 Loss: 0.2415165901184082\n",
      "Epoch: 122 Loss: 0.1624782234430313\n",
      "Epoch: 123 Loss: 0.13847991824150085\n",
      "Epoch: 124 Loss: 0.3745371699333191\n",
      "Epoch: 125 Loss: 0.2377050518989563\n",
      "Epoch: 126 Loss: 0.5204989314079285\n",
      "Epoch: 127 Loss: 0.174076646566391\n",
      "Epoch: 128 Loss: 0.06302891671657562\n",
      "Epoch: 129 Loss: 0.17402687668800354\n",
      "Epoch: 130 Loss: 0.2190781533718109\n",
      "Epoch: 131 Loss: 0.2082107812166214\n",
      "Epoch: 132 Loss: 0.07491237670183182\n",
      "Epoch: 133 Loss: 0.23565249145030975\n",
      "Epoch: 134 Loss: 0.11585365235805511\n",
      "Epoch: 135 Loss: 0.37763917446136475\n",
      "Epoch: 136 Loss: 0.10044410079717636\n",
      "Epoch: 137 Loss: 0.3700054883956909\n",
      "Epoch: 138 Loss: 0.114190474152565\n",
      "Epoch: 139 Loss: 0.11919587105512619\n",
      "Epoch: 140 Loss: 0.13870397210121155\n",
      "Epoch: 141 Loss: 0.22419825196266174\n",
      "Epoch: 142 Loss: 0.1524760127067566\n",
      "Epoch: 143 Loss: 0.14869026839733124\n",
      "Epoch: 144 Loss: 0.28364264965057373\n",
      "Epoch: 145 Loss: 0.2175828218460083\n",
      "Epoch: 146 Loss: 0.11153798550367355\n",
      "Epoch: 147 Loss: 0.09263607859611511\n",
      "Epoch: 148 Loss: 0.06912873685359955\n",
      "Epoch: 149 Loss: 0.10982845723628998\n",
      "Epoch: 150 Loss: 0.10359946638345718\n",
      "Epoch: 151 Loss: 0.29934829473495483\n",
      "Epoch: 152 Loss: 0.268585205078125\n",
      "Epoch: 153 Loss: 0.07164045423269272\n",
      "Epoch: 154 Loss: 0.14713795483112335\n",
      "Epoch: 155 Loss: 0.066266268491745\n",
      "Epoch: 156 Loss: 0.09287369251251221\n",
      "Epoch: 157 Loss: 0.07251463830471039\n",
      "Epoch: 158 Loss: 0.10648007690906525\n",
      "Epoch: 159 Loss: 0.091677725315094\n",
      "Epoch: 160 Loss: 0.19520676136016846\n",
      "Epoch: 161 Loss: 0.05590621381998062\n",
      "Epoch: 162 Loss: 0.07787155359983444\n",
      "Epoch: 163 Loss: 0.12782934308052063\n",
      "Epoch: 164 Loss: 0.334028959274292\n",
      "Epoch: 165 Loss: 0.0822150781750679\n",
      "Epoch: 166 Loss: 0.05414698272943497\n",
      "Epoch: 167 Loss: 0.09925507009029388\n",
      "Epoch: 168 Loss: 0.16240207850933075\n",
      "Epoch: 169 Loss: 0.07837046682834625\n",
      "Epoch: 170 Loss: 0.05341144651174545\n",
      "Epoch: 171 Loss: 0.20461805164813995\n",
      "Epoch: 172 Loss: 0.06420958042144775\n",
      "Epoch: 173 Loss: 0.13329999148845673\n",
      "Epoch: 174 Loss: 0.16849951446056366\n",
      "Epoch: 175 Loss: 0.13007184863090515\n",
      "Epoch: 176 Loss: 0.7963739633560181\n",
      "Epoch: 177 Loss: 0.0954313576221466\n",
      "Epoch: 178 Loss: 0.1575300693511963\n",
      "Epoch: 179 Loss: 0.07111487537622452\n",
      "Epoch: 180 Loss: 0.10285550355911255\n",
      "Epoch: 181 Loss: 0.08428982645273209\n",
      "Epoch: 182 Loss: 0.051896803081035614\n",
      "Epoch: 183 Loss: 0.13082514703273773\n",
      "Epoch: 184 Loss: 0.1252330243587494\n",
      "Epoch: 185 Loss: 0.07510840892791748\n",
      "Epoch: 186 Loss: 0.07107841968536377\n",
      "Epoch: 187 Loss: 0.13059024512767792\n",
      "Epoch: 188 Loss: 0.060901861637830734\n",
      "Epoch: 189 Loss: 0.2467985600233078\n",
      "Epoch: 190 Loss: 0.3365345299243927\n",
      "Epoch: 191 Loss: 0.05187482014298439\n",
      "Epoch: 192 Loss: 0.1331777572631836\n",
      "Epoch: 193 Loss: 0.09848545491695404\n",
      "Epoch: 194 Loss: 0.17468944191932678\n",
      "Epoch: 195 Loss: 0.05147882178425789\n",
      "Epoch: 196 Loss: 0.07365994900465012\n",
      "Epoch: 197 Loss: 0.15608417987823486\n",
      "Epoch: 198 Loss: 0.29379236698150635\n",
      "Epoch: 199 Loss: 0.19130469858646393\n",
      "Epoch: 200 Loss: 0.27466881275177\n",
      "Epoch: 201 Loss: 0.17466725409030914\n",
      "Epoch: 202 Loss: 0.08768186718225479\n",
      "Epoch: 203 Loss: 0.18852488696575165\n",
      "Epoch: 204 Loss: 0.14438240230083466\n",
      "Epoch: 205 Loss: 0.07797276228666306\n",
      "Epoch: 206 Loss: 0.040394969284534454\n",
      "Epoch: 207 Loss: 0.08762866258621216\n",
      "Epoch: 208 Loss: 0.11557896435260773\n",
      "Epoch: 209 Loss: 0.07428064942359924\n",
      "Epoch: 210 Loss: 0.10717689990997314\n",
      "Epoch: 211 Loss: 0.08657670021057129\n",
      "Epoch: 212 Loss: 0.03672139719128609\n",
      "Epoch: 213 Loss: 0.16245320439338684\n",
      "Epoch: 214 Loss: 0.22285142540931702\n",
      "Epoch: 215 Loss: 0.08925101906061172\n",
      "Epoch: 216 Loss: 0.14505860209465027\n",
      "Epoch: 217 Loss: 0.12438427656888962\n",
      "Epoch: 218 Loss: 0.08453361690044403\n",
      "Epoch: 219 Loss: 0.116754911839962\n",
      "Epoch: 220 Loss: 0.07444868236780167\n",
      "Epoch: 221 Loss: 0.15992490947246552\n",
      "Epoch: 222 Loss: 0.08212251961231232\n",
      "Epoch: 223 Loss: 0.07399175316095352\n",
      "Epoch: 224 Loss: 0.1899680644273758\n",
      "Epoch: 225 Loss: 0.18747133016586304\n",
      "Epoch: 226 Loss: 0.8720711469650269\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 227 Loss: 0.2784438133239746\n",
      "Epoch: 228 Loss: 0.3100499212741852\n",
      "Epoch: 229 Loss: 0.09072602540254593\n",
      "Epoch: 230 Loss: 0.055957213044166565\n",
      "Epoch: 231 Loss: 0.2141280323266983\n",
      "Epoch: 232 Loss: 0.10581658035516739\n",
      "Epoch: 233 Loss: 0.32085031270980835\n",
      "Epoch: 234 Loss: 0.05608717352151871\n",
      "Epoch: 235 Loss: 0.06221714988350868\n",
      "Epoch: 236 Loss: 0.03869754076004028\n",
      "Epoch: 237 Loss: 0.06510577350854874\n",
      "Epoch: 238 Loss: 0.13608062267303467\n",
      "Epoch: 239 Loss: 0.10892745107412338\n",
      "Epoch: 240 Loss: 0.12123025208711624\n",
      "Epoch: 241 Loss: 0.04688003659248352\n",
      "Epoch: 242 Loss: 0.07532888650894165\n",
      "Epoch: 243 Loss: 0.04867933318018913\n",
      "Epoch: 244 Loss: 0.056502945721149445\n",
      "Epoch: 245 Loss: 0.07799549400806427\n",
      "Epoch: 246 Loss: 0.24214661121368408\n",
      "Epoch: 247 Loss: 0.07773339748382568\n",
      "Epoch: 248 Loss: 0.07261377573013306\n",
      "Epoch: 249 Loss: 0.06032893434166908\n",
      "Epoch: 250 Loss: 0.20181727409362793\n",
      "Epoch: 251 Loss: 0.10036525130271912\n",
      "Epoch: 252 Loss: 0.07358869910240173\n",
      "Epoch: 253 Loss: 0.06039043888449669\n",
      "Epoch: 254 Loss: 0.18907800316810608\n",
      "Epoch: 255 Loss: 0.05245348811149597\n",
      "Epoch: 256 Loss: 0.25794050097465515\n",
      "Epoch: 257 Loss: 0.14009670913219452\n",
      "Epoch: 258 Loss: 0.1636333018541336\n",
      "Epoch: 259 Loss: 0.12142452597618103\n",
      "Epoch: 260 Loss: 0.035904355347156525\n",
      "Epoch: 261 Loss: 0.14910835027694702\n",
      "Epoch: 262 Loss: 0.1116706132888794\n",
      "Epoch: 263 Loss: 0.04613358899950981\n",
      "Epoch: 264 Loss: 0.05225714296102524\n",
      "Epoch: 265 Loss: 0.10803055018186569\n",
      "Epoch: 266 Loss: 0.08076462894678116\n",
      "Epoch: 267 Loss: 0.029085882008075714\n",
      "Epoch: 268 Loss: 0.14393718540668488\n",
      "Epoch: 269 Loss: 0.06976326555013657\n",
      "Epoch: 270 Loss: 0.08949652314186096\n",
      "Epoch: 271 Loss: 0.15103457868099213\n",
      "Epoch: 272 Loss: 0.1538737416267395\n",
      "Epoch: 273 Loss: 0.04759112372994423\n",
      "Epoch: 274 Loss: 0.09150038659572601\n",
      "Epoch: 275 Loss: 0.045646339654922485\n",
      "Epoch: 276 Loss: 0.05011016130447388\n",
      "Epoch: 277 Loss: 0.08103583753108978\n",
      "Epoch: 278 Loss: 0.2038256824016571\n",
      "Epoch: 279 Loss: 0.11885438114404678\n",
      "Epoch: 280 Loss: 0.09900817275047302\n",
      "Epoch: 281 Loss: 0.04335826635360718\n",
      "Epoch: 282 Loss: 0.08634951710700989\n",
      "Epoch: 283 Loss: 0.08407577127218246\n",
      "Epoch: 284 Loss: 0.12087869644165039\n",
      "Epoch: 285 Loss: 0.09374380856752396\n",
      "Epoch: 286 Loss: 0.08583084493875504\n",
      "Epoch: 287 Loss: 0.07486657798290253\n",
      "Epoch: 288 Loss: 0.1107594445347786\n",
      "Epoch: 289 Loss: 0.15842421352863312\n",
      "Epoch: 290 Loss: 0.15092137455940247\n",
      "Epoch: 291 Loss: 0.07923557609319687\n",
      "Epoch: 292 Loss: 0.18398211896419525\n",
      "Epoch: 293 Loss: 0.11375199258327484\n",
      "Epoch: 294 Loss: 0.1001119539141655\n",
      "Epoch: 295 Loss: 0.0355864055454731\n",
      "Epoch: 296 Loss: 0.15062031149864197\n",
      "Epoch: 297 Loss: 0.12317676097154617\n",
      "Epoch: 298 Loss: 0.15648609399795532\n",
      "Epoch: 299 Loss: 0.10647441446781158\n",
      "Epoch: 300 Loss: 0.061458997428417206\n",
      "Epoch: 301 Loss: 0.26088666915893555\n",
      "Epoch: 302 Loss: 0.0921524241566658\n",
      "Epoch: 303 Loss: 0.1416257917881012\n",
      "Epoch: 304 Loss: 0.12838046252727509\n",
      "Epoch: 305 Loss: 0.11653623729944229\n",
      "Epoch: 306 Loss: 0.031567543745040894\n",
      "Epoch: 307 Loss: 0.14580819010734558\n",
      "Epoch: 308 Loss: 0.10618005692958832\n",
      "Epoch: 309 Loss: 0.10555346310138702\n",
      "Epoch: 310 Loss: 0.11446404457092285\n",
      "Epoch: 311 Loss: 0.05681469663977623\n",
      "Epoch: 312 Loss: 0.09020321071147919\n",
      "Epoch: 313 Loss: 0.16456636786460876\n",
      "Epoch: 314 Loss: 0.11211137473583221\n",
      "Epoch: 315 Loss: 0.1584128439426422\n",
      "Epoch: 316 Loss: 0.06825565546751022\n",
      "Epoch: 317 Loss: 0.12024178355932236\n",
      "Epoch: 318 Loss: 0.07568371295928955\n",
      "Epoch: 319 Loss: 0.15725409984588623\n",
      "Epoch: 320 Loss: 0.14179062843322754\n",
      "Epoch: 321 Loss: 0.05743465945124626\n",
      "Epoch: 322 Loss: 0.17421306669712067\n",
      "Epoch: 323 Loss: 0.11741749942302704\n",
      "Epoch: 324 Loss: 0.07253682613372803\n",
      "Epoch: 325 Loss: 0.17129430174827576\n",
      "Epoch: 326 Loss: 0.2728540599346161\n",
      "Epoch: 327 Loss: 0.11840197443962097\n",
      "Epoch: 328 Loss: 0.08838514983654022\n",
      "Epoch: 329 Loss: 0.12366995215415955\n",
      "Epoch: 330 Loss: 0.11958420276641846\n",
      "Epoch: 331 Loss: 0.09117000550031662\n",
      "Epoch: 332 Loss: 0.0732877254486084\n",
      "Epoch: 333 Loss: 0.07752706855535507\n",
      "Epoch: 334 Loss: 0.13619554042816162\n",
      "Epoch: 335 Loss: 0.05174810439348221\n",
      "Epoch: 336 Loss: 0.1220778077840805\n",
      "Epoch: 337 Loss: 0.0582493431866169\n",
      "Epoch: 338 Loss: 0.3443983793258667\n",
      "Epoch: 339 Loss: 0.12118618190288544\n",
      "Epoch: 340 Loss: 0.06044496223330498\n",
      "Epoch: 341 Loss: 0.08744288235902786\n",
      "Epoch: 342 Loss: 0.17723017930984497\n",
      "Epoch: 343 Loss: 0.08727200329303741\n",
      "Epoch: 344 Loss: 0.04547407850623131\n",
      "Epoch: 345 Loss: 0.07396537810564041\n",
      "Epoch: 346 Loss: 0.10157898813486099\n",
      "Epoch: 347 Loss: 0.15769389271736145\n",
      "Epoch: 348 Loss: 0.07576748728752136\n",
      "Epoch: 349 Loss: 0.16156642138957977\n",
      "Epoch: 350 Loss: 0.04010384902358055\n",
      "Epoch: 351 Loss: 0.039874039590358734\n",
      "Epoch: 352 Loss: 0.1217818334698677\n",
      "Epoch: 353 Loss: 0.08422313630580902\n",
      "Epoch: 354 Loss: 0.06665980815887451\n",
      "Epoch: 355 Loss: 0.1260995864868164\n",
      "Epoch: 356 Loss: 0.09626352041959763\n",
      "Epoch: 357 Loss: 0.1487656980752945\n",
      "Epoch: 358 Loss: 0.13738951086997986\n",
      "Epoch: 359 Loss: 0.11436797678470612\n",
      "Epoch: 360 Loss: 0.1066017597913742\n",
      "Epoch: 361 Loss: 0.06372342258691788\n",
      "Epoch: 362 Loss: 0.06378108263015747\n",
      "Epoch: 363 Loss: 0.16851834952831268\n",
      "Epoch: 364 Loss: 0.07317283749580383\n",
      "Epoch: 365 Loss: 0.12049210071563721\n",
      "Epoch: 366 Loss: 0.07907254993915558\n",
      "Epoch: 367 Loss: 0.07621242105960846\n",
      "Epoch: 368 Loss: 0.10850724577903748\n",
      "Epoch: 369 Loss: 0.05594950541853905\n",
      "Epoch: 370 Loss: 0.09741714596748352\n",
      "Epoch: 371 Loss: 0.16035525500774384\n",
      "Epoch: 372 Loss: 0.09236805886030197\n",
      "Epoch: 373 Loss: 0.05964374542236328\n",
      "Epoch: 374 Loss: 0.0510224923491478\n",
      "Epoch: 375 Loss: 0.08351214975118637\n",
      "Epoch: 376 Loss: 0.06320939213037491\n",
      "Epoch: 377 Loss: 0.06914669275283813\n",
      "Epoch: 378 Loss: 0.09309999644756317\n",
      "Epoch: 379 Loss: 0.0678267627954483\n",
      "Epoch: 380 Loss: 0.1576623022556305\n",
      "Epoch: 381 Loss: 0.10678903013467789\n",
      "Epoch: 382 Loss: 0.05070004612207413\n",
      "Epoch: 383 Loss: 0.08221931010484695\n",
      "Epoch: 384 Loss: 0.0853903740644455\n",
      "Epoch: 385 Loss: 0.09990181028842926\n",
      "Epoch: 386 Loss: 0.03478269651532173\n",
      "Epoch: 387 Loss: 0.16626836359500885\n",
      "Epoch: 388 Loss: 0.13182741403579712\n",
      "Epoch: 389 Loss: 0.03324994444847107\n",
      "Epoch: 390 Loss: 0.0670621320605278\n",
      "Epoch: 391 Loss: 0.08807738125324249\n",
      "Epoch: 392 Loss: 0.15938705205917358\n",
      "Epoch: 393 Loss: 0.06035783886909485\n",
      "Epoch: 394 Loss: 0.15000785887241364\n",
      "Epoch: 395 Loss: 0.06383713334798813\n",
      "Epoch: 396 Loss: 0.09486798942089081\n",
      "Epoch: 397 Loss: 0.12214958667755127\n",
      "Epoch: 398 Loss: 0.1107916608452797\n",
      "Epoch: 399 Loss: 0.10084646940231323\n",
      "Epoch: 400 Loss: 0.08048371225595474\n",
      "Epoch: 401 Loss: 0.07964307069778442\n",
      "Epoch: 402 Loss: 0.08626475185155869\n",
      "Epoch: 403 Loss: 0.08606114238500595\n",
      "Epoch: 404 Loss: 0.08006221801042557\n",
      "Epoch: 405 Loss: 0.09851991385221481\n",
      "Epoch: 406 Loss: 0.15611577033996582\n",
      "Epoch: 407 Loss: 0.09273409843444824\n",
      "Epoch: 408 Loss: 0.1367412805557251\n",
      "Epoch: 409 Loss: 0.03614777699112892\n",
      "Epoch: 410 Loss: 0.04276207089424133\n",
      "Epoch: 411 Loss: 0.06871939450502396\n",
      "Epoch: 412 Loss: 0.13611453771591187\n",
      "Epoch: 413 Loss: 0.0786581039428711\n",
      "Epoch: 414 Loss: 0.10419073700904846\n",
      "Epoch: 415 Loss: 0.11309210956096649\n",
      "Epoch: 416 Loss: 0.19744282960891724\n",
      "Epoch: 417 Loss: 0.06517423689365387\n",
      "Epoch: 418 Loss: 0.05220847576856613\n",
      "Epoch: 419 Loss: 0.11848558485507965\n",
      "Epoch: 420 Loss: 0.0727103054523468\n",
      "Epoch: 421 Loss: 0.03193729370832443\n",
      "Epoch: 422 Loss: 0.12330350279808044\n",
      "Epoch: 423 Loss: 0.13131730258464813\n",
      "Epoch: 424 Loss: 0.06400715559720993\n",
      "Epoch: 425 Loss: 0.06178592890501022\n",
      "Epoch: 426 Loss: 0.08972947299480438\n",
      "Epoch: 427 Loss: 0.1058976799249649\n",
      "Epoch: 428 Loss: 0.07714688777923584\n",
      "Epoch: 429 Loss: 0.10083001852035522\n",
      "Epoch: 430 Loss: 0.17063269019126892\n",
      "Epoch: 431 Loss: 0.10240305960178375\n",
      "Epoch: 432 Loss: 0.0762917622923851\n",
      "Epoch: 433 Loss: 0.08847401291131973\n",
      "Epoch: 434 Loss: 0.0746069848537445\n",
      "Epoch: 435 Loss: 0.0655008852481842\n",
      "Epoch: 436 Loss: 0.09649429470300674\n",
      "Epoch: 437 Loss: 0.18017248809337616\n",
      "Epoch: 438 Loss: 0.0794903039932251\n",
      "Epoch: 439 Loss: 0.1343931406736374\n",
      "Epoch: 440 Loss: 0.059401966631412506\n",
      "Epoch: 441 Loss: 0.05813589319586754\n",
      "Epoch: 442 Loss: 0.09011167287826538\n",
      "Epoch: 443 Loss: 0.03259579837322235\n",
      "Epoch: 444 Loss: 0.09169383347034454\n",
      "Epoch: 445 Loss: 0.10101835429668427\n",
      "Epoch: 446 Loss: 0.1294061243534088\n",
      "Epoch: 447 Loss: 0.03713741898536682\n",
      "Epoch: 448 Loss: 0.16517961025238037\n",
      "Epoch: 449 Loss: 0.11099331080913544\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 450 Loss: 0.03181568905711174\n",
      "Epoch: 451 Loss: 0.09731966257095337\n",
      "Epoch: 452 Loss: 0.06864289194345474\n",
      "Epoch: 453 Loss: 0.1414126604795456\n",
      "Epoch: 454 Loss: 0.06719623506069183\n",
      "Epoch: 455 Loss: 0.05435708910226822\n",
      "Epoch: 456 Loss: 0.04823656380176544\n",
      "Epoch: 457 Loss: 0.1093800812959671\n",
      "Epoch: 458 Loss: 0.12525223195552826\n",
      "Epoch: 459 Loss: 0.2201295644044876\n",
      "Epoch: 460 Loss: 0.09454910457134247\n",
      "Epoch: 461 Loss: 0.16972461342811584\n",
      "Epoch: 462 Loss: 0.14259612560272217\n",
      "Epoch: 463 Loss: 0.07815401256084442\n",
      "Epoch: 464 Loss: 0.07148154079914093\n",
      "Epoch: 465 Loss: 0.09740688651800156\n",
      "Epoch: 466 Loss: 0.17949381470680237\n",
      "Epoch: 467 Loss: 0.06175672262907028\n",
      "Epoch: 468 Loss: 0.14970022439956665\n",
      "Epoch: 469 Loss: 0.04045594111084938\n",
      "Epoch: 470 Loss: 0.08938885480165482\n",
      "Epoch: 471 Loss: 0.08064761012792587\n",
      "Epoch: 472 Loss: 0.04742131009697914\n",
      "Epoch: 473 Loss: 0.09566196799278259\n",
      "Epoch: 474 Loss: 0.08935022354125977\n",
      "Epoch: 475 Loss: 0.08597540855407715\n",
      "Epoch: 476 Loss: 0.0822247862815857\n",
      "Epoch: 477 Loss: 0.09018383920192719\n",
      "Epoch: 478 Loss: 0.19989454746246338\n",
      "Epoch: 479 Loss: 0.07904355227947235\n",
      "Epoch: 480 Loss: 0.10094183683395386\n",
      "Epoch: 481 Loss: 0.0671146959066391\n",
      "Epoch: 482 Loss: 0.10464854538440704\n",
      "Epoch: 483 Loss: 0.10474860668182373\n",
      "Epoch: 484 Loss: 0.06401649862527847\n",
      "Epoch: 485 Loss: 0.12100204080343246\n",
      "Epoch: 486 Loss: 0.06858395040035248\n",
      "Epoch: 487 Loss: 0.09085389971733093\n",
      "Epoch: 488 Loss: 0.08342303335666656\n",
      "Epoch: 489 Loss: 0.06790457665920258\n",
      "Epoch: 490 Loss: 0.03986039757728577\n",
      "Epoch: 491 Loss: 0.04797704890370369\n",
      "Epoch: 492 Loss: 0.038093529641628265\n",
      "Epoch: 493 Loss: 0.13043490052223206\n",
      "Epoch: 494 Loss: 0.11325583606958389\n",
      "Epoch: 495 Loss: 0.07058783620595932\n",
      "Epoch: 496 Loss: 0.06946185231208801\n",
      "Epoch: 497 Loss: 0.10754407197237015\n",
      "Epoch: 498 Loss: 0.14243225753307343\n",
      "Epoch: 499 Loss: 0.04234325513243675\n",
      "Epoch: 500 Loss: 0.09915313869714737\n",
      "Epoch: 501 Loss: 0.11528746038675308\n",
      "Epoch: 502 Loss: 0.06588578224182129\n",
      "Epoch: 503 Loss: 0.05991591513156891\n",
      "Epoch: 504 Loss: 0.11554601788520813\n",
      "Epoch: 505 Loss: 0.07124485075473785\n",
      "Epoch: 506 Loss: 0.10489847511053085\n",
      "Epoch: 507 Loss: 0.11620032787322998\n",
      "Epoch: 508 Loss: 0.11659431457519531\n",
      "Epoch: 509 Loss: 0.08682700991630554\n",
      "Epoch: 510 Loss: 0.1065683662891388\n",
      "Epoch: 511 Loss: 0.12636804580688477\n",
      "Epoch: 512 Loss: 0.16030378639698029\n",
      "Epoch: 513 Loss: 0.1599622666835785\n",
      "Epoch: 514 Loss: 0.0969410240650177\n",
      "Epoch: 515 Loss: 0.055826880037784576\n",
      "Epoch: 516 Loss: 0.04391586780548096\n",
      "Epoch: 517 Loss: 0.13382861018180847\n",
      "Epoch: 518 Loss: 0.07197536528110504\n",
      "Epoch: 519 Loss: 0.03947225213050842\n",
      "Epoch: 520 Loss: 0.023798814043402672\n",
      "Epoch: 521 Loss: 0.05678713321685791\n",
      "Epoch: 522 Loss: 0.21157287061214447\n",
      "Epoch: 523 Loss: 0.12735794484615326\n",
      "Epoch: 524 Loss: 0.08373644202947617\n",
      "Epoch: 525 Loss: 0.06506337225437164\n",
      "Epoch: 526 Loss: 0.1608065664768219\n",
      "Epoch: 527 Loss: 0.08364309370517731\n",
      "Epoch: 528 Loss: 0.02670384757220745\n",
      "Epoch: 529 Loss: 0.08142296969890594\n",
      "Epoch: 530 Loss: 0.06575266271829605\n",
      "Epoch: 531 Loss: 0.05529705435037613\n",
      "Epoch: 532 Loss: 0.06352221220731735\n",
      "Epoch: 533 Loss: 0.05761367827653885\n",
      "Epoch: 534 Loss: 0.06320584565401077\n",
      "Epoch: 535 Loss: 0.06653828918933868\n",
      "Epoch: 536 Loss: 0.05561539903283119\n",
      "Epoch: 537 Loss: 0.1967926323413849\n",
      "Epoch: 538 Loss: 0.09039882570505142\n",
      "Epoch: 539 Loss: 0.07034454494714737\n",
      "Epoch: 540 Loss: 0.07408127188682556\n",
      "Epoch: 541 Loss: 0.06182117387652397\n",
      "Epoch: 542 Loss: 0.07566459476947784\n",
      "Epoch: 543 Loss: 0.2144886702299118\n",
      "Epoch: 544 Loss: 0.10951265692710876\n",
      "Epoch: 545 Loss: 0.14279107749462128\n",
      "Epoch: 546 Loss: 0.11169620603322983\n",
      "Epoch: 547 Loss: 0.22012153267860413\n",
      "Epoch: 548 Loss: 0.09322189539670944\n",
      "Epoch: 549 Loss: 0.1336272805929184\n",
      "Epoch: 550 Loss: 0.06762911379337311\n",
      "Epoch: 551 Loss: 0.09269014745950699\n",
      "Epoch: 552 Loss: 0.16358131170272827\n",
      "Epoch: 553 Loss: 0.15545246005058289\n",
      "Epoch: 554 Loss: 0.15952444076538086\n",
      "Epoch: 555 Loss: 0.0892503634095192\n",
      "Epoch: 556 Loss: 0.08186998963356018\n",
      "Epoch: 557 Loss: 0.05473170801997185\n",
      "Epoch: 558 Loss: 0.10673306882381439\n",
      "Epoch: 559 Loss: 0.06300538778305054\n",
      "Epoch: 560 Loss: 0.08095090091228485\n",
      "Epoch: 561 Loss: 0.17397651076316833\n",
      "Epoch: 562 Loss: 0.08958030492067337\n",
      "Epoch: 563 Loss: 0.10247569531202316\n",
      "Epoch: 564 Loss: 0.05254596844315529\n",
      "Epoch: 565 Loss: 0.0753842443227768\n",
      "Epoch: 566 Loss: 0.08098151534795761\n",
      "Epoch: 567 Loss: 0.04149813577532768\n",
      "Epoch: 568 Loss: 0.05395576357841492\n",
      "Epoch: 569 Loss: 0.08359696716070175\n",
      "Epoch: 570 Loss: 0.058217816054821014\n",
      "Epoch: 571 Loss: 0.08325469493865967\n",
      "Epoch: 572 Loss: 0.07512509077787399\n",
      "Epoch: 573 Loss: 0.047568388283252716\n",
      "Epoch: 574 Loss: 0.06641478836536407\n",
      "Epoch: 575 Loss: 0.03684964030981064\n",
      "Epoch: 576 Loss: 0.09653537720441818\n",
      "Epoch: 577 Loss: 0.07455634325742722\n",
      "Epoch: 578 Loss: 0.04047972708940506\n",
      "Epoch: 579 Loss: 0.04923980310559273\n",
      "Epoch: 580 Loss: 0.08712631464004517\n",
      "Epoch: 581 Loss: 0.07545658946037292\n",
      "Epoch: 582 Loss: 0.0799085944890976\n",
      "Epoch: 583 Loss: 0.03407857567071915\n",
      "Epoch: 584 Loss: 0.05201142653822899\n",
      "Epoch: 585 Loss: 0.04425927996635437\n",
      "Epoch: 586 Loss: 0.06076689809560776\n",
      "Epoch: 587 Loss: 0.10573218762874603\n",
      "Epoch: 588 Loss: 0.07181668281555176\n",
      "Epoch: 589 Loss: 0.08413032442331314\n",
      "Epoch: 590 Loss: 0.08485859632492065\n",
      "Epoch: 591 Loss: 0.057392362505197525\n",
      "Epoch: 592 Loss: 0.06274062395095825\n",
      "Epoch: 593 Loss: 0.049898311495780945\n",
      "Epoch: 594 Loss: 0.06665866822004318\n",
      "Epoch: 595 Loss: 0.04557940736413002\n",
      "Epoch: 596 Loss: 0.07223384827375412\n",
      "Epoch: 597 Loss: 0.03307294100522995\n",
      "Epoch: 598 Loss: 0.0509343147277832\n",
      "Epoch: 599 Loss: 0.07954328507184982\n",
      "Epoch: 600 Loss: 0.05845627188682556\n",
      "Epoch: 601 Loss: 0.08983203023672104\n",
      "Epoch: 602 Loss: 0.11696889251470566\n",
      "Epoch: 603 Loss: 0.05196750536561012\n",
      "Epoch: 604 Loss: 0.04751857742667198\n",
      "Epoch: 605 Loss: 0.08115000277757645\n",
      "Epoch: 606 Loss: 0.04945196583867073\n",
      "Epoch: 607 Loss: 0.08144226670265198\n",
      "Epoch: 608 Loss: 0.059658292680978775\n",
      "Epoch: 609 Loss: 0.051489509642124176\n",
      "Epoch: 610 Loss: 0.09920444339513779\n",
      "Epoch: 611 Loss: 0.04217934608459473\n",
      "Epoch: 612 Loss: 0.07479702681303024\n",
      "Epoch: 613 Loss: 0.0748070478439331\n",
      "Epoch: 614 Loss: 0.04095839709043503\n",
      "Epoch: 615 Loss: 0.09716112166643143\n",
      "Epoch: 616 Loss: 0.04598889872431755\n",
      "Epoch: 617 Loss: 0.05456475913524628\n",
      "Epoch: 618 Loss: 0.034815989434719086\n",
      "Epoch: 619 Loss: 0.029027238488197327\n",
      "Epoch: 620 Loss: 0.07019741088151932\n",
      "Epoch: 621 Loss: 0.047147177159786224\n",
      "Epoch: 622 Loss: 0.03135089576244354\n",
      "Epoch: 623 Loss: 0.12628886103630066\n",
      "Epoch: 624 Loss: 0.06002918258309364\n",
      "Epoch: 625 Loss: 0.1821402907371521\n",
      "Epoch: 626 Loss: 0.043084681034088135\n",
      "Epoch: 627 Loss: 0.08645880222320557\n",
      "Epoch: 628 Loss: 0.12398480623960495\n",
      "Epoch: 629 Loss: 0.07907599210739136\n",
      "Epoch: 630 Loss: 0.0656076967716217\n",
      "Epoch: 631 Loss: 0.10206443071365356\n",
      "Epoch: 632 Loss: 0.03439326956868172\n",
      "Epoch: 633 Loss: 0.04525447264313698\n",
      "Epoch: 634 Loss: 0.08997821062803268\n",
      "Epoch: 635 Loss: 0.04268432408571243\n",
      "Epoch: 636 Loss: 0.1300756186246872\n",
      "Epoch: 637 Loss: 0.06994897872209549\n",
      "Epoch: 638 Loss: 0.2073337733745575\n",
      "Epoch: 639 Loss: 0.024522237479686737\n",
      "Epoch: 640 Loss: 0.038049716502428055\n",
      "Epoch: 641 Loss: 0.04923052713274956\n",
      "Epoch: 642 Loss: 0.07286518812179565\n",
      "Epoch: 643 Loss: 0.7530897855758667\n",
      "Epoch: 644 Loss: 0.08572232723236084\n",
      "Epoch: 645 Loss: 0.03376093506813049\n",
      "Epoch: 646 Loss: 0.1145659014582634\n",
      "Epoch: 647 Loss: 0.05345407873392105\n",
      "Epoch: 648 Loss: 0.04258362948894501\n",
      "Epoch: 649 Loss: 0.14107045531272888\n",
      "Epoch: 650 Loss: 0.14094436168670654\n",
      "Epoch: 651 Loss: 0.10147158801555634\n",
      "Epoch: 652 Loss: 0.1424795687198639\n",
      "Epoch: 653 Loss: 0.1873631626367569\n",
      "Epoch: 654 Loss: 0.07301189005374908\n",
      "Epoch: 655 Loss: 0.12246470898389816\n",
      "Epoch: 656 Loss: 0.1460714340209961\n",
      "Epoch: 657 Loss: 0.08089964091777802\n",
      "Epoch: 658 Loss: 0.058433935046195984\n",
      "Epoch: 659 Loss: 0.06456299126148224\n",
      "Epoch: 660 Loss: 0.029463844373822212\n",
      "Epoch: 661 Loss: 0.049593694508075714\n",
      "Epoch: 662 Loss: 0.07698452472686768\n",
      "Epoch: 663 Loss: 0.10326209664344788\n",
      "Epoch: 664 Loss: 0.044125765562057495\n",
      "Epoch: 665 Loss: 0.11679495871067047\n",
      "Epoch: 666 Loss: 0.06414854526519775\n",
      "Epoch: 667 Loss: 0.09094875305891037\n",
      "Epoch: 668 Loss: 0.0811520665884018\n",
      "Epoch: 669 Loss: 0.07848547399044037\n",
      "Epoch: 670 Loss: 0.07986635714769363\n",
      "Epoch: 671 Loss: 0.06871424615383148\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 672 Loss: 0.06886730343103409\n",
      "Epoch: 673 Loss: 0.1828644573688507\n",
      "Epoch: 674 Loss: 0.06318054348230362\n",
      "Epoch: 675 Loss: 0.07481542974710464\n",
      "Epoch: 676 Loss: 0.10125353187322617\n",
      "Epoch: 677 Loss: 0.06143190339207649\n",
      "Epoch: 678 Loss: 0.17438945174217224\n",
      "Epoch: 679 Loss: 0.18221332132816315\n",
      "Epoch: 680 Loss: 0.07644891738891602\n",
      "Epoch: 681 Loss: 0.034269969910383224\n",
      "Epoch: 682 Loss: 0.05051259323954582\n",
      "Epoch: 683 Loss: 0.07928428053855896\n",
      "Epoch: 684 Loss: 0.10972879827022552\n",
      "Epoch: 685 Loss: 0.09287287294864655\n",
      "Epoch: 686 Loss: 0.054813843220472336\n",
      "Epoch: 687 Loss: 0.04587259143590927\n",
      "Epoch: 688 Loss: 0.04909636080265045\n",
      "Epoch: 689 Loss: 0.044456847012043\n",
      "Epoch: 690 Loss: 0.05293724685907364\n",
      "Epoch: 691 Loss: 0.06599404662847519\n",
      "Epoch: 692 Loss: 0.0872536301612854\n",
      "Epoch: 693 Loss: 0.09475407004356384\n",
      "Epoch: 694 Loss: 0.06766457110643387\n",
      "Epoch: 695 Loss: 0.09704149514436722\n",
      "Epoch: 696 Loss: 0.06383312493562698\n",
      "Epoch: 697 Loss: 0.03519367799162865\n",
      "Epoch: 698 Loss: 0.06888407468795776\n",
      "Epoch: 699 Loss: 0.09958535432815552\n",
      "Epoch: 700 Loss: 0.03177260234951973\n",
      "Epoch: 701 Loss: 0.04080839455127716\n",
      "Epoch: 702 Loss: 0.04769207537174225\n",
      "Epoch: 703 Loss: 0.12193524092435837\n",
      "Epoch: 704 Loss: 0.03663920611143112\n",
      "Epoch: 705 Loss: 0.05106211453676224\n",
      "Epoch: 706 Loss: 0.08122120052576065\n",
      "Epoch: 707 Loss: 0.05655553564429283\n",
      "Epoch: 708 Loss: 0.089870885014534\n",
      "Epoch: 709 Loss: 0.1916181892156601\n",
      "Epoch: 710 Loss: 0.062482357025146484\n",
      "Epoch: 711 Loss: 0.15067721903324127\n",
      "Epoch: 712 Loss: 0.0739620178937912\n",
      "Epoch: 713 Loss: 0.030234411358833313\n",
      "Epoch: 714 Loss: 0.059725530445575714\n",
      "Epoch: 715 Loss: 0.05761323869228363\n",
      "Epoch: 716 Loss: 0.056882891803979874\n",
      "Epoch: 717 Loss: 0.026200629770755768\n",
      "Epoch: 718 Loss: 0.03814763203263283\n",
      "Epoch: 719 Loss: 0.07226593792438507\n",
      "Epoch: 720 Loss: 0.09225001931190491\n",
      "Epoch: 721 Loss: 0.08049090206623077\n",
      "Epoch: 722 Loss: 0.05047323554754257\n",
      "Epoch: 723 Loss: 0.056147076189517975\n",
      "Epoch: 724 Loss: 0.0462360754609108\n",
      "Epoch: 725 Loss: 0.03458412364125252\n",
      "Epoch: 726 Loss: 0.13078118860721588\n",
      "Epoch: 727 Loss: 0.09510371088981628\n",
      "Epoch: 728 Loss: 0.1658669263124466\n",
      "Epoch: 729 Loss: 0.02960021421313286\n",
      "Epoch: 730 Loss: 0.04619155451655388\n",
      "Epoch: 731 Loss: 0.057305432856082916\n",
      "Epoch: 732 Loss: 0.056859090924263\n",
      "Epoch: 733 Loss: 0.033939260989427567\n",
      "Epoch: 734 Loss: 0.05834145471453667\n",
      "Epoch: 735 Loss: 0.15706463158130646\n",
      "Epoch: 736 Loss: 0.04561205953359604\n",
      "Epoch: 737 Loss: 0.04475640133023262\n",
      "Epoch: 738 Loss: 0.062431901693344116\n",
      "Epoch: 739 Loss: 0.05004291981458664\n",
      "Epoch: 740 Loss: 0.05596641078591347\n",
      "Epoch: 741 Loss: 0.07271680980920792\n",
      "Epoch: 742 Loss: 0.09331830590963364\n",
      "Epoch: 743 Loss: 0.10466131567955017\n",
      "Epoch: 744 Loss: 0.07582557946443558\n",
      "Epoch: 745 Loss: 0.06805527210235596\n",
      "Epoch: 746 Loss: 0.06853312999010086\n",
      "Epoch: 747 Loss: 0.04355396702885628\n",
      "Epoch: 748 Loss: 0.052518393844366074\n",
      "Epoch: 749 Loss: 0.06933184713125229\n",
      "Epoch: 750 Loss: 0.1651686280965805\n",
      "Epoch: 751 Loss: 0.041152048856019974\n",
      "Epoch: 752 Loss: 0.0723564624786377\n",
      "Epoch: 753 Loss: 0.061824485659599304\n",
      "Epoch: 754 Loss: 0.11003942042589188\n",
      "Epoch: 755 Loss: 0.10439048707485199\n",
      "Epoch: 756 Loss: 0.02788672037422657\n",
      "Epoch: 757 Loss: 0.11231739819049835\n",
      "Epoch: 758 Loss: 0.04380454868078232\n",
      "Epoch: 759 Loss: 0.062127675861120224\n",
      "Epoch: 760 Loss: 0.0607205331325531\n",
      "Epoch: 761 Loss: 0.06412363052368164\n",
      "Epoch: 762 Loss: 0.07579049468040466\n",
      "Epoch: 763 Loss: 0.060903988778591156\n",
      "Epoch: 764 Loss: 0.05245676636695862\n",
      "Epoch: 765 Loss: 0.0989496037364006\n",
      "Epoch: 766 Loss: 0.040149152278900146\n",
      "Epoch: 767 Loss: 0.07405361533164978\n",
      "Epoch: 768 Loss: 0.025115394964814186\n",
      "Epoch: 769 Loss: 0.029368625953793526\n",
      "Epoch: 770 Loss: 0.04985635727643967\n",
      "Epoch: 771 Loss: 0.06245546415448189\n",
      "Epoch: 772 Loss: 0.0441066212952137\n",
      "Epoch: 773 Loss: 0.031049858778715134\n",
      "Epoch: 774 Loss: 0.07339795678853989\n",
      "Epoch: 775 Loss: 0.09359896928071976\n",
      "Epoch: 776 Loss: 0.08459056913852692\n",
      "Epoch: 777 Loss: 0.08006521314382553\n",
      "Epoch: 778 Loss: 0.089089535176754\n",
      "Epoch: 779 Loss: 0.08238998055458069\n",
      "Epoch: 780 Loss: 0.05876327306032181\n",
      "Epoch: 781 Loss: 0.09188751876354218\n",
      "Epoch: 782 Loss: 0.05418096110224724\n",
      "Epoch: 783 Loss: 0.12813584506511688\n",
      "Epoch: 784 Loss: 0.0455874539911747\n",
      "Epoch: 785 Loss: 0.03167147934436798\n",
      "Epoch: 786 Loss: 0.09761656820774078\n",
      "Epoch: 787 Loss: 0.04557725042104721\n",
      "Epoch: 788 Loss: 0.43221578001976013\n",
      "Epoch: 789 Loss: 0.08963309973478317\n",
      "Epoch: 790 Loss: 0.15374352037906647\n",
      "Epoch: 791 Loss: 0.05701855197548866\n",
      "Epoch: 792 Loss: 0.07119516283273697\n",
      "Epoch: 793 Loss: 0.030969690531492233\n",
      "Epoch: 794 Loss: 0.06715643405914307\n",
      "Epoch: 795 Loss: 0.06899397820234299\n",
      "Epoch: 796 Loss: 0.11507894843816757\n",
      "Epoch: 797 Loss: 0.11292529106140137\n",
      "Epoch: 798 Loss: 0.04123435914516449\n",
      "Epoch: 799 Loss: 0.05907437205314636\n",
      "Epoch: 800 Loss: 0.05763256549835205\n",
      "Epoch: 801 Loss: 0.11191584169864655\n",
      "Epoch: 802 Loss: 0.09316813945770264\n",
      "Epoch: 803 Loss: 0.05596742033958435\n",
      "Epoch: 804 Loss: 0.13188424706459045\n",
      "Epoch: 805 Loss: 0.05989791452884674\n",
      "Epoch: 806 Loss: 0.048269160091876984\n",
      "Epoch: 807 Loss: 0.07723146677017212\n",
      "Epoch: 808 Loss: 0.13205339014530182\n",
      "Epoch: 809 Loss: 0.09752564877271652\n",
      "Epoch: 810 Loss: 0.09236571192741394\n",
      "Epoch: 811 Loss: 0.12608195841312408\n",
      "Epoch: 812 Loss: 0.03673179820179939\n",
      "Epoch: 813 Loss: 0.03392742946743965\n",
      "Epoch: 814 Loss: 0.07482285797595978\n",
      "Epoch: 815 Loss: 0.0756668671965599\n",
      "Epoch: 816 Loss: 0.1336609423160553\n",
      "Epoch: 817 Loss: 0.10083012282848358\n",
      "Epoch: 818 Loss: 0.04699714481830597\n",
      "Epoch: 819 Loss: 0.09459507465362549\n",
      "Epoch: 820 Loss: 0.06273628026247025\n",
      "Epoch: 821 Loss: 0.11676639318466187\n",
      "Epoch: 822 Loss: 0.10106652975082397\n",
      "Epoch: 823 Loss: 0.0791071280837059\n",
      "Epoch: 824 Loss: 0.07646499574184418\n",
      "Epoch: 825 Loss: 0.06945629417896271\n",
      "Epoch: 826 Loss: 0.05934533104300499\n",
      "Epoch: 827 Loss: 0.03506823256611824\n",
      "Epoch: 828 Loss: 0.041439883410930634\n",
      "Epoch: 829 Loss: 0.03657473996281624\n",
      "Epoch: 830 Loss: 0.051328033208847046\n",
      "Epoch: 831 Loss: 0.062108226120471954\n",
      "Epoch: 832 Loss: 0.09479933232069016\n",
      "Epoch: 833 Loss: 0.031764738261699677\n",
      "Epoch: 834 Loss: 0.1098865270614624\n",
      "Epoch: 835 Loss: 0.05081281438469887\n",
      "Epoch: 836 Loss: 0.07625782489776611\n",
      "Epoch: 837 Loss: 0.10406061261892319\n",
      "Epoch: 838 Loss: 0.09834155440330505\n",
      "Epoch: 839 Loss: 0.03848470002412796\n",
      "Epoch: 840 Loss: 0.10381878167390823\n",
      "Epoch: 841 Loss: 0.03650469705462456\n",
      "Epoch: 842 Loss: 0.07183367758989334\n",
      "Epoch: 843 Loss: 0.06713274866342545\n",
      "Epoch: 844 Loss: 0.08628972619771957\n",
      "Epoch: 845 Loss: 0.0718122348189354\n",
      "Epoch: 846 Loss: 0.04798874258995056\n",
      "Epoch: 847 Loss: 0.10835982114076614\n",
      "Epoch: 848 Loss: 0.033253904432058334\n",
      "Epoch: 849 Loss: 0.04872792214155197\n",
      "Epoch: 850 Loss: 0.1385612189769745\n",
      "Epoch: 851 Loss: 0.09807056933641434\n",
      "Epoch: 852 Loss: 0.06784752756357193\n",
      "Epoch: 853 Loss: 0.15440692007541656\n",
      "Epoch: 854 Loss: 0.037827759981155396\n",
      "Epoch: 855 Loss: 0.05189381167292595\n",
      "Epoch: 856 Loss: 0.07373514026403427\n",
      "Epoch: 857 Loss: 0.04140262305736542\n",
      "Epoch: 858 Loss: 0.10493718832731247\n",
      "Epoch: 859 Loss: 0.07089725881814957\n",
      "Epoch: 860 Loss: 0.05234446004033089\n",
      "Epoch: 861 Loss: 0.07531743496656418\n",
      "Epoch: 862 Loss: 0.06028713285923004\n",
      "Epoch: 863 Loss: 0.07194772362709045\n",
      "Epoch: 864 Loss: 0.05332447588443756\n",
      "Epoch: 865 Loss: 0.07077984511852264\n",
      "Epoch: 866 Loss: 0.12843896448612213\n",
      "Epoch: 867 Loss: 0.03419975936412811\n",
      "Epoch: 868 Loss: 0.06716025620698929\n",
      "Epoch: 869 Loss: 0.08016548305749893\n",
      "Epoch: 870 Loss: 0.059779636561870575\n",
      "Epoch: 871 Loss: 0.06533890962600708\n",
      "Epoch: 872 Loss: 0.07130734622478485\n",
      "Epoch: 873 Loss: 0.07824360579252243\n",
      "Epoch: 874 Loss: 0.07028210163116455\n",
      "Epoch: 875 Loss: 0.04119471088051796\n",
      "Epoch: 876 Loss: 0.09341587126255035\n",
      "Epoch: 877 Loss: 0.06793136894702911\n",
      "Epoch: 878 Loss: 0.04821233078837395\n",
      "Epoch: 879 Loss: 0.03955843299627304\n",
      "Epoch: 880 Loss: 0.09709752351045609\n",
      "Epoch: 881 Loss: 0.09766361117362976\n",
      "Epoch: 882 Loss: 0.05355985835194588\n",
      "Epoch: 883 Loss: 0.06003810092806816\n",
      "Epoch: 884 Loss: 0.11051627993583679\n",
      "Epoch: 885 Loss: 0.0686437264084816\n",
      "Epoch: 886 Loss: 0.13296498358249664\n",
      "Epoch: 887 Loss: 0.21515317261219025\n",
      "Epoch: 888 Loss: 0.04208740219473839\n",
      "Epoch: 889 Loss: 0.09727931767702103\n",
      "Epoch: 890 Loss: 0.025851933285593987\n",
      "Epoch: 891 Loss: 0.04481155052781105\n",
      "Epoch: 892 Loss: 0.16459500789642334\n",
      "Epoch: 893 Loss: 0.1293036788702011\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 894 Loss: 0.04644174501299858\n",
      "Epoch: 895 Loss: 0.04356101155281067\n",
      "Epoch: 896 Loss: 0.049488410353660583\n",
      "Epoch: 897 Loss: 0.06836169958114624\n",
      "Epoch: 898 Loss: 0.07200150936841965\n",
      "Epoch: 899 Loss: 0.08711527287960052\n",
      "Epoch: 900 Loss: 0.048042260110378265\n",
      "Epoch: 901 Loss: 0.026298947632312775\n",
      "Epoch: 902 Loss: 0.1205015555024147\n",
      "Epoch: 903 Loss: 0.07188738882541656\n",
      "Epoch: 904 Loss: 0.05594242364168167\n",
      "Epoch: 905 Loss: 0.06512707471847534\n",
      "Epoch: 906 Loss: 0.04626314714550972\n",
      "Epoch: 907 Loss: 0.08612926304340363\n",
      "Epoch: 908 Loss: 0.12230116873979568\n",
      "Epoch: 909 Loss: 0.031205622479319572\n",
      "Epoch: 910 Loss: 0.08776069432497025\n",
      "Epoch: 911 Loss: 0.051366161555051804\n",
      "Epoch: 912 Loss: 0.04833034425973892\n",
      "Epoch: 913 Loss: 0.036557313054800034\n",
      "Epoch: 914 Loss: 0.13479961454868317\n",
      "Epoch: 915 Loss: 0.0581376776099205\n",
      "Epoch: 916 Loss: 0.10337430238723755\n",
      "Epoch: 917 Loss: 0.037511296570301056\n",
      "Epoch: 918 Loss: 0.03582250326871872\n",
      "Epoch: 919 Loss: 0.059217069298028946\n",
      "Epoch: 920 Loss: 0.09467591345310211\n",
      "Epoch: 921 Loss: 0.06387850642204285\n",
      "Epoch: 922 Loss: 0.03672377020120621\n",
      "Epoch: 923 Loss: 0.03869352117180824\n",
      "Epoch: 924 Loss: 0.0514688715338707\n",
      "Epoch: 925 Loss: 0.05245400220155716\n",
      "Epoch: 926 Loss: 0.04347379505634308\n",
      "Epoch: 927 Loss: 0.0653371810913086\n",
      "Epoch: 928 Loss: 0.06529742479324341\n",
      "Epoch: 929 Loss: 0.07930240780115128\n",
      "Epoch: 930 Loss: 0.0636427253484726\n",
      "Epoch: 931 Loss: 0.0685642883181572\n",
      "Epoch: 932 Loss: 0.027135547250509262\n",
      "Epoch: 933 Loss: 0.06562335789203644\n",
      "Epoch: 934 Loss: 0.07209508121013641\n",
      "Epoch: 935 Loss: 0.14547200500965118\n",
      "Epoch: 936 Loss: 0.06717408448457718\n",
      "Epoch: 937 Loss: 0.030777396634221077\n",
      "Epoch: 938 Loss: 0.08819551765918732\n",
      "Epoch: 939 Loss: 0.05776999518275261\n",
      "Epoch: 940 Loss: 0.04856717213988304\n",
      "Epoch: 941 Loss: 0.0899859219789505\n",
      "Epoch: 942 Loss: 0.11656634509563446\n",
      "Epoch: 943 Loss: 0.10824044048786163\n",
      "Epoch: 944 Loss: 0.11400420218706131\n",
      "Epoch: 945 Loss: 0.06294422596693039\n",
      "Epoch: 946 Loss: 0.033925481140613556\n",
      "Epoch: 947 Loss: 0.0745222344994545\n",
      "Epoch: 948 Loss: 0.06484701484441757\n",
      "Epoch: 949 Loss: 0.07701411098241806\n",
      "Epoch: 950 Loss: 0.10947313904762268\n",
      "Epoch: 951 Loss: 0.04606819152832031\n",
      "Epoch: 952 Loss: 0.037383802235126495\n",
      "Epoch: 953 Loss: 0.04440136253833771\n",
      "Epoch: 954 Loss: 0.06950981914997101\n",
      "Epoch: 955 Loss: 0.08073128759860992\n",
      "Epoch: 956 Loss: 0.06270752102136612\n",
      "Epoch: 957 Loss: 0.06860098242759705\n",
      "Epoch: 958 Loss: 0.05175966024398804\n",
      "Epoch: 959 Loss: 0.041412509977817535\n",
      "Epoch: 960 Loss: 0.08546360582113266\n",
      "Epoch: 961 Loss: 0.04115340858697891\n",
      "Epoch: 962 Loss: 0.06143340468406677\n",
      "Epoch: 963 Loss: 0.05479559674859047\n",
      "Epoch: 964 Loss: 0.6384637355804443\n",
      "Epoch: 965 Loss: 0.23012810945510864\n",
      "Epoch: 966 Loss: 0.04919898137450218\n",
      "Epoch: 967 Loss: 0.09502493590116501\n",
      "Epoch: 968 Loss: 0.06754858046770096\n",
      "Epoch: 969 Loss: 0.081737220287323\n",
      "Epoch: 970 Loss: 0.03128480166196823\n",
      "Epoch: 971 Loss: 0.14495554566383362\n",
      "Epoch: 972 Loss: 0.07557553052902222\n",
      "Epoch: 973 Loss: 0.06521260738372803\n",
      "Epoch: 974 Loss: 0.09688454866409302\n",
      "Epoch: 975 Loss: 0.03445795923471451\n",
      "Epoch: 976 Loss: 0.06628460437059402\n",
      "Epoch: 977 Loss: 0.06710661947727203\n",
      "Epoch: 978 Loss: 0.6395112872123718\n",
      "Epoch: 979 Loss: 0.04853536933660507\n",
      "Epoch: 980 Loss: 0.0363110713660717\n",
      "Epoch: 981 Loss: 0.07461453229188919\n",
      "Epoch: 982 Loss: 0.06988388299942017\n",
      "Epoch: 983 Loss: 0.06524381786584854\n",
      "Epoch: 984 Loss: 0.043839454650878906\n",
      "Epoch: 985 Loss: 0.06297294050455093\n",
      "Epoch: 986 Loss: 0.05997033417224884\n",
      "Epoch: 987 Loss: 0.03241049870848656\n",
      "Epoch: 988 Loss: 0.18677926063537598\n",
      "Epoch: 989 Loss: 0.10025554150342941\n",
      "Epoch: 990 Loss: 0.14507797360420227\n",
      "Epoch: 991 Loss: 0.4417860209941864\n",
      "Epoch: 992 Loss: 0.05363479629158974\n",
      "Epoch: 993 Loss: 0.10023079067468643\n",
      "Epoch: 994 Loss: 0.06531590223312378\n",
      "Epoch: 995 Loss: 0.036549560725688934\n",
      "Epoch: 996 Loss: 0.045127175748348236\n",
      "Epoch: 997 Loss: 0.06589729338884354\n",
      "Epoch: 998 Loss: 0.033528946340084076\n",
      "Epoch: 999 Loss: 0.06229903921484947\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(1000):\n",
    "    losses = []\n",
    "    for batch_idx, (data1, data2, targets) in enumerate(train_loader):\n",
    "        data1 = data1.to(device=device)\n",
    "        data2 = data2.to(device=device)\n",
    "        targets = targets.to(device=device)\n",
    "        #output = model(data1, data2)\n",
    "        output = model(input_ids=data1, decoder_input_ids=data2)\n",
    "        loss = 10*criterion(output, targets)\n",
    "        losses.append(loss.item())\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1)\n",
    "        optimizer.step()\n",
    "        \n",
    "    mean_loss = sum(losses) / len(losses)\n",
    "    scheduler.step(mean_loss)\n",
    "    print('Epoch:', epoch, 'Loss:', loss.item())\n",
    "    \n",
    "    if mean_loss<min_val_acc:\n",
    "        min_val_acc =mean_loss\n",
    "        torch.save(model.state_dict(), 'best_cos_3-3.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data1 = torch.from_numpy(trainX1_copy).float()\n",
    "test_data2 = torch.from_numpy(trainX2_copy).float()\n",
    "test_label = torch.from_numpy(trainY_copy).float()\n",
    "test_dataset = TensorDataset(test_data1, test_data2, test_label)\n",
    "test_loader = DataLoader(test_dataset, batch_size=128, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions=[]\n",
    "for batch_idx, (data1, data2, targets) in enumerate(test_loader):\n",
    "    data1 = data1.to(device=device)\n",
    "    data2 = data2.to(device=device)\n",
    "    output = model(input_ids=data1, decoder_input_ids=data2)\n",
    "    targets = targets.to(device=device)\n",
    "    predictions+=output.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = np.array(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_copies1 = np.repeat(predictions[:,0].reshape(-1,1), df_for_training.shape[1], axis=-1) \n",
    "predict_1 = scaler.inverse_transform(predict_copies1)[:,21]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainY_copies1 = np.repeat(trainY_copy[:,0].reshape(-1,1), df_for_training.shape[1], axis=-1)\n",
    "trainY_1 = scaler.inverse_transform(trainY_copies1)[:,21]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAABKUAAAJcCAYAAAAo8BegAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nOzde3yU5Z3//9c1h4QzhIAcggmEU0BAICCJBxzlZGpRka0KarfuqnXX/nra9ldt7dZu19rtdrtuT7aorcUT1goqVkRAR61OUIPIQROUcJCjGBLOSWbmvr9/3MkkkwMKYeZOJu/n44G5r+u+57o/k0cg3p+5rs9lbNtGREREREREREQkmTxuByAiIiIiIiIiIp2PklIiIiIiIiIiIpJ0SkqJiIiIiIiIiEjSKSklIiIiIiIiIiJJp6SUiIiIiIiIiIgknc/tANqLfv362UOHDnU7DBERERERERGRlFFSUvKpbdv9WzqnpFSdoUOH8s4777gdhoiIiIiIiIhIyjDG7GjtnJbviYiIiIiIiIhI0ikpJSIiIiIiIiIiSaeklIiIiIiIiIiIJJ1qSomIiIiIiIhIpxcOh9m1axfV1dVuh9IhdenShSFDhuD3+z/3a5SUEhEREREREZFOb9euXfTs2ZOhQ4dijHE7nA7Ftm0qKirYtWsXw4YN+9yv0/I9EREREREREen0qquryczMVELqNBhjyMzMPOVZZkpKiYiIiIiIiIiAElJtcDrfOyWlREREREREREQk6ZSUEhERERERERFpB9avX8/69evdDiNplJQSERERERERETkNJTsq+e0rH1Gyo/KMjNfZklLafU9EREREREREpJEfL9/M+3sOn/SaI9VhSvcdwbLBYyBvYE96dvG3ev3Ywb340dxzWj1/5513smzZMgAeeeQR1qxZQyAQYOrUqWzYsIGVK1dy9913EwgECAQCPPzwwwBcc801fPnLX+aTTz5h/Pjx/Pa3vz31N+wSzZQSERERERERETlFh6sjWLZzbNlOuy3uvfde7rjjDu644w7WrFkDQHFxMYWFhaxcubLV1y1atIhx48bx2muvsXfvXjZs2NCmOJJJM6VERERERERERBo52YymeiU7Krn+wWLCEQu/z8P/XTeJ/JyMMxrHuHHjuPrqq1s8d+LECbp27UpZWRlvvvkmwWCQqqoqdu/ezYQJE85oHImipJSIiIiIiIiIyCnKz8ngsZsLKC6voCA384wkpLp27UpFRQUAtm3To0ePuPNpaWkcOHAAgBdffJF58+YxevRozjvvPG666Saef/55srOz2xxHsmj5noiIiIiIiIjIacjPyeD2S0acsRlSs2bNYunSpVxwwQW8/vrrzc5fccUV/PrXv+a2224jMzMTgFtuuYUVK1Ywffp0fv/733P22WefkViSwdi27XYM7cKUKVPsd955x+0wRERERERERMQFH3zwAWPGjHE7jA6tpe+hMabEtu0pLV2vmVIiIiIiIiIiIpJ0SkqJiIiIiIiIiEjSKSklIiIiIiIiIiJJp6SUiIiIiIiIiIgknZJSIiIiIiIiIiKSdEpKiYiIiIiISOoKheDee52vIp3Aww8/zMMPPxxrf/Ob3/zM12zfvp1gMHja9zhdvjaPICIiIiIiItIehUJwySUQDkN6OqxZA4WFbkclqSQUgmAQAoF2+7N13333feY19UmpQCCQ+IAaUVJKREREREREUlMwCDU1ANi1tZhg0EkcdIBEgrjsm9+E9etPfs2hQ7BhA1gWeDwwYQL07t369RMnwmckiO6++27Wrl3L8ePH6d+/P0uWLGHmzJlceeWV/OlPf2LDhg3Yts2tt97Kli1b6N+/P08++SSWZXHNNddQVVWF3+9n4cKFsTEDgUBsFpRt23zta19j/fr1+P1+lixZwpNPPsmf/vQnqqqqCAaDPPXUU/Tr1++U7nG6tHxPREREREREUlLp6Mmx47Bd1w6FYMYM+MEPnK9a1ien69AhJyEFztdDh87IsBdddBGvvvoqAwYM4Nlnn2Xv3r0YY9iwYQMAzz77LOFwmFdffZXs7Gz+9re/sXTpUnJycnjllVfIyclpdezly5cTiUR44403+M53vkNJSQnf+MY3uO+++/jKV75CMBikf//+bbrHqdBMKREREREREUlJe954h7y6Y78Vddr9PHDihNNZXQ2LF2u2lDT3OZa8xRKctbWQlgaPPXZGfpby8/MBmDBhAtu3b6d37958/etfj50vKysjFAoRCAQ4evQoY8aMoaKignPPPReAKVOmtDp2aWkp5513HgBf/OIXseqTak205R6nQjOlREREREREJCWNf/GvzduNaubYto31wAOaLSWnp7DQqVP2k5+c0Xplb731FgDvvvsuI0aMoFu3bng8Demb0aNHc9111xEMBrnvvvsYO3Ys2dnZbN68Ofa61uTl5fH2228D8Nhjj/HDH/4QgK5du3L8+HHA+XvRlnucCiWlREREREREJCXt79G3xbZd1zaAiUY5ePd/JjcwSR2FhXDnnWd0tt3bb79NIBCgqqqKL37xi83OX3HFFezZs4eLL76Yu+66i5ycHObPn8+WLVsIBAJs2bKl1bHnzp2LMYbp06fzyCOPxHbmmzRpEmVlZVx00UU8+eSTbbrHqdDyPREREREREUlJO/tnMa5pu4Vt72t37kpaTCKf5dvf/nbcLnjBJj+zHo+HBx54oNnrnnvuuRbHa/x6Ywz3339/s2vS0tJ49tln4/pO5R6nS0kpERERERERSUkFb62Ja+e/9wbbL5jE0CbXVX/5K8kKSeSk7r77brdDSCot3xMREREREZHUEwrR58CeuK7edoTtq/4eW75nA5v7D6Ni4VeSHZ20U7Ztf/ZF0qLT+d4pKSUiIiIiIiKpJxjENOk6cc44jlRH4vryDmxn2/LVyYsLnMLq996rAuvtTJcuXaioqFBi6jTYtk1FRQVdunQ5pddp+Z6IiIiIiIiknkAAG+ISUxu6DaD43AIuDz3nFDkHvNhMePlZ+NqX4l8fCkEw6OzWdwaLWBMKwcUXg2VBWtoZ3bVN2mbIkCHs2rWLAwcOuB1Kh9SlSxeGDBlySq9RUkpEREREREQ6hcyP3id/4NnNlgzVRKz4jvrEUTgMXbuePHF0qsmr//s/Z1yAmhrntUpKtQt+v59hw4a5HUanoqSUiIiIiIiIpJwDv3mA/k361k29lCs3vx5r1y/S6lk4Nf7CYLAhcVRd3Xri6FSSV/XXP/VUw70tC5OZ+fnflEiKUVJKREREREREUs7hnbviklKV6T04NmosvQuGYr/+Smz5nm0MQ6mOf3FVVcOxbTvtlmZEtZS8qu9vaebU4sXYlhW7twXs+WgXWW1/uyIdkgqdi4iIiIiISMrpX3s0rp1Rc5Rb7r4FIG73vbDxUDp6cvyLn38+vr14MVx6KfzgBzB9Oixa5PRv3txwjW077UAAvv99uOgimDcPZs9uuL4RG7CMh1D2+NN+jyIdnWZKiYiIiIiISMrx1NTEtU1d36FHl9Cr8XW2zaY9h8mr71i0CMrK4gfbt6/hOBKB225zjh97LNZtA2bJEohGnY5oFJ55xjletQqAl/Jnc4l5AL8dxQYenDaPqXNntuFdinRsmiklIiIiIiIiKWd35qC4trMTn0256RabKWXqzox4/x2n43vfg69+tSGx1Brbhh/9qHl3K6+zAR56iEfMYJ4dMz127396+zny95R+vjckkoKUlBIREREREZGU02/3jri2qfvae9d2Krr1BuqW73n9fDR2ilMz6uc/bzaOTcNyv8Z9HDwY1284uYN9+nHOoF6M/aQ8dr0/GnaWBop0UkpKiYiIiIiISMo5arX8uGund6Ha3wWAGq+f66+7h9qp01pNDrWWbIq0cOZkiamN3QYwonwToz+NT5bFLQ0U6WRUU0pERERERERSzkc9zyKnhX7LtvBFIwDYxsO7WWOYcbwW3n//lMb31NZ85uyoxiateprq7rZmhog0or8PIiIiIiIi0rGEQnDvvc7XVjw/dCoAVpP+7vv30i3iFEFPi9QybX8ZBbmZ8OmnrY5laL6Er3FCqum5lvQ8dpizHv9zs/5jZR99jleLpCYlpURERERERKTjeP11uPBCuOsumDGj1cTUzgHOPKnjvvS4pFGPmmP0qj4KgBebxx//Pvl7Stmf1uNzJZfg8yWhGoslsGw7LpllgG4fbHIKrIt0QkpKiYiIiIiISMfx61+DZTl/amqcWlAtzJoa1MVJ/xzq2jOuv8fxI3FtT7gWgkE+OVJz0ts2Xap3Kkv3PnPcn/8cFi06QyOKdByqKSUiIiIiIiIdQygES5c2tC0LHnzQ+ZqeDmvWQGEhAAtDywAYdKRhWV5LiSTL68WTmcnYre81O2/TfJmeaWWck72utXvHeeghuPXWz7pKJKVoppSIiIiIiIh0DMEgRKPxfZGIk5Q6ccI5D7BoEYXFLwLOQ2/T5XZWoz4ranHi57/A28otW1qqZ3/G+dNy8OCZGkmkw1BSSkRERERERDqGQODk5zdvdr7+6lexmUktJY0aJ6B8tkWXrR9+rtvXj9m0ePqpJqaaXm8DVFWd4igiHZ+SUiIiIiIiItIhNUsGrV0LwPHq2rju0n5O0XMLsDzN50S1tLtefXvdwFHN+prOvjoj9aXS08/EKCIdipJSIiIiIiIi0jEsXhw7bHF20rRpEAqRtr081hXFcNecrxEFPu49gENpXYGWE0l2o3ENEAXWjCpoNZzWZki1lORqer6ZPXta3UlQJFUpKSUiIiIiIiIdQuXWj2PHLSZ2Pv4YgkE8TepOjfp0Ox7g7EP7yag+2ur4TYuae4EeNcdavafBmX3VUoF0aL7Mr+n5xuPYth2XdBPpDJSUEhERERERkQ5hV5derc5AsgFefx0yM8E0pIm82HzjracxxD8Af1YdqPoRZn70VrPXNK5X1VIhdYClYwO8N3DkZ9yliX37Tu16kQ5OSSkRERERERHpEPpl9Y9rmybHtm1DRQXH+2TGXZd5pOIzx246S6perxPNZ1aZRn+ijV5jNzo+kdaVsNf3mfeNox34pJNRUkpEREREREQ6BPvd9fHtJseWMRAI0KX6WNx13ibL+T6LhSGKIeLzE/GnNY8jdh2EfWncP20+W/qeHTtvgGs2rCK7quWZT60WRj9w4JTiFOnolJQSERERERGRDmHpsGlA60vvbOM84vp69ozrN95Te/Td3as//zP9RhYuuJfyrBHN7revzwAAgrlTuP66e/h54Ca2ZWbFkk0G8FkRvHbzqlKNZ1Q1fS9lvQefUpwiHZ2SUiIiIiIiItIhHB2ZF5fEabp8z2tbEAxSdtEcoCHhUzVsZLNE0MlqSh1O787vCq/hncF5LCqYT9jjdWZFebwAvDp0IgCRujbA2P0NO/7ZdfG8kD+n2b2iwIFufVq8b7E/s8V+kVSlpJSIiIiIiIh0CJd9Whar5QTNZxxFPV5KR0/ml5azlK5kcB53zrmd34yeFbvONPnakrDXHxtzU/ZYrlv4M34x/ctct/Bn1Hq8FGx/D3CKoD++5C4m7/6Aan96XDxVZw3mN3Nu5v5p82O78NmA5fHx/lnDYu3GcZz76fbP940QSRFKSomIiIiIiEiHEKmsAlqf6WTZNsEtB5hevg6A14ZNYsnEIrocrmp1hlVj9dc8ea6TxPIA3bv4WZc1ht8VXgOA34rGakV5sPFFwxTs3Mgfp1wRN8Yfpy/A7zH8PHATT0wswqq7r8e28GATrWs3jqvPjdd93m+FSEo4xa0ARERERERERNwxeFsp0JDMabp8z29FmbX4PoZ/UALAt954gk969KU4e3yL49WP0XisnT3P4i+TivACfp+Hcwb1YnflCQAKdm4EGmZ3WEDY62NtznhKBo8BoKjsTVaMPp/X84vI7dedPYdqWDruUuZvWoM/GiHs9fHC6AuYuut9/JEw3rq0VMTj5bW0gQxt83dJpONQUkpEREREREQ6hA8HDmMwr520HtTZ+3fEtYvK3uT5aV/kiL8bvcPH487ZODWevDTMWLr//C+R26878yYPoSDXqfEULPuE2qhNj5pjsdcZoKxfDj/+4teZf9s/sO+VD1kysYglE4sAOK9PV7qlOY/c67LGcP1191CwcyPF2eNZlzWGLf2H8o2/P85F2991liTaNtWrX4Z/W9CWb5FIh6KklLgnFIJgEAIBKCx0OxoREREREWnnuh92lu+drB6UnZYW1948IJeBvbpQ6/dDuO6aunPfn3M7fU8coUfNMc7ZX86K0eezZGIRs/r34PZLRsTGeOLWQp5et4txf9kWd/9B0RPcPfcc8qZls2nPIR5fuzP2mhEDenLgSE2svS5rDOuyxsS1/+/ChRTu3EiaFSHi9dFl5qWn9g0R6eCUlBJ3hEIwfTpEIpCeDq+8osSUiIiIiIicVF//Z1/j37cnrp17cDczxwzgtaGTmP9+MNYfHDopNqupqdsuHh7Xzs/JID8ngw+XF8C2dbH+3pWf0OeGebBmDfMn5/HXdz4mHLXxew3zJw9h6bpdceMYwOsxRCwnLbYuawwPTb2Sf1n7NI9842fcollS0smo0Lm446GHnIQUQE0NLF7sbjwiIiIiItLurcyeDDi1nFpawtfSrnx51hF6dvWztV92bBc8C3i7lTpTt03PJT8no8VzA+2auLYBqK2FYJD8nAyeuLWQ78wZzRO3FpKfk8HVk4eQ5vNgAJ/XsHBaNv9x5TjSvA1zvbZlZAHwWG0mJTsqT/LuRVKPZkqJO957L769b587cYiIiIiISIdRecBJ2nzarQ/9j1c1O2+3cFx+5QIKcjO5J3s8Nb60WLHx4uzxZPXpwsJpORw5EWbz3sMUjRvEwmnZrd7fX1Yat3TQBmyvD08gADTMqKqXn5PBE7cUUFxeQUFuZuzc6IE9eXrdLjbvPoS9wRnRCkcoLq9oNSEmkoqUlBJXVPXoQ5/GHQcPuhWKiIiIiIh0AKVLV/Jvz/8GgL4nDrV6ndW9J95jRwCIGA+DL5hCXk4G/WYFuJ74YuM/vWTkSZNQTR36eC9dmvRV9RtI35OUImmaqGrcV7KjkideXAZAuodYYXWRzkLL9yTpSnZUsnnbgVjbBnjtNVi0yLWYRERERESkfatcsQp/1CkBYmy7xVlRQCwhZQCfbdF36RIAvnrxcDblnMPvCq/h3SFjuG167iklpAA29RjYrK/X4dP/gD0/J4NRWc7H9f/7D+M1S0o6HSWlJOmKyyuYsKcs1o5Nf336aVfiERERERGR9m9Qblbs2cEDHPU3nbPU8q587+85DDQspfvunNH89bbzueMLY1q4+uQevegaIk36qmZedsrjNNarRzoA45Y/4WwIJdKJKCklSdd0Sqpd94f5890IR0REREREOoChO7fEtau792x2TdPZU2GPlxcmzYr15edkcPslI057RtK+sZPY2Tt+ttSBo7WnNVa94RvfAsD+3//FClyixJR0KkpKSdLl7yllb+aguL5Xh06iZM6XXIpIREREREQ6nOwcID4RZRp9tQHbGGaOGXDGbpnm89DveHw9q2Fvrj79AUMhJq9eCjgxm9oaPvmtyppI56GklCRXKATnn8/IfdtiXe8OHMVXrv0JxeUVLgYmIiIiIiLtWemsq4ga5xG21usj1G0QFqbFJXvgPOz6sZl9oPSMxXDt1GwOdI/bson9Xfu0cvXnEAxibDuuq/zAsdMfT6SDUVJKkisYBOLXek/Y/xGTd3+gnSZERERERKRVj5jBLDl3DgA3XPsTHh8doMbnJ9okLVXfsgGPxwOBwBmLYfTAnoSGToybnfXWsImnP2AggOXxxpphj5d3L7ni9McT6WCUlJLkauEXgte2+O57z2mnCRERERERadWBIzV8WjdL6e0h49gxcgLXX3cPT0y8jCjxy/jq2eEwbNx4xmIoLq9g6bhLqfX6iGKo9fr4YNZVpz9gYSErrv96rHnDDf/FeQsuPwORinQMHSIpZYwZYIx59yTth4wxIWPMXSfrk3aglV8IBRtfh0VaOy0iIiIiIi3r1zMdnxUl7PGCMZzdtxvrssZw15zbKT1rWLNlfPXtQ48uOWMxFORm8m7WGBYsuJf/mX4jCxbcS8ngvDaNaY05J3b8vR/fpA/rpVPpEEkp4BdA15baxpirAa9t24VArjFmZEt9SY9YWnT0d39o1hf75fH000mNRUREREREOo75k4eQFo0Q8fhI8xpGDOgRO+ePRJpdXz9z6uVzLjpjMeTnZDB1aAbrssbwu8JrWJc1hrN6dWnboL6G5Xtn/eMC7b4nnUq7T0oZYy4FjgH7WmoDAeAvdccvARe20tfS2LcaY94xxrxz4MCBRIQvTVRZDT9ydpOvzJ+f7HBERERERKSDyM/JYLI5grEtnsv38g/5Z9PF78EA2zKzWly+d8ybzorCuWc0jqsmDYlrXzL6rDaN533xxdjxkNdeIjr9YiWmpNNo10kpY0wa8EPgjpbadboDu+uODwIDWulrxrbtRbZtT7Fte0r//v3P/BuQZrr3byhmXr9Na1V6D+6cczuPn3uZa3GJiIiIiEg7Fwox6e2XSY+GybthHvl7Snns5gIWTMtm0bT5WJhmiamjXbqd8TAqj9fGVnt4jNM+XSU7KjmveGWsbQBPJBzbIEok1bXrpBRO8ul3tm1XtdIGOErD0r4eOO+ppT5xWyhEz1dWxZr1vzBeGT6VJROLWLFprztxiYiIiIhI+xcM4rHq9tqrrYVgkPycDH46bzzZl8/gB3P+tVlS6lB6D/r1TD+jYRTkZpLu9+A1kObztGkX8eLyCtIjDUmtWPxncMdAkfasvSdrZgK3G2OCwETgK43bxpgHgRIaluedC2xvpU/cFgzisa24rijEdtAoGjfIhaBERERERKRDCASwjcdJ3Ph8cYmb+66bxJKJRbw3cATQkNzZNHA48ycPaTpSm+TnZPDYzQV8e/ZoHru5oE2FyQtyM1k/aFRc3+b+w9pcPF2ko/C5HcDJ2LY9vf7YGBO0bTvQpH2zMaYX8LoxZjBQBBTg/BvUtE/cFghgxxbtOVNTvUDO0U/56bzxLJyW7WZ0IiIiIiLS3tV/yG3Ff9j9zSXO5uy1PmdWVP1Tx6CawwnZzS4/J+OMjJufk8HSiy6FHetjfaMqPua55avJ/9qX2jy+SHvX3mdKxTROSDVu27Z9GKeweTFwiW3bh1rqS2as0rqm27QCnHtktxJSIiIiIiJycosXY6h7pgiHYfHi2KngFmfjqmXnBLBpmCm1ZuyZ23kvUYbv3x47NoDPilC4c6Nr8YgkU7ueKfV52bZdScNue632icuCQWhhTwzP8eNJD0VERERERDoum/gPvAOj+vPM+j0smVgEQFHZm6wYfT59bvuqK/GdCvvApw3HAB4PWfOKXItHJJk6zEwp6fhe6p/X4jatPY5WUbp0ZQtnREREREREHC/lz47Nggp7vLyUPzt27r7rJnHVxMGkeQ1LJhZx88L/pPor/8wdXxjjWryf18fpveLaH54XgMJCd4IRSTIlpSRpap5e1uIPXNfaanKuvUKJKRERERERadXqD/YDTlLKNibWrndj4VCilvMxeDhq88KmfZTsqEx2mKfs8bGXxo6jGJZcssDFaESSS0kpSZqZa19osaaUAfzRCDuWvpDskEREREREpIMo2LkRg/MQ67UsCprUXSour8BqtDQjHLEoLq9IaoynI93b6CnJGIZldncvGJEkU1JKksZ069bi8j0LCHt9bBs3NdkhiYiIiIhIBzF2wRWAM1Mq6vHG2vUKcjPxN0rw+H0eCnIzkxniaZm8bUPsOcljW2T/7a+uxiOSTEpKSdK8ea1TZLDxbhgAEY+XP0+Zy9QFl7sSl4iIiIiItH95n+6IHfu9hrxB8bWY8nMyeOLWQhZOy+b6adk8cUsB+TkZyQ7zlJTsqOTVwWOp9Tp7kBng/Fef5aUHl7kbmEiSKCklSTP4ginxySicf3TTrChfLX6azMcfdicwERERERFp30IhuP12DM4zhIlE6nb3jpefk8FP543nnnnj231CCpwlh+sGj+GVYVOAutImVhTvo4+4G5hIkigpJUmTt+qZ2C8RgONp3eLOm6VLkx6TiIiIiIh0AMEgRCJA3fI9G0pHT3Y1pDOhIDcTj8fwaY+MuA/ws/t2a/U1IqlESSlJmreL349r7+w9IG4pn3311UmPSUREREREOoDMJrWhbAhuOeBOLGdQfk4G//+c0Swd5+zAZwNRfxojv3u7u4GJJImSUpI05XSN233vvaw8Pho4lKjx8P6NtzH0zm+5FpuIiIiIiLRfn7wWih0bwIvFxFeecy+gM2je5CzWZY3huC+Nj0aei+/VIBQWuh2WSFIoKSVJEx0xEnCy/2GPl6q8cQzbvxOvbZH7xB8pXbrS3QBFRERERKRdOrJ9d7O+URxzIZIzr3TvEQDCvjRCvc6mZHCeyxGJJI+SUpIcoRDXPvOHuK5z9m/FY1tOMb9ohMoVq9yJTURERERE2rWeQ7Oa9fXNzXYhkjNv4+5DeAyEPT480SjF5RVuhySSNEpKSXIEg5hIGKibbmtZHDkRJurxOjOnvD4yima5GqKIiIiIiLRPaR/vjB3bAMbAl7/sWjxnUkFuJmk+D1GPhzQ7SkFu5me/SCRFKCklyZGZGasnZQNRj5dNs65ibeFl2Bh2PPkceVfPcTNCERERERFpp9LfXRfXru3aPWXqLuXnZPDYzQVEPD6G9k4nPyfD7ZBEkkZJKUmOiorYLnsW8NSEWcz+53lUn52DB5u8K2e6GZ2IiIiIiLRj5ZOcBFT9M0XZeQHXYkmE/JwMol4v3TyW26GIJJWSUpIUpaMnE/V4AYh6fPS//RbyczLwH9gPQNlTf3MzPBERERERaceenzQbqFt1gWFZ4ZXuBpQAPitK/21bIBT67ItFUoSSUpIUr2w5gLGdzzVsA1s/PUbp0pWc/8ozAOTc+CXtviciIiIiIi0au+VdoO4B1hhyN73tajxnXCjEoEMHOGvHh1iXzlBiSjoNJaUkKXI3vY3Xdqai+qMRcje9TeWKVXgsp8+n3fdERERERKQVNZ86O9JZOJskLes9kpIdle4GdQbtXjOnc20AACAASURBVLYCg40BrJoadi9b4XZIIkmhpJQkRf6xvbFC56aunVE0K7akL6Ld90REREREpCXf+x7z33bKfRjghVHnsy5rDEvX7XI3rjMolD0eGxNLuoWyx7sdkkhSKCklSdFjfUmsKGF9O+/qOfx9mrPj3pvXflW774mIiIiISLxQCH7+87iuee+/yuTdH8Q9X3R0w+bOpKxfNjv7DOSmG+5l2FxtBCWdg5JSkhSbCpx/VO1G7ZceXMZFa18E4MIn7uelB5e5FJ2IiIiIiLRLd9wBELfqwmBT+PFG5k8e4lpYZ1p+TgbHe/TmSOYAvnv3TeTnZLgdkkhSKCklSWF+9jMO+7sRNYbXhk3G/OxneB99BJ8VBcBvRfA++ojLUYqIiIiISLsRCsFrr8V12YBlPJx7w1Upl7ixfH56eOyUe18iJ6OklCRF5uMP0yt8HK9tM33bOjIff5iz+3aLu6ZpW0REREREOrFgsMUleodmXcbsm+clPZxEs3w+PNGI22GIJJWSUpIUZulS52uj9qjv3k7U6xQ6t4GeAzLdCU5ERERERNqd0tGT49rOLCnDJ1/9ujsBJVi36uP0PviJM0NMpJNQUkqS4sOBw4CGmlIfDhpOyeA8VudOBZxk1cDf/4rt9/6vOwGKiIiIiEi7smnP4diH2vWeGXMx/3M0BT/MDoUYu2Mzvas+hRkzlJiSTkNJKUmK8N79dUUJHccOHKS4vIKzD+0H4mdQiYiIiIiITHvqwWZ94/Zt5ZPD1S5Ek2DBIMa2MIBdWwvBoNsRiSSFklKSFDndvXHtszO6UpCbyTPjLgUaZlDZV1+d5MhERERERKQ9svfsiaspZYBRBz9m4XsvuhVSwpSOnoxlPNhAtfE2W7ookqqUlJKkGPtP1wJgAVGvj8k//Cb5ORkMvcNZD36oey/ev/E2ht75LRejFBERERGR9mLbuKkt9k9clXqrK9ZkDOfdQaOo8fr5ycxbWJMx3O2QRJJCSSlJjvffjx3apmFl+FkfOv29jh0m94k/Urp0ZdJDExERERGRdiYU4sLli5vVlAI4lnlW0sNJtBmVW5m0dwvp0TA/XP0AMyq3uh2SSFIoKSWJFwoR/cUvAOcHzkQjPP9/jwNg3gzF+v3RCJUrVrkUpIiIiIiItBef/HYR3mg0rq9+Kd+g885NfkAJlle2Dk9dTal0O0pe2Tq3QxJJCiWlJPGCQbAswPlFYhsPf+npTEf1zbzU2doVQ9jrI6NolmthioiIiIhI+7D/cE2zvvpZU4PWFSc3mCQoHT0ZC4MNhDGqKSWdhpJSkniBAJbXB0DEePjhrNvoO+NiALIvn0GN18/W0RPZ8eRz5F09x81IRURERESkHdh7xZdixzbEFTyv7NMv6fEk2rL1uyFW5sQ4bZFOQEkpSbzCQt676AsA/OriG6j+yj9z33WTAEjzeajxpWFPnKiElIiIiIiIAOD7oKEmbX2qxgbCHh9/mDbflZgSKWv92tjyPa8VJWv9WrdDEkkKJaUk4V56cBkTXnsBgNv/voQvHN0eO5fm9WBh8L39loqci4iIiIgIABc+8utmfcd86Vy38F5W9851IaLEGnjFZUQ9XgDCXh8Dr7jM5YhEkkNJKUm4qhWr8FlOkUJfNEJVo2Lmu19YQ++aowwt30zOtVcoMSUiIiIiInDkcLOug916sy5rDMP693AhoMSaffM8Nkw4H4CN3/p3Zt88z+WIRJJDSSlJuD5Fs7Dr1kdbxtCnUTHzfctXYqjbfS8SZsfSF9wJUkRERERE2o3VeYWxWlL19aR+V/glPAZuu3i4i5ElSCjExI3OzuTn/eYeCIVcDkgkOZSUkoSbbR3AYzu77/mtKLOtA7FzJ3r1AZxfNF5sjvfs40aIIiIiIiLSjjw2oQhDQ1Lq/mnzWTKxCJ83RR9hg0E8datL7NpaZwdzkU4gRf9GS3ty6NElrban9XQ+9zA4s6jO62kjIiIiIiKd28W7NwHOA6tlPBxN7w5ANGpRXF7hYmQJEghgeZ2aUvjTIBBwNRyRZFFSShKuZOoMoGHabX0bIGveF7AxzicgaelkzStKfoAiIiIiItKuDLgsAEAUQ9jrozh7PAbw+zwU5Ga6GltCFBay4cobAIj+9a9QWOhyQCLJ4XM7AEl9gy+YQvSX4AXCHi+DL5gSO1cyOI++vQfQp+Yov7z0Jq4anEe+e6GKiIiIiEg7kH/FpfBd2J6ZxV8v+hLnLbicGV39FORmkp+T4XZ4CXE4KweAyMRJelCXTkMzpSThqle/jAdniZ7Htqle/XLs3Lblq8k+vJ8+1Uf5/kt/YNvy1a7FKSIiIiIi7cOuFWsAGFqxm68//1uuqt7J7ZeMSNmEFICpW75nRy2XIxFJHiWlJOGe7TMSy3iwgbDXx7N9RsbOFe7ciMe2nam40QiFOze6FqeIiIiIiLQP0ddeB5zNkPzRCJUrVrkcURJ4nMdzOxJxORCR5FFSShJu5JWz2Twgl+O+dH484xZGXjk7di5rXlEsYeVJV00pEREREREB71Sn5Ed9TamMolkuR5R4lTXO7nsbd1W6HIlI8igpJQm30NrNuP3ldIvU8J/Bh1ho7W44WVjIhtwJHOmVgeflNSroJyIiIiIi9JkyCYDXJ1/K6/cvIe/qOS5HlFglOyp5c5uTjLrjqfWU7FBiSjoHJaUk8YJBPLaFAbyRMASDcactnw9jad20iIiIiIg4tu05CMDBGos/vrEt5ZM0xeUVRGwDgB2JUlxe4XJEIsmhpJQkXOnoyVjGYAPVxkvp6MkNJ0MhJpaV0OPoIaxAAEIht8IUEREREZF2In3Z0wBctTnInx69M+U3RCrIzSTn0D4AJuzfSkFupssRiSSHklKScGsyhrOz1wCquvTgJzNvYU3G8Ni5A795AA9OoXNTW8uB3zzgXqAiIiIiIuK+UIjAc38GwINNWjSc8hsi5e8p5V/X/hWA//3bL8nfU+pyRCLJoaSUJNyMyq3kHNpP7+qj/HD1A8yo3Bo7t7XiaNy1TdsiIiIiItLJLF4cK+9hAx6PJ/U3RAoG8UadXfc80UizkiciqUpJKUm4nsVvYLDxAP5ohJ7Fb8TOrQ9cQRRnaV/Y42V94ArX4hQREREREfcdOFyDadSuuvSy1N8QKRDA8vmcY58PAgFXwxFJFiWlJOFC2eOxMVhA2OsjlD0+di4wqj+YuoJ+xuO0RURERESk0/p7r7Pj2sHh+S5FkkSFhWy+5VsALL/9bkoG57kckEhyKCklCTds7kyq0nvwSY8M/nPWVxk2d2bsXM/iNxp25rOicbOoRERERESk8+l2pAq77tjC0O1IlavxJMuWvkMA+P3B7lz/YHHK7zgoAkpKSRJ0L3mLjJojnHW0krtW/YHuJW/FzoWyxxP1eIHms6hERERERKTzMYEAUeM8qtb6/JhOspRt+8FqAIxtEY5YFJdXuByRSOIpKSUJV7liFUCsplR9G5xZVKtGFgDwi0tuiptFJSIiIiIinc+Hw8fz0sgCTvjSuGHBPXw4vHN8cJ3ZqwsAXtvC7/NQkJvpckQiiaeklCRcRtEsgFhNqfo2OFufzv5oLQB3vvawtj4VEREREenkCnIz8UcjRDxePMZ0muRMv97dAPDYNo/dXEB+TobLEYkknpJSknAjr5pNFMMHoyaz48nnyLt6Tuzc7mUrMNGo06gNs3vZCpeiFBERERGR9qB7yVtcUv4OPWpPsPjx78eV/0hlFccjAHhsy+VIRJJHSSlJuHBtGB82ttfb7FzjmlIRr1c1pUREREREOrnKFatimyE1Lf+Rqkp2VPLylgOAk5Ra8IAKnUvnoKSUJNyWp54HYOwHb5Nz7RWULl0ZOzds7kzuL7wGgDvnfls1pUREREREOrmMolnYxmDTvPxHqiouryBcV9zdY9sqdC6dhpJSknBHX1wN1Bc6D8d90pGfk8FZhZMB+MdbLte6aRERERERYX/3vhzo1od/XPhTjuWf53Y4CVeQm8moio8BuGXtUqbsLe00tbSkc/O5HYCkvsxB/QGwAa9tMyg3K/58Rg8AhvdOT3ZoIiIiIiLSnoRCjLzmcjzRKDYw4pNtFJdXpPyH1/l7Sjn35QcAmLn1LS7eVkL5leMgZ85nvFKkY9NMKUm4QbVHADAAHg9DqY47n7F/l3NQ8k5yAxMRERERkfblRz/CG41icJ4f/mPl/cyo3Op2VIkXDOKp2wDKAH4rSvjhP7sbk0gSKCklCXd8/AQAbOPBpKdDINBwMhRi0v3/BUC373wLQiEXIhQREREREdeFQrB6daxpAC82eWXr3IspWQIBbGPiurr49LguqU8/5ZJwm3o5y/VCU2dS+ugyKCyMndu9bAUm7Gx9SjjM7mUr3AhRRERERETcFgyCbceaNmB7vPEfaqeqwkLeGzk5rutQeneXghFJHiWlJKFKdlSy6pG/ARDslsUV66y4rU1D2eOJeJ3SZjaGsqjqSomIiIiIdEpVVc26TDTC9mCxC8EkV8mOSvyH4t//yN0fuhSNSPIoKSUJtW35an6y4rcAfPe1xYzbsTlua9Nhc2eyqGA+AB7bIvCb/9ASPhERERGRzmj9euxGzfrFbGbpUjeiSari8gp29hkY19e7cKpL0Ygkj5JSklDTi1/AbznL83xWlH94/5W4rU3zczKY7j0MOD+MntpaWLzYjVBFRERERMRFaydfEteuT1ClTZnc/OIUU5CbSa0/Lda2gd22VpFI6lNSShLqrJ5d4tqz8gbEbedasqOSjyprYm0bERERERHpjH4z4hLCjR5R62dKDdq3052Akig/J4NBg/vF2gZU2kQ6BSWlJLEmTYpr9r+4IK5dXF7BsjHOJyIWUOv1UzrrqmRFJyIiIiIi7cS/rHgAP1az/qPbPnYhmuQbmnNW7DiKYbS35iRXi6QGJaUksSoa6kdhPPFtnGmqJTnnALC9zyDunnUrazKGJzNCERERERFpB8a+sjw2OwoaVlGsKrzcjXCSbuBN1xPFOO/b7ydrXpHbIYkkXIdIShljBhhj3jXG9DbGrDDGvGSMWWaMSas7/5AxJmSMuavRa5r1iQsCAWyfHwA7zd9sO9f8nAx+OOgEAEOr9vLvqx9gRuXWZEcpIiIiIiIuO9GtR+y4PiEVHDqJFYVz3QkoyUr3HgbjpOWilu20RVJch0hKAb8AugLXA7+0bXs2sA+4zBhzNeC1bbsQyDXGjGypz7XIO7vCQl65/AYAXrjzl1BY2OySieUbsHF+GP2RMD2L30hujCIiIiIi4roT4yfGtTf3H8ZN1/6Efj07R22lyhWrMLaFAbxWlMoVq9wOSSTh2n1SyhhzKXAM2Gfb9u9s267/m9kf+AQIAH+p63sJuLCVvpbGvtUY844x5p0DBw4k5g10co+v3UnwuPNL5Eef9ubxtc2LFG7HKYZuA15sFfQTEREREemEQmkNNZUiHi//PudfAZg/eYhbISVVRtEsLI8XGwh7fWQUzXI7JJGEa9dJqbrleT8E7mjSXwhk2LZdDHQHdtedOggMaKWvGdu2F9m2PcW27Sn9+/dPwDuQFZv2khYJA1Dr87Ni095m14zy1QLODhOWUUE/EREREZFOJxTiumd/H2v6rCijDmx3Lx4X5F09h415U7Aw7P+Pn5F39Ry3QxJJuHadlMJJRv3Otu2q+g5jTF/g18A/1XUdxVnaB9AD5z211CcuKBo3iGGVewAYu7+conGDml1zaNr5QMPue0cKLkhmiCIiIiIi4rbFi5s9tF27wVkkU1xe0fz6VBQKMaHsHbzYDP3JDyAUcjsikYRr78mamcDtxpggMNEY80fgKeBO27Z31F1TQsPyvHOB7a30iQsm7/6Aaze8BMDDT/2Iybs/aHbNa5kjqUrvwf4effnJzFu0+56IiIiIiLC/R1+6+D0U5Ga6HUpyBIOYqOUc19ZCMOhqOCLJ0K6TUrZtT7dtO2DbdgBYD7wNTAZ+YIwJGmOuBZ4BbjTG/BK4BvhbK33igsoVq/BaUQD80UiLxfpmHyqnd81RBhw9yA+1+56IiIiISKdTOusq6tIx2EDU4+Xo17/NYzcXkJ+T4WZoyRMIYHm9AFj+5juXi6Sidp2UaqwuOXW/bdsZ9Ykq27aftG37ME5h82LgEtu2D7XU517knVtG0Sws4zlpsb4+b72BoW73vWhEu++JiIiIiHQyr2w5gI1xElLGcNes26idOq3zJKSAksF5PDKxCIB/uuoHlAzOczkikcTrMEmpk7Ftu9K27b/Ytr3vZH2SfHlXz6E8bxJhj7fVYn2h7AnYGCycxFUoe3zyAxUREREREdeMeWkZXmwM4LVtxu0vb3GTpFT29LpdhD3OTCkiUZ5et8vdgESSICWSUtKOhUKMKFuP34q2Wqxv2NyZ7OrVn6ouPfnp7K8ybO5MFwIVERERERG39DtehWncPlbJOYN6uRaPG7LL3uMrJc8D8Ptnfkp22XsuRySSeEpKSWIFgxgr6vyCaaVYX/6eUoYcOUBG9RF+/PKD5O8pTXaUIiIiIiLiosEH42dFDanaT8+ufpeiccfcg1vwWhEAfJEwcw9ucTkikcRTUkoSKxCI1ZSy/GktF+sLBjG2M1XXhLXLhIiIiIhIZ5N+YH9ce8Cxg51n1706WSOGxB7QvdhkjRjiajwiyaCklCRUyeA8yjKzOervwo8uvbnFYn2loydjGaeoYbXxUjp6cvIDFRERERER19T07RfXjgwY1KmKnAPs/mgXdt2xhWH3R6opJalPSSlJqG3LVzO6Ygc9wtV8/6U/sG356mbXrMkYzjtZY/mkewY3LriHNRnDXYhURERERETcEqmujWvvGNn5Nj8KZY8n4vUBYBtDWTTd5YhEEk9JKWkuFIJ7722xKPmpKty5EU/d0jx/NELhzo3NrinIzSTi8eK1LXxeT6ebpisiIiIi0ql973v037MdABuIGg+vTLvM1ZDcMGzuTJ6Y6LxvY9sEfnfPGXkmE2nPlJSSeKEQXHQR/OAHTv2nNv4jmDWvCLtuaR5paWTNK2p2Tf6eUgo+3kTm8UM8vuQuFToXEREREelMli6Na+7vnsHrmSNcCsY9+TkZjOzhPKJ7sfGo3q50AkpKSbw//hGiUbBtZ7e8xYvbNFzJ4Dz29MjkYNde/HjGLS3WlHIKnVsY0D+8IiIiIiKdzN6ZX4hrP3tOgIPHalu5OnWV7KhkZXoWAFFjWt8oSiSFKCkl8aLRMzrctuWrGXykgowTh1utKUUggO35jB36REREREQkJf1m9s2U9x4IwGs5E/l54CaumpjlclTJV1xewcazcgFYOu5Slv73n6Gw0OWoRBJLSSmJ161bfLtXrzYNV7hzIwYbD63XlCoZnEdoyDlEjKfVHfpERERERCQ1jV7+BLmH9gEwfcd6bv/wZe74whiXo0q+gtxMbL8fgDV5FzJs7kyXIxJJPCWlJN7GJkmj9evbNNyRggucGVBA2OvjSMEFza7Ztnw103a9j8+2Wp9NJSIiIiIiKWnGyiWYRu2Fxctci8VN+TkZzC8YBsA/nzeY/JwMlyMSSTwlpSReXsMsJRtg4sQ2DbcmYzgV3XqzacBwblxwD2syhje7pnDnRrxW9KQ79ImIiIiISGrqEq45abszOXtgHwBGvb5SO+9Jp6CklMTZVdPwGYWFYbed3qbxCnIzwRg2DRzJhuxznHYTRwouwDLOj2LU42lxNpWIiIiIiKQmM2niSdudSe+tWwDo9dzSM7Ibukh7p6SUxFlfFYkd1/r8PNd3VJvHTA/XMvrANiZ+/H6L5zftOdyoZZq0RUREREQklR2efglQt1IDOBzovLWUzvr7ywDOcsYzsBu6SHunpJQ0CIWY/beGf/R+POMWdo0+t01Dblu+mp61x5m0p4w/P/79FutFFe7ciMd2fgV5raiW74mIiIiIdCKH//IMQKyu1PZVf3cvGLf5fW5HIJJUSkpJzO5lK/BGGmZK9T1xhHMG927TmPUJppPtvpc1rwjL63UaaX6y5hW16Z4iIiIiItJBLFrEuA1vxHUdqY60cnHqOzF+IjbE/jBpkrsBiSSYklISE8oeT8TbkJkvzh5P5fHaNo1Zn2CyAY+/5YRTyeA8HpxyJQD/35Xfo2RwXrNrREREREQkxYRCWP/yL7GH0vrle7uHdd7ngZ1bPgacWWNRY1i/fqu7AYkkmJJSEjNs7kz+++J/jLW9HtNiYfJTYtuxabie2K+ZeMXlFdR66pJhtWGKyyvadk8REREREWn3di9bgceyYm2Dk5gaZqpdi8ltqweMAcACwl4/z/YZ6W5AIgmmpJTE8UUbpso++tgddC95q20DvtyoUF80CsFgs0tmVG7ltrVPA/Cr5/6Ly4uXt+2eIiIiIiLS7oWyx8eO65erhb1+TCDgVkiuy758BkfSuvHu4NFcf909jLxyttshiSSUklISU1xewZyyhvXcadEI4Yf/3LZBzz8fcH7BWF6fs61pE3ll6/BZTjLMZ1kM/dH3tPWpiIiIiEiKGza3+S57D025glczR7gQTftwzZSzOZHWhe2DcjlvweUsnJbtdkgiCaWklMTMqNzKhH0fxfUN6JXepjHLdh0E6j71iEYp3Xu4+UWBALbHKXR+shlVIiIiIiKSOvJzMmLH9SU/CndubKXoR+ewac8hjGUzatcW1j+1gpIdlW6HJJJQSkpJTF7ZOkzjXwFeL2fdfmubxjz04hrA+UHzWhaVK1Y1v6iwkJWXfxkA2xhIT29xRpWIiIiIiKSQRYuaddV4/cyfPMSFYNqHPStept/xSs7Zv5U/PXon25avdjskkYRSUkoaBALYvobd98y//RsUFrZpyO4XOa+PYgh7fWQUzWp2zeNrd3Jf/3wA3u83lLXf+Pc231dERERERNq5hx5q1tWjiz9uBlVnc8GuTRicB3V/NELhzo1uhySSUEpKSYPCQrZPnxNrWr/6dZtrOw26cCoAOwbksOE7Pybv6jnNrlmxaS8jPt0JQN6B7Uz8n7tVU0pEREREJMUdO3KiWd+Aqv0uRNJ+HC24EBtTt/uejyMFF7gdkkhCKSkl8XbsjB1a1dXsXraiTcN9/GIQgJz9O5jwix9RunRls2uKxg1i/P6tAHixnR0AVVNKRERERCSlRSoPNuuLWp25ohSsyRjOR5lD2J4xmBsX3MOajOFuhySSUEpKSUzp0pXkbN0Ua3uxWXvEnOQVn63m9TdjY/mjkRZrSi2clo190UUAWEDEGEpHT27TfUVEREREpH2Lpndp1lc2sHMnYQpyM4kYLx7bwuf1UJCb6XZIIgmlpJTEVK5YhafJXheDyz9o05j+/EnAyWtKAXTp3rVRy7BpTwu79ImIiIiISMp4YtqVsWMbiOLhr5cucC+gdiB/TymjK3aQU7WPR5/4Afl7St0OSSShlJSSmIyiWdjEz4zK7d+9TWNWZucCsHTcpfzjwp9yLP+8Fq87b98WoH6XvqgK+omIiIiIpLjNPQbFjqPGw11z/oXCG+a6GJH7di9bgceueyqrrW1zORWR9k5JKYnJu3oOJaPyY+2I8bI+cEWbxizfUwU4SamSwXkUl1e0eF2fuZcBzvI9fD6y5hW16b4iIiIiItK+TdmxIa7d98QRlyJpP0LZ47Gomznm8RDKHu92SCIJpaSUxJTsqGSfp2EZnW0MoVaSSJ9X9k5nBlTuwd34fa2vif648gQ2YHCKG5bu1fI9EREREZFUtuHsMUBDqY/i7PGs2LTX5ajcNW5wLzD1q1eM0xZJYUpKSUxxeQUjP23Yfc9rR8kvf++0xytdupLAQ/8NwL+veYBf5VSTn5PR4rW1a14BnKSU14q2WBBdRERERERSx9UlLwKwv0dfrr/uHtZljaFo3KDPeFVqyytbh6lbvufHIq9sndshiSSUklISM6Nya1xSyjIeSnLPPe3xKleswhuNAk6iqefaN1q9ttecmc49caaptlYQXUREREREUsANN3DRxtcAGHS0guvX/Y2pQzNYOC3b5cDcVTp6MpZxtp+qMV7tSi4pT0kpickrW4e30e57rw2dxMgrZ5/2eBlFs7A8zo+YZU6eaPJ5nSmqjf8rIiIiIiIp6pln4v6vf86HIe4oGuNaOO3FmozhBIflcyStGzcuuIc1GcPdDkkkoZSUkgaZ8fWe+o4d2aZPKvIG9cJT95vG6zHkDWp9PfTRl1YDWr4nIiIiItIppKfHNdO6dWu11EdnUpCbSdTrwWNb+Lyt1+QVSRVKSkmDivii5kO94baNFwzisSwAPLYFwWCrl2YUzcZGy/dERERERDqD/WePiGsfPWugS5G0L/l7Spmx9R26h6t5fMld5O8pdTskkYRSUkpi6tcv16vavgtCodMfMBBoWL7n8UIg8BkvMFq+JyIiIiLSCWytjX8U7f1RWduePVJFMIjHimIAT7j2pB/si6QCJaUkZrEZzFtDziFcl5jKfm8t1qUzTvuXQ+new9iWU6MqYlmU7j3c6rWVK1ZhsLV8T0RERESkE6js2lDawwDmM1ZWdBqBALanrtJvWtrn+GBfpGNTUkpiDHA0vRu1Xj+AU/S89vSz85UrVuGxnaSU17JOmmjKKJqFBdho+Z6IiIiISKqzunQFnP//t/m8Kys6gcJCgufNwQCljy6Dwv/H3n3HR1Vmjx//PHdmElogISAQSiC0SFFMgCQoGpoIikuxYv/al/1td8W2rlvUZZu737WhrrtYFgvlK6tI0+iqE8AACiIdQo1ASCAQSGbmPr8/7swkN5OESSEzgfN+vSJzyzz3BDIT75nznCcr0hEJcUZJUkoETU3rRvfiAzhNLwA+FKbLVe9fDgkTxuHzT9/zOJy1JppSu7RFKWvantMwam2KLoQQQgghhGjeBm5bB1Q07tjSta8kYIC8/CLWudoDcM2X5eTlF0U4IiHOLElKiaD0D98m9fBuYk0fAIWt2vHEmLvJS0qt13ipU8ez+tKrAFjyzGukGCz14gAAIABJREFUTh1f47n7FiwGbU3f016vtS2EEEIIIYQ4+7jd9Di4B7CqpAA+HXl15OKJIrk7CvEYTgB0eTm5OwpP8wwhmjdJSokKzzxj2+xYWszDS19k56Ll9RouL7+IdeWxeJXBgwfias3yu3sMDk7fM5XC3WNwva4phBBCCCGEiHJz5uDADG6u7DaQNeOvjWBA0SMzJRGvw0pKtVImmSmJEY5IiDNLklLC4nbD5s22XQpweT302fhlvYbM3VGI0+vF43Dh9Zm1ZvmHluzFEbim6WNoyd56XVMIIYQQQggR5QoKbJvFLeMiFEj0SU9OIM1RCsCbAzXpyQkRjkiIM0uSUsKSk4PW2rZLYzU7P9Kyfv2dMlMS6XrsIEqbpO/fXGuWv2fOh7VuCyGEEEIIIc4Oh1rZEy2HWyfQIS42QtFEGbebyz96G4C+999W75XQhWguJCklLMXFwSaDYCWkAtvddn5bryFb561i/OYviPV5+NebD9E6b1WN5x5ISa11WwghhBBCCHF2mDd4ND5l3YqWO5wsGDyaaWndIhxVlMjJwfBZC081ZCV0IZoLSUoJy7p1NR4q85o1HqtN0eJlGNq0puT5vBQtXlbjubu8rmCTQw0c3neoXtcUQgghhBBCRLc1Sams7dIfgH+kXY1jxAiZphaQmFhRLGCakCg9pcTZTZJSAoDDrdqF7AskieKyhtVrzIQJ49BKoQGf4SBhwrgaz+2S0jX45quAgR+8LaWqQgghhBBCnIUuyZnP0P3WbIz7Vs/nqlX/iXBEUaSwEB24MzIMKJTV98TZTZJSAoATew+E7FOACbiKal41rzapXdoGE00uhyK1S829qXZt3h1MgilA+Xwwa1a9riuEEEIIIYSIXtn/XWRrHZL930URiyXqZGdjGtZtus8wIDs7svEIcYZJUkoAcPz8QWgIfuH/0wA2++rZdDAnB6WtPL/h89U6H/rtNr0xlbLvXLRIqqWEEEIIIYQ4yyS67Nvx7WX1vYCl3xRU3I/5TFa+90lE4xHiTJOklABgrxkDWFVKlSuWfED7k8fqN2h2NloZ1ngxMbVm+XtMHMMH/S4ObitAnyaRJYQQQgghhGhm3G5af7vBtqttUqcIBRN9ihcvwzB9ADi0SfofHpMP6sVZzRnOSUqpWxvzolrrOY05nmi4tSkXMg6FRuM1HLhMHxpwAEda1jztrlZZWezuO5iWBfvo9OF7kJVV46k9ElszbM83IfsP7C6gS/2uLoQQQgghhIg21bTo2FN0ku4RCCUaxU8Yh17wIvgXjDK0aX1QX8u9lBDNWVhJKeCfVBTQNAZJSkWZvKRUdsd3oswZw+puA7lp3WIU4FWq/pVSQFnLVhxv15FOp3kTXbzhAJPLjofs96z4qN7XFkIIIYQQQkSZzZtDdhXvLZCklF/iuGyezbyWH7nfwodCxcRKXylxVqvL9D3VSF8iChWVenD6fPiUwYZOKfj80+48DhfbBgyt97jeMg/lyiAvv/Zm6RMGdam2IuukCjdvKoQQQgghhIh238WG/j9/rLc8ApFEp3lr9vLewGwAtnRMZuHtD0iVlDirhXvH/0Q9xj4PuAkIdK0LJKRC52iJiBtTvJ2kkkMklRzi8RUvkZfUnwGHdnH39N/ywKSx9RozL7+IFkeOkFh2ggd/9SoP/OoO0pMTqj13ekYP1rfrQNfjhbbMpcvpqNe1hRBCCCGEENHnwLGTnIe9l+2GCdfSL4IxRRMF9D68B4B+h/Lp/Y9ZcOsVkpgSZ62wklJa67CTUkqpgcBPgOlALBXJqBXAn7TWH9Y1SHHm3XpqV7CUzeXz0tZlYDoctSaSTmfnouVMObQTQ2teff0h3k/vTvoPrq3x/EVDr2DQPns5b4cD+fW6thBCCCGEECL6dCw6aNveHXcen142makRiifaTE3rRu4ftgHgQGP4PNJTSpzVGm31PaXUBKXUUuBr4A6gBeAFXgOGaK3HSUIqenWdMgEAEzBiYzHi4mhVdor0/ZvqPWbW7vUYWgcTXVm719d6/muDxlMc08q2L67osKw2IYQQQgghxNlg9mySigpsVVLPj7iWdXuKIxlVVElPTqDXtVcCYCqFdtW+irkQzV2DklJKqRZKqXuVUt8C/wHGYBXbHAV+D/TSWt+mtf664aGKM63c4eRgcl+Mvz5Dn29W4zK9eEeOZNdTf6nXeF2nTEArhQkQExNMfNWkU7sWrOxxQfAXVHAaX05Ova4vhBBCCCGEiCKPPx7SZHhLx55cMbBzRMKJVkeGWlVRxTGt2d6mA7tyciMckRBnTr2SUkqpJKXUk8Be4DmgP1YOYRfwI6C71vohrfX+xgpUnEFuN4wZQ6zPy3n5W/nu+VdQpg8Ah89Ht4d/yqb5S+o8bF5SKrvbdWJbYnduvvF35CWl1np+v05xzM6chs//qyq43GNiYp2vLYQQQgghhIgyxRUVUYHk1K1bP2XmxPMjE0+UOvGZlYRqX3acPof3kPzwT2H27AhHJcSZUaeklFIqXSn1OrATeBBoj/V+kgtcC/TVWv+v1vpEo0cqzpycHPTJk4D1j3neulXBQwpwAO0f+Emdh83dUUi5I4atHXqwunN/cncU1np+x7hY1nQ9n0XnXxq8tqkMKKz9eUIIIYQQQojoV2aE3n6O6CMfQFd18b6KtcGClWXz5kUkFiHOtLCSUkqpKUqpT4FVwI2AC6v90DxghNZ6hNZ6ntbaPHOhijMmOztkylzVstqE/K11HjYzJZHW5aWkHNnHsILNZKbU/gtnalo3FLBogJWU8qEodzjZ1D+tztcWQgghhBBCRJHZs4kpLQ1uBu4/SgdeEJl4olhMaUnIvpKDUfhBvdsN999vfUkfYFFPYa2+h5V80lTkKjRwEkgH3lSqagqjVlpr3bsuTxBnWFYWp3r1ptXO7TWe4kPhquOw6fs3YZYcpkvJYd6c+yjGPVmQXPOqEenJCdx7aQpvnjoOQE7KUJ4dcR1jEnpT+8Q/IYQQQgghRFR75RXbZqDZ+YEd++gZiXiimPFxTsi+lhu+shI/0bIKn9sNl14KXq+1/cor8Mkn0ROfaDbq2lNKU5HUbg0kAz3r8SWiTMzddwFW+ZvPMCr6Ofkda9Gm7oPm5KCwfsgMT3lYDctnTjyfy9OSAXCaXmKcxmkrrIQQQgghhBDR7RiO4OPATaXXcFCScXHEYopWpUZo7YjD64WRI6OnImnOnIqEFIDHY+0Too7CTUrtruUrv45fuxsvfNFYtrbrAsDKidN5755HQ44XdOpe90H9S5eagFmHpUxnxFvlqiN3rePNuY+Svn9T3a8thBBCCCGEiBp7VEvb9pEWcVw//Wm29h4coYiiV8e4WNu28n/h88HMmZEIKTy5udCtG1x2WfQkz0TUCysppbXuqbXu1VhfZ/qbEnWTl1/Ec8s3A/DrziNof/IYZpWuUqm7v63zG0teUiolMS0piEvk8dF3nXb1vYC2qz5HAwYaVV4WVoWVEEIIIYQQInqVnPLatld3H8jarufLrIhqtNbeavdrgB07mjSWGt16K1RtXL9uHezbB59+ak3tk8SUCENdp++Js1DujkJMn9Wj3qMMnjW7YcbE4PMfV4DT9NU5ObRz0XLiyk/SuaSQh5e+yM5Fy8N63gFHa8D/pmua7KJFna4rhBBCCCGEiC6dDu61fewdf7KENrEO0pMTIhZTtFrl6lDjscNDo6RnU1ZWcCZM5R4/QV7vuV1c8OCD0Lev9aeo1WmTUkqpD5RSs5RS7ZoiINH0ElrFYPgXTtRK8WVSKq888TKfJQ+x9gHKNCGxbp9iZO1eD1g/ZC6fN7h9Oq5lSypKVAHf+4vrdF0hhBBCCCFEFHG7ST5gr/Bpf/IYN2UkRyig6NayqDA0yeN3wBfuWmVn3qlVq4HQldsBcDrDbt9y1nnwQZg1C7Zts/6UxFStak1KKaUMYAVwF7BNKfUDpZSjtueI5qeotJyUI3sBSD24Ew18HJ/CoTbtgUpvMmvX1mncrlMmAGCiMGJjg9un0/rwd7btFocK6nRdIYQQQgghRBSZNSskcXGsTTwzJ54fkXCi3d7R1n1TdYkpj9ds2mBqsGn+EmKOl1R7TAOMHn3ursQ3e3bt28Km1qSU1trUWv8J6A28CfwJ2KiUuropghNNY0zRdv7fF28B8Of//Im0fd9S5jVpd+q4/cSCOiaHsrLwGA429rmALW8sCPtNKTf5AlsJqLuHND8UQgghhBCi2dq8OWTX8ZS+EQikebj+pd/y0PgZ5LfrHHLs49bdIhBRqKOzX6m+QspPL1167iZjPB77trf6HmHCEm6j8yKt9Y+AQcBGYKFS6mOlVNoZjc5PKdVJKbXW//gVpZRbKfVopeNh7RPVS122EId/+l6M6ePajR9x/bAeHIyrMl2vc+ibYm3y8oswtCanYyqT15rk5ReF9bwOvlNARYVWYFsIIYQQQgjRDHXsGHxoffisKJ9+c+TiiXJvrtzN3CETONqydcixvnu3RCCiUCfLfTUeCyar5s1rkliizqBBwYcaoE+fiIXSHNSp0bnWeqvWegqQDbQBViml/qWU6nomgqvkj0BLpdRUwKG1zgJSlFJ9w913huM7q4w5vxPTM3pQOO16TMAEPIaDpemXWye43fDUU6ddTSF3+2Gc2sRrGHi8Jrk7CsO6fm/f8Vq3hRBCCCGEEM3HnioLF63qNoCcRLlRr8niDQcA6Hg89EP91C5tmzqcah3pP6jGY8Fph9OmNUksUcXtpuzLNbZd5rp1527VWBjqtfqe1vpTrfUw4HasBNUWpdRvlFJtGjE2AJRSo4ETQIH/Wm/7Dy0FLqnDvurGvkcp9aVS6stDhw41dujNx623YhpWqzAdE8N5M+4BYNvBE5UajiuWf/udlYi69FJ45BEYNarWxFRmcjwAafu+Jf3A5rCXe93Xsl2t20IIIYQQQojmo3jfdyH7DpeURSCS5mHCoC4AHI9pZdtvAubNt0QgolAZcTW1YreSUp9nXAH33NOwi4RZDBE13G64+GJifRXT94L30/fd13y+jyZWr6RUgNb6daAf8Dvgh8BWpdTdSqnappeGTSkVAzwGzPTvag3s8z8+AnSqw77q4p+ttR6qtR7asVJJ6bkmLymVtwaPBeCm635DXlIqAFM2rAi+iFyml4lrl8Ef/2jNidUayspgzpwax22zOheAS3at419vPETrvFVhxbMu+2p8yvrRLHe4WJctLcyEEEIIIYRoruKOF9u2E04eo0NcbISiiX7TM3owu0/FYlQBCli4bl/1T2piXfvYe1upKo8zVy5h0/wl4Q12443WSu83V5rSWYdiiKiRk2PdJ1ehwNpfy73zuaxBSSkArXWZ1vpJoA/wf8BzwHql1PiGjo2VjHpOax14FzsOtPQ/boMVf7j7RA3mrdnLgbgOAKzqksq8Ndab3xCn/dOLC51lsG6d/ckbN9Y4bvHipYD1l+/yeSlavCyseNqOupQ5aVcBcOe0x2g76tKwnieEEEIIIYSIPiWt7TMfilq2ZVpadDTsjlaXH9oUchOrgAs+ei8S4YQoXLKixkbnCnCgKX7xldMPdPPNMHcuHDkCb7xRkZiaOTPsYoio8c03kY6gWWq0ZI3W+pDW+j7gQmA3sFgp9aFSqubJpqc3FpihlMoBhgCTqJiKdyGwC8gLc5+oweGSsuAbiqailNZzXkfbMqSe8zqCwxHc1gCnam5C3vbSEQD4UHgcThImjAsrnqLScna2TwJgU+feFJWWh/mdCCGEEEIIIaJOfLwtgeHokEh6ckLEwmkWsrMBqFp30/e8Ru+YUy/f7a5YmV1X+TPgoo/DSKAtWmQfZ9Eiq//Sp5/a99dSDBE1Pvkk+LDy30VwZfmLLmrigJqHRq8g0lpv1FpPBMYDXYC1SqnZSqm6Ld1mjXWp1jpba50NrMNKTN2ilPozcB3wPrAwzH2iBh3iYlH+MkOtVLCUdkMnq/lg4AW1oVMfDrRpb9t3IC2zxnGTRw4HYE3aZeS/9R6pU8MrnstMScR0OAFohS/sXlRCCCGEEEKI6HPQae+NdKi1JKROKyuLf2ffAFTce5mGQd8HZkQupkq2XFTRtrm6iikFxHjKoEuXWscpd8aEbj/1VMh5pfsLQvZFnZSUkMQcVPz9FL0bHVVu0eaMTWvTWi/DSiLdD1yJ1Qz9UaVUy9qfWeN42VrrY1hNzHOBUVrro+Hua+j3czabltYNw//ycTmMYCmtUXgYjfUi8ilFzFdr6bhuNfj3aWCX11XjuL7SUgDyho3hRPrwsONJT07gshYnAXj1fC2fogghhBBCCNGMrbvgYsBq1F3ucPL5iImRDagZyMsv4pGMm3lo/Ax2JFizSH5xxQ+D/X8jbUivDuGdWFApmVRN4/JSHLbTS5WD8mOhq6/vbB/90z2X3vLjYFVUsDqqkrI9e5o+qGbgjPZa0paXgb7AM1g9orYopW5twJhFWuu3tdYFdd0nqpeenEBye+vTi3/fOyKYBPokaSA+w4EGPA4XhSfKUdoErBeYqQxKMi6ucdxNOw8CsPbgSW56OZe8/NAlTavldjPmP9ac4ZSf3Ns8mtoJIYQQQgghqtV97zYAvurSjxtvfIpDg9IiHFH0y91RCMDcIRP49dh7ARiyfzM7Fy2PZFhBPfdsDdkXKFywaeOfbuh2wyWXwMMP2xqXb+g10Hb6VykX8sWlk2xTAk1g0fibGjH6M+PL/3wSrIqq3B4n8L2cuvX2Jo+pOWiSBuBa61Kt9S+xVupbAfxDKfVsU1xbhKeFQ2EqZatKir3kYuYNHI0Cbrr+t+ycMBVTVWSyTWVw7JS3xjE3+5NSp5yxeLxm8I31tHJyUF7/Mprl5dYqBkIIIYQQQohmZ9dTf+HaD/8FwJADW+h3aFdkA2omKrcwSS46AMD0dR8y9YHbouJD+/1GmBOg/vQn6885c8C0ChwqNy43iu2TmnzHj5M7+BJKXNb4CjD9hRLR7srVi4GKhNTutudRZjjxGA729RtMz388Bw8+GLkAo1STrkqntd6vtb4dGAr8pSmvLWqntUZXmQ0c19KF19/byWX6cI28hG96WplsBRimjz4bv6xxzP7trOdesfkLhhVsDr83VGJiRSSmaS0PKoQQQgghhGh24l58znaX8T9fvhfsYSvC09+fyHOgMTzR8aH9rp2hjc6rbmvg3Zf8fZQKqkxg8m93K9xn291v/zZ++tR9xHlOBvc5TR9XL3nD2njwQejbN7zkTjXTBc+opCTb5oG2HXGZXlymj65b1qO3bYNZsyQxVUWTJqUCtNbrtNbbInFtUb12hwtQaNsLdkzRdq7/eikA/3rnccYUbac43po7rLHeFHfoFjWO2XuvVdJ5/fqlvDn3UdL3bwovmMJCtPL/6lIKCsOssBJCCCGEEEJElTYnSmzbbU8eD/awFTXL3VGI4b8lWt/ZWoDKpxSmKya4Ml8k7es9IGRf1VX4FDBp7dLqk0JHjoDbTVLxQdvuLscOEeP1hDRPP+/4ESuZM2sWhJPcWbLEmi742GMwZkzDElNuN0yZAhkZ1sqANbjwr78DrOmGHsOaYWRg/T0EvgB49dX6x3IWikhSSkQZt5vMLz7A0BpzdMULNnXzGhz+EstY7SMu93PivtsP+JufA61Limsc1vX1OgAMXbeM/qb+aXgMq8rKh2IXNSe+hBBCCCGEENEr9jz7rIe2SR1lIaMwZKYkEuM0UMA3nXoDsHDgKOb/4V+QlRXZ4IChPeKDj00ILpAFcLiVdUwBDtNn3Qfu2hU8XwN8+inMmoUDM7hfYd07Vmdjv4vgn/+073zppZoDfPZZa9aNz9ewljBuN4wYAQsXwqpVcO+9NSamlq7fhwKOx7Ti5WGTSTp2qNqVCXE66xfLWUqSUoJ9CxYHX/z61En2LbDmwpKdjWlYPyLK4WCzL5YL92+2zgMcQHz3mpf4LE/uZZ2rlPXCCzOjP0cl8Ur61YD1ppT0q4ejYt60EEIIIYQQom4KMi61bR8de0WEImle0pMTeOOuTG7M6AFOf9WN1rRtER0JjV47NwYfV62QWtY3A7CSVU6HAdnZeHbvDZ4fbIiemxvWtTRQ6GwJJ0/aDxQVWRVM1d0r9u3rv5iCmAZUl33/+6H7fv5z68/K0wPdbkbffwMAceWl3L9yHrE+T/VTGzMy6hfLWSo6fqJFRB3Y8x1d/Y+NKtuBzK6pYdB32zD8LyuF9SZjHj5c47hG/i7rgdbWV5gU0Mpb5o9H4whUWUXBJwJCCCGEEEKI8B39PJfOlbYPrPqKmj/WFpWlJyeQnpzAmzmLALj6mxzK7/+cTe3fI3Xq+MgGl2atoOhTCo/Dxez0SQz8bgeL+4+g7alSwJ988npRCxeijoTeN+qCAlslUW13jEklh8DjCT2wcCEsXgwff2y/X+xtVZcxfDj85S/h30u63da9Z3a29ZxN1bSgKSmxkl0BDgdMmoTDv1J9IOnmadcOToSuQL8rdy09w4vmnCBJKUHC5g227fZbrO19CxbT2fQBYHo8tNiyxfamoQCjQ4fqB3W7abfw3eB52utFhZlYmprWjU9atQWsF7Ohpdm5EEIIIYQQzVH7A7tt2wl7d0UmkGas81arKsmBxuXzUrR4GUQ4KfVW7k6uB3bGJ/Hy8MnMHTIheGzOW48Gp/NpgPnzq52iVXVqW/D8avZnLHnHNkXQpqys5iKGtLS6JaRGjrSm/CkFL7wALVvCqVPBU6qNweezVX0FvofcASOYvH9XSNIluSAfxo+3+l4Jmb4nYE37ntVub/bFBn9AHGg8Bw+GvAA7/N+7oQO63fCrX6H8/ag04EWxqX9a2DG18ViVUgrAMKTZuRBCCCGEEM2N2037kiO2XaVt42s4WdSkfLg13cuHwuNwkjBhXETjWfryAq55+UkAehft44nls0nb923w+Af9LwYqJZimTg177GqTTlRpFF6VYTRO8/eZM60EE1gzfe67Dzp3tp1SYww+n20a48Zb7mO3zxWScAk83/fppw2P9ywhSSmBim8XfOwDjHjrF0X7k8fQ/peNieJwlx4hz035Ns/e6M3ttt4Qli61nffysMmsSOgdVjy5OwpZ2X2gPx6FxxkdK0wIIYQQQggh6mDOnJAbzr1dekUklOas7cgRAHybOYb8tyI/dS/uf/9ia+vi8nmYcnQrI/t24Mkpg4n/0QxKnTEcj23Nxlvug8mTQyqgakzuVKO2czXA2LE1V0PVoY1MyFQ9rdl98FhYTz2iKhJQCjj035V8d1FmRYxV7ExKCT+us5wkpQQp11wZfOxxxjDgRqvJ+LYBQ/E4rKZ6XoeTLfFdbc8Lvjm88krFzjlzrNUNKvGhONmqDZkp4U3By0xJJK/HYAB2JXThiTF3k5eUWofvSAghhBBCCBFNNGAqgxXDItwLqRlyxsQAsGXICE6kD49wNJB4tKI/VCA1tWPQMF67M4PpGT1I3vwVLb3ltC47wfmvvcDhaTfisJ1vV1PaKOx00vLloc3OAz2fCgoqmpGfTlJSyK6dbTqeNhYfinYH99v2Ze3+mh5XjSW3T3q1zz/Qsv3p4zlHSFJK0H3C6ODj4rvuC2bee00ay5Oj7wLgyTF3MfDg9mpfjEXxNfSVwnrx+RxOBk3/XthLv6YnJ3Bzy2IrhqL9PLrsRXYuWh7eNyOEEEIIIYSIDrfeillp5sUjl99P+TBZeayu8o9ZrU3ili/hD796lbz80ObZTembCdcCFYmWFzKm0vd7lwePj/nV/8PASjYoIPFAfq1Jnep6SdV2fuVjCsA0reKI6ixcCA8/DJdeWn1iKrCC3uzZsGGDfSVBl4sVmRNricTiQIckVk45Yyk56WH6tCeYPyAbs0rcnY5Le5oASUoJYl5+Kfi48wt/s03H+7azNeVuUME29vToD1gvpsAXwNpBIyoGu/VWa/UBKpdZao6d8tYppolHrQSYAbi8HrJ2r6/T84UQQgghhBARtn59cJpX4M/CE+W1PUNU4/jKLwEYs20Vr77+UMQ/sO8x88ds7NgTnzJ4PmMax375G6ZnVLR6SSwpCt4rnm51vcB9pVnNMU+Yk/yqTWDt2GHf9nph1qyKbbcb7r/fSlY9/DDcd5+1OJf/cJnh5K3bfsEvr+gfVgxVIzUvG8U3B6ypfz+b9HMeGT/DdvyjiyeFNe65QJJSAs8779i2j74+F7B6O/U8vAeAqV8vJ+uDNylo3Z6TTqt8VGH1oOrvKKt4clYWTJ4c3FSAw/TRZ+OXdYqpc4o1VVBjZZ679ulWp+cLIYQQQgghIuv4c7NtN+vXf72MgV3aRiye5mr4gc2Aldhz+bwR/8A+ff8mUg/vxqFN7ln3PjMTim3HzbSKBa5sq/BRffJpT9vz+LLrgJD9Rhg5KQ1opaziiMpWrgw9ecsW689AH+QXXrCSVQBa235WY00vU/7xe4rnWvfKge/BVklVQzwAM3uPZ8KgLhWX7tgTU1npF4/hZEdn6a0WIEkpwRp/pVPgBZQ3bAxg9XYaeGgnYCWGHF4v2jDY065T8HwH4EmoMi3PqPix0oBDa460rNsvn6I9BwDrxW8qxb5te+v0fCGEEEIIIURkHaxSFFXmcBHX0hWZYJqxomHW/ZoJ+AyDksyLIxrPvgWLUdo/MbO8nH0LFtuOl3/2BVvaVxQVmFSsnldd5dSPr36AomruF3WYTco3dugZ2oP4WDUNyjv4287k5IT0Qa5KAS7Ty66DJYDVN8pXJe7KSaqqDh0vY3pGD56cMhgDyNy9HuX/fgxtMv3kztq/qXOIJKUEXGfNCT7cqh0vZV1Dux9+H7B6O3WdMAoArQy0y8VJZywObeW3FeBTis3f7LKPt29f8GEgo9z+ZHirFgR8mXxBsIzTazhw+xufCyGEEEIIIZqHo7Gt7dst48Je/EhU2H6kFAgkdBQb9tft3qqxuXsMRitl9Q+u5l7t8j/nkOC//6uciKou/kDgAAAgAElEQVTaBgZgd9x5rOl6Pt2OfhfcFzh+ytUirGbn5x/exep/v2/f6fOFnnjAKnwIZ2X3wHW3t+sMwMe9h3LdzX/gofEz+LTnRTyfMY0SZ2zI8wLf6+WHvgVgekYPdjx9JVf/aDqmv/m6zzBoMXZ0yHPPVZKUEgzaY71gEk8e466175O+v2IpzCMDhwCwe9QVLPzjHMpcMRS2ikejMAGPw8XalAvtAxZVNN4LlGvWtVJqcPd4oOKNd1CSlPkKIYQQQgjRnMQ67Nsd42LDXvxIVMg6YN2fBVqjRHr63qCktqAr6oWq3qvtP1pGYjVFCUdjW/NixjT/syzPj7AKJBJOHrMloEqcsbyWdqXt3Moq96wytKbXhtX2E44fDz1/61bIyAjdD3jbxIVMzTs8YAjTPp8PwMhd6wCYO2QCt13/G2Zl38EFP5vH5vbdbWNprOl59z1+l+06G/Yfs6YZVtoWFklKCVq/txCwXsyGp9wqZwTy8ov438+saXOzW/ShfFgGDtPHkVbt2N2uE8Ut4nhizN2UXDTMPuCePcGHgZddXSul2uV+HsyqO31eEue9VY/vTAghhBBCCBEp7Vz2282OcS0iFEnz1mHSeP8sEoURG0vXKRMiGk/q5jXBlfVcaFI3r7Ed7xrfgsKW7UKanbfwlrO8b2aw2uih8TOYO2QCw3smsPgCq3Io8JzX06/iD9l38HzGNNvKdZUTVJWTQKpK9dPxI0dt28G+VqtWwcyZtv0AjuMltqmF5crBkpguGP6eU06fl8xqkoHftbWvRH+4ZTtumP6U1Wu5kqzd6zFMa8aRwzQjnliMJpKUOte53cR98B7gX/XAMILljLk7Cjnlb8aWvWUlMatX0sZzigGHdpB8tICEUyU8sXw2t+j99jFjK8oYA28ada2UcvcYHHyugSbhnTeqX8JTCCGEEEIIEZWOnzxl2z560hOhSJo3lTUCj+HguyHDMD5aEZLwaGqb+qcFZ86UKQeb+qfZjn82cwwP3/LrkERSrM/D3DcfYkvHntx2/W+YO2QC7Vo6efu+Ebw1bQbPZ0xjZ3wXns+YxqzsOzAUzMq+g22J3W3j7257Hg+Nn4EPRXFsG3457l629rZPIfR6Qld/Dyadqq7MR+jqeTHax/VfLanoA4XmshHnMz2jB8ntWxHjsJ7R5tQJe2ztOrGm6/kh45dkXozPsEoHvYYj4n3BokmTJ6WUUm2UUnOUUq809bVFNXJyUN6KF6zp9bHJv3RlZkoiAw/vAqzlRyf/9Ga6Hj1I96KCYBVTjM9D6rKFFeO53ejCwuCmwuoLVddKqfNXfRT84VSAo1IFlxBCCCGEECL6HXa2sm3vi5WWHPXhchp4HU4Opl4Q8YQUwIqE3hxu1ZaTzlj+mT6JFQm9Q85Z3aUfL2RMs1VLBZqH37NyXvC84b2sHmMnyr3Myr6D0fe+xKzsOwBo39pa9f3VoVcDlab8ZV3Llo49caBpV3acx1e8xJii7bbrxzoq0kwhVVbTp9f4vVWO16kr1gr0oTAPH+bJKYP55Bej2PK7iex6+kpSjh6wVW/1Kj5A3472Xmpg/Z29O8haUOyFzGur/Ts7V4WVlFJK/UUp9VelVFwjXNML3AxMboSxRENlZwcbrln/1RQtXgZYjc4faHsEsDLDhtfjf2x3cvnHwSqmQ39/KXRFBWWwbcDQOoXV/cOFoTsTpSmiEEIIIYQQzYXzhNXXRwPlDhcrho2PbEDNlMuh8CoHuprqn0i4MncRHUuP0spbxn0r53Fl7qKQc46e8jFm6yogtAop5Yi1MJbTgPsus5IzLZ1VGpABF/Ww+o/NHTIhZMpfYCqdAcSYvpAphC2HWtVbVaf7lQxJh8nhpyICzzcdDhImjAs5XnTZGNt57n7DWPaz7JDzxhRt55pvVgBwf+47IUm0c1m4lVK3AT8AGmP9zjL/nycbYSzRQEu/KUDrQDoKfIbT9mJrN/FywKp2MgnNNgO02LYZRo0Ct5vthfaGctbJmrYtnHWK65Sjmh+1ShVYQgghhBBCiCj24IMM37QquPmf/hdTMOCiCAbUfLkMA5/h4GBhCXn5Rad/whnWM+dDoCLZFNiuLL6lE1U1G+XXoX0cD4zvz1v3jgg2vr9zZIrtnPsuTeHey3oHp8kFGozPHWL108r1t3sxgXKjyhRCtxvtn2Wjgd1xHYPxtlmXx7Ef/+y032PVflgONKldQiv9rrv4+8wfkE1RizjmD8jm8WtnhpwDVh8up2mtCOjSoUm0c1m4mYKTQDvgFIBSahiQ6N/vw/pZqCuZUBwFihcvQ/lfciaKFZkTmTi14hOM/OIyuuKfQqdD/5mD7zNlZTBnDuuyryZzyTu24waauJWfw11Two6rwNGKjlQ0pNMoNvdPI7WO358QQgghhBAiAubPt21etH8z/3ukNELBNG9r9xTTw+HgUPEJfvhyLm/clRnRVQx3ZV9B8tKlwcTNruwr6FnlnHWPj+dXq6fw+Pt/C3n+cW0wY1Qf277pGT0AWLzhABMGdQlu//ueLO7+12qOlFakDzq0iaF19kgOzU9AoXnm0pvomtA7eK946O8v0dH/WAGJp44FH2vAtXFDjd9b4ByP4cBl+oL3u4ZpWu1kqkyfPFHm42eTfh7cblnmq3bcTf3T6GU4ifV5MDXspkXI39m5KtxKqcBPQKC66YfA+8BHwCfAf+v4BdWv7CiaWPyEccGGax6HE+ftt9mOez76GAgtuaxWQQHFF6TbdgWblXfoEHp+LRam2Ut7Fwy4TObdCiGEEEII0VxkZNjuIdYm9eeKgZ0jFk5zlrujEGWaDCrYxqD8b8jdEdkZJO9nTqLUGcv+uA48fMUM3s+cVO15PR/6sW0GTODe8IPhE6s9f3pGD167MyOYkAKrpczPx9tLE346rj+PJBTTsbSYDqXFPLbc3lOqoOSULdlw3GXvbabia07oBZ7nMu3JJa8yWNoxtERi/MBOtW4HrEjozatpVwFgaJOuj8+Uhbz8wk1KaQCtdeV/WwXs9n/56rgtokTiuGxmD58KwE+u/jmJ47Jtx1uPHwtYpXCBXyq1ZRPdVd4gA5lm8/DhOsX1afZUnq/UGG/ili9k3q0QQgghhBDNxL6kiulYPiB28CBmTgxdlUyc3pii7bQ/eYzBBdt47d+PRPy+KKFVDIbW7Gt7Hps79CShVUy15xX+5e+08NknSM0fkM27aRPqdL3pGT14cspgRvbtwJNTBjM9owdxuZ+j0BiAy+clLvfz4Pmu22/D519Fvtzh5JmR0zGx7ku9ykHRVafvKVW1KGNL+268ppJCznvmhouYPCSJ+FYuJg9J4pkbqp+impmSyKCD1qp/BuD0lHPw2dlhfPdnv4asvqe11r201r2A7XXcFlEid0che+OtbO76Lv1Csu6lacM4FtOKdV36B/cdbB0fkpjSAJ07E+s0QvYr6l4p9T8X9+J4rLVqgbXKn1fm3QohhBBCCNFMrCqpuK13AJ6E9pELpplL3bzG3xYFWkRBP6KY1bm08JUzdN9G3pj7CDGrV1Z73vSP3gxJ7rQvPUqvjm3qfM2qVVTuHoMxlcLEmvHj7jE4eG7q1PGsv/IGAG6/5gnmpU8kLymVMoeLl4ZP5rtPcsO6ZuXYBxzOZ+Yn/6z2vGduuIh1v7y8xoRUwHFXS9v2d8fKajjz3NKQpJQ4C2SmJOL0p5gMp5PMFPsKd2t3F+N1OIgrq2hg3r60JJh5DvBhsGncZEYX77DtV/ibjtWxUmp6Rg9GDO8HWIktQ5uy+p4QQgghhBDNRKuS4uAH2T6laFVSHNF4mrXsbLS/E7CKiYHs7IiGk5H/dTBJ5vJ5yfKvhFdVvC4PKWbI2rMhuOJeQ/SaNJadCUkci23Nk5ffS69JY23HS09aCZ/rMpO5rHAbF+3fRKzPw/0r5zH421XVDQlY9641GfjhvHrHm7ujEHfyBUDFzKO4rGH1Hu9sUmNSSikltZXngPTkBC6PsRq/zb7ACGmYN+7oDhJOltDbv2wngEP7KHW1sJ3nwGTVfz5h0pEttv0aMA0nJRkX1zm27tpqYaYAUyn2bdtb5zGEEEIIIYQQTS956kRMZVhNox0ukqdW30dIhCEriwMJnfiuRx9YsSKk2XZT6zgx0OJFQUwMXadUPx2v5T13hewraNexUZq0p+/fRK+iA7QrO8HjK14iff+m4LGlLy9g+McLAbjigf/hpx+9igPrvlJhVe7VRCsH++Kqn+Xj8XjrHW9mSiLx3or7W60MelrryJ3zaquUek4pVaiU+gzoBKCUekop9SMgpZbniebE7ebiD94EoP8P7gxptjZgS0WpaIAC4spDV844//PleBJC32AMbbLj8Ik6h/ZBYv+KZT4dLt5r36/OYwghhBBCCCGa3on04azsPpDCVu24dfqTnEgfHumQmrUTMa3Y2a4LeUmRX498daJV6bQroQtPjLm7xpgmd5/E/AHZwW0f8PztjzVKDPsWLEZp05piV17OvgWLg8eKFy/D4W9U7vJ56XR4f9jjOrWPriXVz/IpbdGq2v3hSE9OoMc1V/nvbxVlDieb+qfVe7yzSW1JqUQgARgBtMDKRfwC+DMQ2dSsaDw5ORg+f5Gix2Mtc1mJGjUqmBgK7qP61fjyho6ixL06uK2D52l6bVhdzTNqtzd1CIdbteNQ63ieGHM3e/tfWOcxhBBCCCGEEE0vd0chxS3iKGzVji+7pEZ8xbjmLC+/iHIUJ0pPcdPLueTlF0U0nv0fLAegZ9EBHl76IjsXLa/2vA37j/FG2pXBbZ/DReGJ8kaJwd1jMDpYiWfvKRVYYT5w7IuM8TWOE1DbYl4B5gUNux/d0fcCPIaDfW078puxd8vq8n61JaU2AZ/4v8qw/p2KqD4fIZqr7GxMwypg1C5XyPzkTQeOAcr2j64JfdGWK4M1468l/tgR2/6GlOveovfTsfQo550o5onls7lFh5/hFkIIIYQQQkROyUkP7U8eI6H0GBft+5aSk57TP0lUK3dHIV7DwGmaeLxmxBN8Q/M3AGCga+0pNSipLZmVjjl8XkYVbGyUGHpNGstnyRdQ1CKO26Y/aespdfldU/gibTRew8E7T/+Txb2Hh/REriq4anw1xzSglSLhV482KOZxR3fgMn10PXaQx5a/FPFVFKNFjf8yWuvrtNajtNajgAL/vg5AS6D+Hb5EVMlLSuXNC63M8R3THg8pvSxavAyFDklKFcXG2c6L0SaT3/4bxW3ibfvXdenHXx96ntSpp89OV5W6bGGwKivG5yF12cI6jyGEEEIIIYRoekdWfMLwPd/QsbSYN+Y+wpEVn0Q6pGYrMyWRFp5ykov2M6xgc8jiVE2t7ehLgNP3lFr4g0vQ7RODBQ0ONH3O79locfgMJw7TBGWvm8nLL2Kbak2ZM4Yni+OZeHgzStdcC1X5yLb23ZkzZKLtmE8ZPHz593m6KD7kuXUxcMtawErCxEbBKorRos6r72mty0A6cp0tcncUUtDGelNbVU1ZrdHBavJW+YWqgK0de4RUS2V8sYQTvfvZzn/nwssZd+eUesW25buSWreFEEIIIYQQ0Skr/ysM/4fbLp/XVjEj6iZ9/yb6Fe6mZ/EB3pz7qK2pdyR8ldgLgGV9hnPzjb+rtc/VkNY+/J2f8ClF8Z4DjRLDzkXLuXTnGtqWn+Bfbzxkm0KYu6MQh+nDpww8XpNTl1yKz+GsdbzA/eucjO/xzMibgvtLYlpx3U2/Z+6QCbyWm9+gmLcNGBqsxipTDukp5VfnpFRlSqlblFK3Au3quC2iRGZKIk5tFSkaMc6QrLt52GryFihnBKtB3bYOPUJLG51OHGvyguf7gKFtzHqvrvDv1Gy8/ut6DAf/Ts2u1zhCCCGEEEKIptVmdHbwscfhpM34sTWeK04jJwelrQSf4SkP6QPc1Dbstlq2mMrA66t9OuGOQcMod7rwKgOPw8WOQcMaJYas3esx/I3OXV6PbQphZkoinUsO4/R5GVawmfJhGTw96o5axzsa25qHxs/g3bSJTNpYUdUXV15Kv0O7APD4qpvcF76PEnpT2Koth1onSE+pSmpPF1aoLnmlgH9W2VfXbRFh6ckJnFLHAJiX7iK1SgKpS0pXoHLTcmsJzT3J/XmkUwpPLnkWw3+s/aH9tCv8Lni+A6BD9ctphqNXYmvbtMFeia3rPZaIUm639Us1OzviS9sKIYQQQojGs8CVxDj/4yfG3M2RmO5cHtGImrHsbLRSoDUqJiakD3BTyzq8DYDLt+aSvTOP/MmDgT7Vnjv8xiu57dsnGbrra77seQEP3nhltefVVdc+3YK9jh1ouvbpFjyWvn8Tvm0rMUyT1//9CAvTu1OmHLWOd8LVgnnpE7lyUGfGvrHKduyO1e8xd8gEJg7u0qCYxxRtJ7G0BNA8tvwl8u+eRE1/b+eScJNSLgCllEtr7QFOAt8BpVgFMb46Xrc//pyFiDC3m8zP30cDqTdPgRUrbMkBV5G1skPV7vZ3tT7KsNRptC89xi/++1rwHMO/9Gagsmrwd/Vv3tZv6YJgwstl+ui3dAH87MZ6jyeijNuNmT0Ko7wM0+HAeO45uOeeSEclhBBCCCEaQfxXecHHTyyfzWMDBwFDIxdQc5aVxdYeqXQ4Vkji+wsj/mFu761fA1YyqEWwN1L1PYTTkxN48Nf/Q+6OQh5MSaz3LJqq9m3bSxes6hmfUhRs20vXwLEFi+li+icNlpdzwUf/x6SP3g4Zo3I7mgNXTWPuPVmkJyfw9sdXoWevC/Y37ndkD78vdHP9Db9tUMxxuZ8H+zW7fF7icj+HevRePtuEO32vpf/PFgBa63u01l201r211v201ufX5cs/liSlokFODsrns5JI5aGloO4eg/H5l9qsrGNpEZcP6GRl7Cupet4pb/1LHKsMHbItmrd9CxZDeRkAyufDnDHDqpwSQgghhBDN3m0rFwQfx/g83PBtTuSCOQsUt47ncKt2tfZvaipbu/cHrOl74VRupScnMGNUn0ZLSIH/PtW/iny5w4W7x2DbMdN/D+txOCnzmjh9oas/auBAXAeez5jG69+7Lxhfdt/zQooyRi+Z2ygxB6q7TKVsMZ/LakxKKaVcSqnAJMfZwJ+pfoXEOlEqWDcX09CxRMNt6p+Gz3CggVPVNFsrH5bBR72H4VEOW8LpUKsE7r2sN2O3rrSdH/iBCqxS4Lr9tnrH1u6eO4MJsXKHi3b33FnvsUT0WdS+X3BdRwXg9UV8frwQQgghhGgEbjd9v/yvbZfL2aB2xue0vPwijno0Po+Xm17OJS+/KKKx/G63dUv/nwGXsun1BRGp3Oo1aSwf9bb6Uz095k56TRprO+ZOvoCiFnHccfNTrL1sUkiSSQNHYuMY8f1/Miv7DnK2HAoec/z9ryHX00eONDjmoSV7bTOBhpbsbfCYZ4Pa3hmuBtYqpR4CntBaP6C1PtEI1ww0BoprhLFEA61I6M37/S/GYzi45cbfhTRbKyotZ3/bjngcThRWVrLc4eSTrAmk79/EkAObaxy7JKEjqQ0oR0ydOp7ckVehgJ1vL2rQWCL6WJ8S6OBjhYbEyC5vK4QQQgghGsGcOdb/2/n5oEEfVp/rcncU4lMGDtOHx1t7Y/GmiAWPF4D/9L8kYs26W+etYvT21QDMXPEKrfMq+kClJyfQreQwbcpLuavwa5bFp3DKGVoTUxrbMvg4u1/H4GPXoUMh55bFtWtwzDH/t7DW7XNVbUmpHwBtgN8Cu5RSjyil6t+1ukIJ0Aurr5SIsMyURI60TqDMGcOG5IEhq+9lpiQSf7KEll5rmtV/e6Vx441PUT4sw5r6V82YgV8/+6+c0uD4jnTuDkDpoAsbPJaILlm71wffgII/R2vXRigaIYQQQgjRWPL/+6XtPsFQitQubSMWT3OXmZJIXNkJOpwoZljB5pB7tqaOJTZwx+cMXb29qRQtXobDtCZyuXxeihYvCx774pq76Fm4F5fpY8yif3Hdu89ypEVoTczGTikATB6SxDM3XBTc74xxBu9pgyvQ//CHDY55cb8Rwel7gW1RQ6NzpVQskI+VQIoDOgC/Bh5RSn0GeBtwTQNr6l6sUioGiNFaS8YhQtKTE/DqElymj4UXGSGr76Xv38SFmz8LJg9al5UCVgXVpv5p9DYcwebmYFVSGYBXGXw7fDQDGxBbXn4RRTt2A/C/T7zCD578fqPOQxaRdaRl25Ck5p5vd9I9ItEIIYQQQojGsGn+Evp+86Vtn9KafQsW01VWW66X9P2b8OV/jYHm9TcewnlPFiRH5u8yPTmBn3Q8DsDdXXwRuz9LmDAO7z/+SozpxetwkjBhXPBYt48XAxWLb124agXxLVzo4/YFvGZnTCO+pdOWkAJw3XUn/PEPweRRXuowhj70kwbH3HLG/Xy17F0GF2znxYypxM+4v8Fjng2qrZTSWpdprW8HOgHTgcX+Qy2AMVit9QNfV9Tx63IgG8gC0oFBjf5difC53Qxd+wmx3nJr9b2qjaZzcjDMilZiafs38cbcR+i7fX1w6l9lgTmyCuiz0f7LqK52LlrOjWs+AOD5t3/NzkXLGzSeiC79HWUhjfHXe1tEJBYhhBBCCNE48ud/UO1N5mZfbJPHcrY49PeXMPzdWB2ecg79/aXIBeN2M+KvvwYg/fnfR2yhotSp41l7sdXeZe3t/8/W6mVnbyvFoCttzx9wqW1fqcOazrfu8dAWMaMSx/N8xjR2xnfh+YxpXPO9x7n1lZUh59VV2r5vGXhwJwaaO/IWkbbv2waPeTaotlIqQGt9CpgLzFVKDQWeBkYTaAFjFcbMAXbV47oOrCRX69OcK86knBwM0xdcLpOcHFujOqsayghWQxn4l69c+TmZ47LxloTOZ9aAz3CwbcBQhjQgtKzd64MlmU6fl6zd64FrGzCiiCZ7Ha1IqrTtVQ6+Hn01EyMWkRBCCCGEaKi1KRdSXSfY/o6yJo/lbFFQcooOVbY71nj2GZaTg/L3lFJeb8j9Y1PZNH8JF32+BICL/vk3Nk0YF0xMJV86DFYvRWFN8eqTncFtRgbHy3xc9/VSOpwsoZWvnDfmPsKmKYNDehfvKz7FrOw7mJV9R3Dfql0Nb3RuTTm07r2DUw6lb3LtSanKtNZfAmOVUmOBPwGDsRJT1wCPaq1DW9SL6JedjWkYGKaJdsVgVFnOc0VCb1ZfcDm3rLOK5XwoPP7yyNTkBArN4zUMrGnbIuwfr2p1nTIB75+fAp8XXC66TpnQoPFEdMnfspthVJTQvnXh5ZApJd1CCCGEEM3ZRYv+HbKv3CH/L98Qrttvw/zPWxjapNzhimzT+OxsTKcDh8fEdDhxVLl/bCqBBA+A0+ezJXiK9h+iJ1axhAPo2qcbbfc7mZV9Bwknj3Pj10tqTQx1jW/B3uJTtn3De7ZvcMwJE8ZhvvIXDG3iMwzblMNzWZ3X5dRaL8eadvcE1kIKrYA/K6U+VEpFLGEr6icvKZVPeqZxLKY102/4LXlJqbbjmSmJ7G3fJbidO3Q0+W+9V5FN9oa2F1OAwzSJW/l5g2N7e7C1tOfzw6eFxCaat/gJ4zBVxVvQ/EGj+ebAsQhGJIQQQgghGir765yQfQvv+EVEqmnOFqlTx7NmyEhOumIjvip5XlIqvx95KwCPjbs/YvdoCRPG4XM4AGuWTiDBs/TlBQz+92yg4sPv3W/M49U7hgPw7Xm9ACth5anSiyrgs5lj6BZf0Vbk0r4dmHNnRoNjTu3SFqWsqJyGIc3//eqclALQWnu11k8AFwO7sf69U4DzGjE20QRydxRS1DKOYy3bsLpz/5DlRdOTExjuKg1ubxgxnhPpw4Pbezsl284PrCbgcTgpybD3m6qrnYuWc816q4/UPe53pKfUWebyu6bwad9hwe01Xc9nwqAutTxDCCGEEEJEs6UvL8Blhn5oPezzDyMQzdml7LwueJ0xEU1IgXX/qHxWi5Vy/3YkpE4dz6q7HwBg/UO/Df69FC9eFpLkKN+zl/TkBObdPwLnACuJVtChq73YoorPZo5h19NXsuvpKxslIQWwb8Fi8Len0V6vtS3ql5QK0FqvxqqaehnI1Fp/0yhRiSaTmZKIU5v4lIHLaYQu6el2k7383eBmv0Vv8YdfvUpefhEARtlJ2+nFsXEcd7XgiTF3s7X34AbF1mfjlzh8Vkmmw/Q2uHG6iD7H4irKYF0ORf/OoUu1CiGEEEKI5qF48bJq9/fctCZiDbHPFtrptK16Hiljirbzs89eA+B3S55jTNH2iMXSclgaAAlDKu474yeMw/TXSAWamhdefwtgFVz8cqKVlOqSNrDJE3zuHoPxGVZ1l9fhxN2jYffLZ4sGJaUAtNZHtNb3aK0b3vlLNLn05AQSWjhQTgdv3JUZuqRnTg6q0pvfZTvzePX1h4JVS7vi7MVxCWUltPGc4vEVL9F3+/oGxbZtwFC8jkBfKsWRllLeeDbJyy/i/F0bgts+U0fskxYhhBBCCNFw7T2lwSlTlSmwGmKLenMdPkSMp4xN85dENI7UzWtw+u8PXdpH6uY1EYtFxVgr6JllFU30Lx/YGVRFUmrjLfeR8dTMiif5ix7YtavJE6W9Jo1l4cBsAJ4dcT29Jo1t0utHqwYnpUTzF4PG4XSGJqSwVt/zKkdwO7D6nrUSHmzpOTDkOYGmcQ3tKdVr0lheHfY967pak/3c7+QTlrPId3/4K/0L9wS3b1j3YWilnhBCCCGEaDbO27Ep+FhX+lM5nRChhthng03zl5C+ejku00fy9VdHNjGVnY32Fw5opyui/64q1kpKUSkpteY3f8WhrSlyCig7XGR/0jf+yV1btsCoUU16f9k6bxWTv8kBYMbnc2mdt6rJrh3NJCklMHy+YJO4qlYk9ObFjKnBbRMwYmODq2eMKt0b8pzG6imVnpzAyKSWVoxolKdcPmE5i/T+1N5b4Np1S9hcUBKhaIQQ0SIvvysJS7EAACAASURBVIiHF6znkQXrg1PFhRBCNA97R9lX2DPxJ6T+/ndpdN4AgZXmbCvGRUheUirPZUwD4MdX/TSii1HtOW71L3O8NTeYXDq+235/WnWbJZUSemVlMGfOGY2xMuvf0YrZGeF/x2hS56SUUqqVUmqkUmqAUqqTUsp1JgITTUeZPrRR/Y9CZkoio7ZX9HJSgDFtavCXisvpCH4KEnCgTQduvuF3De4pBXDkgnQAfChOKQeb+qc1eEwRHT49f4Rte9B3O1jw7Dvk5RfxZm4+f7v+52wYnMmup/4SoQjFuS4vv4hrX/iCzCeX8/QH30Y6nHNCXn4R17/oZtP8JbR75o88/ct/SHJKCCGqyMsv4tmPt0Xle+PhE2W27Y3DR8Onn8I990QoorNDwoRxwV5ENa0Y11RydxSyp63VwmVtp74Ra7+Rl19EzsJPAUhe8n+Yo8eA202bHl1t51XdpnPnpgoxRJeUrsEEjANNT6cnYrFEk/pUSnUHPgHWA/uBU0qpEqVUvlJqnVIqRyn1nlLqdaXU35RSjyul7lNKTVZKpSul2jTqdyAarM3xo7QtKa6xdLH/oXzb9qnPK85z3X6bbXofwP62Hfim58BGmYq1+ry+AGzt0IPfjL2bFQm9GzymiA7eW26xbTu1jztz3+WFT7Zz9Ic/5f+9/ScGblhJ8sM/lcSUaHJ5+UVc98IX9F74Jr9/6RcU/+1ZSUw1gdwdhYze9DnzXn+An306h9ffmMm385dw08u5UXnzJYQQTe3Nlbv53aOvcOJXv+Gpx16JqvfGvPwiRr37sq2nVOtd26VCqhGkTh3PquyrAch/c0FEV+DLTEkkxj89znC5ItZ+I3dHIQMObAWsBA/l1qyatMd+jIlCA16ni7THfmx/4owZEBNj9Z2KiYFbb22ymF1FRZiVtju9/Jy0p6Fh0/dUpa/WWMmqC4CRwJXAjcAM4JfAs8A8YBVwVCm1Sil1cwOuLRqL203/XRtJKD4EY8aEvChW//t9DG1f5WFDZkVDttSp4/mq70W2451PFFXfNL0ehp88AEC/w/k8vuzFiK7uIBrXNV8tDdk3btsqLlz8NvesXhB8cwFQ8+c3aWxC5O4o5No1i3lqybNcumstTy15Fs8LL0Y6rLNeZkoi97vfQQEOIMbnZeqGj/B4TVkIQQhxzsvLL+Ldv7/N268/wAOfzuH/s3fm8VEUaR//1szkIBAghPsKhPsUiUqyKqKAvLgeiKursrK6q6zX7uq6oHiiKwrrsb77gusB6nIfCqICcgkikgQYQCEQBBImXOFIBgKEHDNd7x89V0/3hJxMIP39fAJT1dXdNT09PVVPPc/vmTfzWRZNXRjubvnYNHcp7c6c0NQ1KjBzYVUX7vYdAOh+201h7UdSQhwD2qkJqN4ZlVQtc77KkJwYz0/tegBqVA2RkTBoEPbW3clokUhhRBQThj6qDy9MSVElYSZOVP+/iEbTr5t0RRGqCUYAuBVTnoaqGaVOAe8AHwJzgK+AdcBWYD9wEnCjNV55/64C/iuEeLYK5zepDtatQ0g1aaYs0Ws2ddy52Ze9AGBvkzb88tQLmjb5TVpoytIiqu3h1Df9O0C9USPdLrqv+rJajmsSfuSXSzRlAQipcMsvP+KVxvSGhp7t0fui9s3EJDkxnmd+mKkxjj64fm44u1QnSEqIo567RFcfYbOYiRBMTEzqPGlZebz27fvYwGO8V3hg5uRwd8tH+6/1BjKbTujDpNLYPOLiLleYOwJt8w4DcGWe4wIta46khDiGPXgbAI6BN2P5bg2kpLB57lJ6HcsiprSYl1d+wOa5S/U7p6TA+PEX3Ysvp9sVvH29Gi2iAG6rmQAAqmiUklKOlVI+JqX8nZRyhJTyJinl1VLKrlLKFlLKSCAO6AkMAR4FfvDsL4BnhRCRVXsLJlUhs1t/FKG6NxppNiWMvAVXgN5UR2cukZvTNW1cV12tKUe4XdWWEUJE2KrlOJcbk5btps8r39J3wopLNqRofedrdHWl1gh+umaIzxAqUA1TBVH1L27nTOo8GZ9/S/z5Ak1dy4KTYepN3cHucLKvSVtfudRiZfVVw6rN+9bExMTkUiYuJpJOpw5r6to4j4WpN3paHs7WV/bpe/E7cplSUKoGfm3LCvN4JDWVvktmA2C9a2RYw8+6tFHHBudvHOwzMPVb95WaJAuIdJfSb91XYetfMHf1b8u+lh19ZYsoo3Edosaz70kpT0spM6WU30kpPwJuBLx3biPgV6H3Nqlp1sR1IrNZRw42asED903UaTZ1HzmMg/38FmSbdHND6nJNm3aOPZpyi4KT1ZaqNHPonb7XJdYIMoeOqPIxL3WemreNhq+9RNrE27G/dgsDnhh1SRqmclsl6OpeGTKGpUoTkH5PKQVBervq85SqzeKgJrWHDp++T/A4wSYVM+6/BrE7nPz2o1QaBxgDhYT79qwj6UhmGXuamJiYXP7YHU5e+Wonx+s10tTvi29j2D5z0Qq+GP57Fve6kewmbfh6eM3r5jQt9mdRlp6/hv/7do2fty5gdzg5nrEPgPffnBnecey6dQi3R97FINLmYmKNVP1bZKnfe6xTvFbCOrgcTpIS4ngkSg1xtaB6vR1evLzsneoANW6UCkZKqQCBeRevDtXWpOZJToynMCKag41bsDPBWJy8WaMYbblQ+xAsdSkax9zqTFX6fQt/DPAnV91e54XO7Q4nXd+byGPpXxDjLsUmFQYd2Ma1f37gwjvXMvrn7NTVvbLmY55a/B5e6XzVNV3SbG31eN7ZHU7u/SiVd1buMYWTTcqkU+lpTdlnoDLj/muMtKw8+ubs4tqcHb46m3Rz8w9fGmoempiYmNQl0rLy6JOziyZBXrxtTp/Qtc1ctIJOd/+au76dwYhd6+jgPMKt386sccPU+aCp5cH4NqbIeTWR/fVqHrB/A8DUha+R/fXqsPUls1t/3J5ImnBnR7dEqLMGuWy5zyGi2ZOP+IyibquNZk8+Erb+GfFLTzVaxI2g1GojtX3VM9Zf6lx0o5SHQN/OHmHqgwmqtTbaIqkXHRkyPKI4XztxLzh8XFOe12OQL4uAN9zKbbFWS6rSlLV+getH07/gqpWfV/mYlzJpWXmM2rZcI9AGcM2B7ZeUgcXucDLX1UxXH+EqoeOpo7r6YT+tqZbzzk5zcJd9GZ/Oe4k7Ny81hZNNQtLmmSc1ZQnI6Hpm3H8NcuZ8Ka9/O0XjoeZ9zilFRZyY8nGYemZiYmISfrrs38H8Oc/RwFWsqW92zqkz2u95ayo2RfVkCRwvJv1Ycx4ZdoeTmMKzmrrIaFOlpbq4IXU5Nk/yqUi3Sxe5cjFZE9eJBX3Ued5D97waVqeB49+r936v7Rt8kTrLdhzx3fOKlKzMyA1b/4xodevNKMChRs15fegYOt425IL7XO6Eyyjl9e0UQPsw9cHEg00q1KsXFVKvw+nU/sDknjilKTepH6mZREhgbWIS55L0mkEVpe132gduy9UGQnV1iOTEeCLcpbr6CMUd1hWTirJo6yEST+qFEa2oBs1gztZvXOVz2h1OuvzrdV82tTdWTK3zRk6T0NiH3c3KLsm+cnabTuS8PNFc8a1Bsr9eTXeD5wKAkJKG82dVm16hiYmJyaWE3eFkx+wlRChuneEe0IT/PDVvG733bDE8zumWbQ3rq4PNc5fSukC7cF3YqEmNna+u0axhVJnli0lyYjxWT5yMsNnCmoik+PsNAFiQRLhKcS5fhW32LLVvqHMk66yZYeufEU122hFAu9PHeHHVR9S3bwp3l8JOuIxSCpALvASYGfjCjEVxIw0MAV72NWoVVG6pKf8h6wfNjSSAwfs2s8ko00EFkSNH+twvveW6jjeNqBfvClj9+bPD0p/KUPj9D/zlx3mG26JceqNbfp+quwVnf72aMemLNCuGdd3IaRKatKw8jcB+wuEsWrz8nKFRZE56DndM2cCYGVsuKY/F2sZfF7+n0/HyIgCrUj1h4SYmJiaXGmlZeeRH1NPVS9SEEIHhPze+/jc6OY8aPk9ldHSN9bG5PVU3sXS53DV2vrpG5tARuDzzNZfFFlad3aQjmdy9U10Mn73g5bDqPjZNVA2tElXyo1ViG1o30n5X2jWJMdgzfJxf6c8uX12SN5c64TJK7QY6SSknSintYeqDiQeLoiCtoY1SbV1ng8rnNOXmsdE6TSmbdHPl2qpnOugw/mmOxsbjrN+ITc+9SYfxT1f5mJcyP4ybSP0gt20v3TIuHSv7/V9+QKg7rjTKP2Dy3lc7WyZW+ZyJyz7HEpSWOK3fDVU+rsnlSZf9O7gzY62vbEUaDhzmpOfw+ZQFXLvwY06uWse9H6VidzhNQf1K0M6ZG9IoJQEpLJwZcO3F7JKJiYlJrSA5MZ7rcn423CaFhUP5/rH54L1pIY+TsHtbtffNizh9WvcMryddhm1NKs6auE68MuRRAN688cHw6uyuW4dwq+ItojS8QufthTovEoC0WOhAEc2fUDWkFMAdEUnXsU+ErX9GxN2ihj4qgNtiqRbJm0udsBilpJQFUsrz4Ti3iZ56xYXE5+aEFJHdknSTpry5/43aBqNHY7QOktisvkFtxbA7nOTHNMbeqhu/t11R5yd4d62YFXLS1uJs/kXtS1XodPJgyG3HuqqZ9iR+j6amv+yq8jmLD2u1qiTwfVRL48aXKbNSD3DXfzYyJz0n3F2p9cSm/4hFKr6yApRabTqjyN4lK5k3Zzxj189g4axxPL3mE77Yeoi3JnxK4av/4K0Jn9b551Z52de0XZnbf27eib2dTDFQExOTukdSQhyJeYd09WpyoVKGTHnNl4k5r0mLkMexKi6um1Q9Op3B9Ptpg++1dwlQeegPNXKuukhyYjwZbbsCcMWx/Qx27g9bX7xC55LwC51n9rjKl6272GIjs1t/ivolIYDj11yP7ft1tU56wWpRZziB/9Z1QhqlhBDPCiFeFUL8RQjxkBDifiHE3cDNniYxQohBQojuQoia8wU1qVlSU2ntPEaLg/tRbjLOblTvicd8r18Y+rimDEBKCm5rhK/o/SFqPrDqD4C0rDwkYJGSklKlzgtTx53XZgQL9Ps51uDSids/ERu6r1sUfdrWZueqNqm3O5ycPl+q02H4U/oXVTrupcKc9ByGvLOOF5dkIDdu5NC4l1g5bXG4u1WraZXYxpe4AeBkTGNeG/KIzijSZ80SIhSXL1PkY+lfcPV/JvPprPH87fuZfDpr/CWl9xYu5qTn0PrUsZDbBdA/9xeunDrp4nXKxMTEpJYw4525dDlpvKAkgF4nsun7/JPYHU42NO8W8jhRiptpbz1UI4sl1qBZZV5skzof4VCdJCXE8UhzVeLi9p1r6X7f7WHLSrsmrhNf9RiIW1h44L6JYfXa+r5JZ0otVja16+Xri3Je9X058auBtc4gBfi87gVgNcP3gLI9pUYBLwL/AqYBM4F5wHue7c2ANUAGcE4IcUgIscxjyBpYg302qUYOL16OQKrZjYqLNUKJXrq1jPW9XnDVLZqyEb6Jf17VDUhxMZEowoKQEsVTrssURcX49bWCtrV35l4yIsBnIv2x3oHvw42g35E9gHbdIO9cSZW8e7K/Xs1N+zfr6tue0K86VpbaGq7lDS+7+atPGbf2UxbOGsff189g0KO/Ddtg5lIgwql+jt77sFnhKSas+lC3MnnNrlTdGtcNG5cS5Srxhfw13bKx5jt8ibN9wTKaFZ66YLsua5ZchN6YmJiY1C6KVn8Xcpv3N+i6fVtIy8qjawhvdG+7bvkHOf3v96u3g0BenOqh5R3XHWzbudrPUde5wuONJgBKSmDGjLD0IzkxnrwGTXBZbexM6BVWofMBiWo/fm7V1dcXr1Gq6bZNtXKs2yqxDaDVwarrlGWUSsCvoRz8h0Fda2AYqiFrrRDioBBishDCvMq1mNT2fTwuj2poSqBQopdA7yRFQe+t9NFHRAZkhJOAYrFWS+p0Z2EJUggsUmIRarkuc6ZfkmG910uj9LP/XtwOVQK7w0mbk0cMt0khfO7pgcaqwfs3s3fJykqfs+mWjb7UyIFENG9e6WMGYnc4uefDVN5esYdR09JqlWFq89xvWDD7Wf6+fgaPbfoCK9IjrFjKiSkfh7t7tZY9bjWrjfc+FKgpmC0BGVyemreNpkHeiwDFkdHIgIQEq465atU9URu5Yv/2crXLb1FzmaNMTExMaiu968sLaq7s6XctyYnxFESFFnX2TuKSNld/CF+rw9mac7Q+kl3t56jziHDJQWtJSogjoVEUirAw++HkkBncLwb928fhElYSGkX6+nJsuXp/t/x+FcqgG2udYaoDRYBWB6uuY3hnCyEEMBzoD/QAOgb8eZW4coG7gL8C/wS+8dR5jVRtgL8D+4QQ7wkhGtXc2zCpCJmLVpD6yN/JXLSCjrcN4WRMHLtaJPLQ796k421DdO0DvZMMvZW+0IdAOW8fWS3uksmJ8UgEFqlgEYTVEl9RJi3bzaC31vpi/KuD2JeeB9TPQTHYHm2rHT9WZZGWlUdxpHEaW4uUWD06PoHGAJvi5t61xtn6ysN+JdowYtsV17jSxwwkLSsPtyLVLDiu2hVmet/audikggV91HruGfNHMBRNzhcA+mt2OtvvXbduzwkKIvXaeV8Me4CchqrB0yYVXlz9UbVkI72cOZN8nS+zaLAXaCA72vU0NdFMTEzqHL86E1qL08u6lj2YmXqAqw9rx52aLNae/6c3v7I6u4fd4eRAQ+1C36kWpl9CdfNTijoNlwBRUTB6dNj6Em0TSIslrAYpUPWZ3BYrrRpEkJQQh93h5MR0dQFRAKKkmONTPwprH4PJ7NYfiUABnw5WXcdwBitVNkopt0sp90gpHd4/wDsiL5JSLpZS/p+U8jkp5e1SyjZAO+ApYBPqvRAF/BnYLoS47iK8J5MyyFy0gk5338o1094l4be3U9++CbfVyolOPRg74SHDB0ugd1L/w7v13kp33aWbuDXdrg+Vqgx7cs+gCPXoLkUth5s56Tk8MD29zInRpGW72TR3Kbd88xmb5i6tNsPUHEsbXMJCQVR9vuw5CDdCM9hIbdy+Ws5TXSz786ts6no1y/78qq8uOTGeze16AfpBkvSEkoLeGNBqR+WzC3ayGBtfGq76tlpWTwKNpUKIWhNmanc4aZ2tT9Prvd4RD/7+4nboEiK/XkNAbyCJtPnvzL99N51mBp5S3c8dJ+F0rq8c5SqhcMVq01uqDAZ1bYbwGKSNDO5emu3bzfOLd1Srsd/ExMSktnNg0P9csM19Gxdx4xt/p2FJoa8ucIwI/rFVh91bq7V/aVl5fNPjeo0WY9SD4TOYXI7YHU4mnlB1V9d0SSZzzpKw6iUJtxvFEv7FcJtF4LJYEaVqpse0rDyEW5v18ViBcebycLEmrhOZzRI42Khl2DW5agvVfidJKQ9LKf8tpUwGhgA7UJ+BCahhfQ9W9zlNyo9j0TIiFJeqdeIqwbFoGVbFTZNGMSEt3V327/C9nj3vBU0ZgDFjoIFfnFoAnDtHdbB851EUYfFlwVq+8+gF9qhZvPo8fWa8z+dTFjBp2W6djtDo6elsmruU+XOeY+z6GcybM56fFuq1uipDxLSPiJAKjYrPMXLXOg7GtQL8g4zOWzaE3rmaKK920rI/v8rwKRO4eu8Whk+Z4DNMJSXE0T1RzXonUCeg3kGTtFg1hqrAgVTsuTNkjA4S2S8nhSf1nksCsEqFnOcmVOqYgSQlxHHvtuXMmP8iv9m6jNe+yQi7AcLucHLXfzbS8sxJw+3OmEasiesU9n7WVgI9pQLvw5P11efke699xu/WLzD0wLtyzZe6+rzoBrXKg6620X3Vl1g9ry2E9pY6HxFF/8O7+eiHLPPeNTExqTN85AwdkuelsMTN9Xv1i8KWESNwB4V9Dd/zY7V6nSYnxtP6nF+L0QxJqn7SsvIo8Uzdf+jQL/yGDEXxeTiHE9VTygIeQ1RyYjwbOl0FqHOMEqut1i3CJifGUxDdgNyGTfm5Xc9LKhKopqjRO0lK+R1wJTARr5YXTBNCVGhmKYRoIoQYKoRoWgPdrFNEn/N7Glk9ZYtUwGoNuU9s+o8onilWhNtFbPqP+kaPP64tP/RQdXSX4b1boXg0pbzlcLJ3yUoWzh7H2PUzmD/nOTbNXco7K/06Qvd/lMpDrz/GgtnjiFDcaqpexcX/zn+Vp+Ztq/L5h+/+AfAboZoHeWkkFF9YKLgq2B1Ovnj0ZXr/4R4WPfZymZPCDkvmaUToOizxh9/Jvn3V/y0WlKho7K27I4Gvul9v6Cnlfd10yeeV6neHn/2DtODJrmXvL5U6ZiAH3vwXb66cyvUHtvPmiqmM2LyUB6al0f2l5Yyenl7l41eGtKw8vn//IWwhtttKijX3romWfT2vMgx5aJByDQC953wU8gc0uqRId/++tPrjsKZvru0cDwoldYdIkXzz3jQWzH6We7YtN418JiYmdQK7w8nAxZ9dsN3h2KYURBgkkhk3DhkZoRn/RLlLOfXXv1WbYSopIY6WrdRFGwWBJSqqWrRlTfwkJ8ZjtajzNauUYffKF4q7VhilhFDD94RLNUolJcTRK16VCdncK4XsBd/QfeSwcHbRELfFgkVRQBiPd+oalbmTvFeuXPtKKRUp5UvAPUCJZ7//E0KMLNfJhIhD1au6BtXTqpkny98WIcSHAe2mCyFShRAvllVX12mXs0dTbpuzB6tStlEqbvhQim0RuISFUquNuOFD9Y0mT4Zx46BzZ/X/yZOrpb/3D2hPTJQNm5C8cWcf7h8QvvC0zEUrePTf47BK6dM5em3F+zy6cQG9DmSQlpXHmDefYNCBbVil1vTR7HwBI194uMp92N83GfAPNHYl9NSUN7TtXeVzlEXGq28x8dspDDywjdeXTyHj1bdCtq0n3brynPQc/vzkFPYtWwdAwX0PcPiVN+iXuxcLcHvmD7734vbEWgdy3lb2D3BwuKDd4eT5xTsokKHv73MJVV9pKpm/UGOAe37tp8yc9hSb/vkbxj1/H/c99K7hwK8mdMe87D12hnZnToTcLgQ8unEBvR0Z5uTegJ6tYjVeUl6vvrbuQuwOJ12PhjYwRQQkfvDuG+kqJTbNwKBvAsC0Dv7ofpfFyoKrf61rI1AHEFap8PrK/5hGPhMTkzpBWlYeSUf044TgRbZBB7bR6ly+pq4kMhpSUtjXvoevzjteeSz9C2InVM8UaeW0xdzy5XQAFCFI/+vLYQ0tuxxJSojjvpQOgGoQCrdXfqzzBJGlxbVCRNyiuKm/eyeZi1awctpi7pv9DgBX7t5MTn7hBfa++KRl5eEWVqzSjdtdu7Row0WoRfSy8BqjQs/yDJBSfiGEUIAFnn3/K4TYK6XccYFd+wJ/k1KmeQxU9wOzpZSzhRBzhBBXAe0Bq5QyRQjxiRCiC9AnuE5Kubcifb4cybbUJzGg7LDUp6W7lOb7dqkPFYMfkO4jh5E5/yucy1cRN3xoaGvz5MnVZowKpEHpeeIKTtPw8G7Uj/ris3LaYm549B4ig2KUe53IpueJbEqtNia3a0xKzs+69X3vxDb5wE9V6sOc9By25FkYDDijYzl69yic6ds15+i1I420dr1pf/oYS3sNouSNN0lOjK82EcLrl87RnE8tv2HYVpRotcdkSQndRgzlvly/Z9Ku/bmk9OqGoqjmJxtSXXWR6sqBJci4F9E0tHurN1wQgL1bmF9UyrZDp3ho01d0zlcFQoO9XtzCwqKh9zP+Qm/8AmSkDKXrT+qPsgBiSwrp73mfvY5nM+u/f+dulwLc4zOsjpqWysOvP8FfDmeQ3rYXk6bO5rlbeoQ4Q8VpNOuzEL4mKg1Kixi7fgYl1giyR/QBzNTNgXTeZQf8oWTS83qPO4r8r1fTr+C4r22g4QpUcfNgLEgWHyzi6OIdjOzfNuzCoLUJu8OJPSdgYC0lHc6WYVAFLFKh+56tqEl/TUxMTC5fkhPj1QVkAyR+I5NE9c4PRGnVGoCD416m2yMjNd7oErhh5w/V0sdTy1cR4RkjCylx/JLDgGo5skkg51zqiENIxZdYJyzjidRU+mzfoHr6DB4Ma9aEzQiZuWgFXc864Ww+xb+9HWfPAb6M2xGKC+usmfDwnWHpWyiSE+M5Y1HlaSJsFjN8j8p5SgXKPlQIKeViVBF0gPrAF0KIMoOkpZTfewxSA1G9pU4BvYUQjVFF1Q8Cg1CNXQArgetC1GkQQozxeFxtOXEi9AD4cqLJWW14V9sTh4gpLaJlxnb1oRLC2t195DBSPn77ors/Zi5aQULOXtqcOkbCb28nc9GKi3p+APuBfJR//pNIt8vQ4GRBTRV/88z3fA9B0K9gBcfzV5S9S1Yy6dt/AxBXdIauc6eTdPQXTZ96nchmwKEMWp05ycNpn3PDvTfz1oRPq20lpcH5M5rzNT6bb9jO7nBSGDR+apF3hKTcXzQeRclpK8jYnYO0qtemVFhY0UUdxpyObkAwpQ+GDgsNDhdMXvAxb347la75B7GCZpsXRQiOOM+XSyOrLOon9dOURdCfRUpeW/E+8zer3lJz0nP4+0ujudGxjXquEgYd2MbNfxxR6fMHY3c4+eMPZWcr9PYt0l1K3vsfV9u5Lxd2dFE/U+9tLFDvl27WYlJydhiGl3pfGxkDJVB45Biz03O4+4ONjJmxxQyb9JCWlccjaf4srjapcMVBvUC/F4n6ubxXGt5wbhMTE5OLQVJCHHs69fGVgzU3vXjHpIHs66uOqW5++E5cUfX8Gp6e7VtadqmWPiZ0bY/Fc1QLkoSutSvxzuVCz3aqAcoWbmPGunUIRRV3kSUlsG5dePoBOJevQiCxABGuUpqf1XodtWtyYT22i01SQhzRURFESoWXb+1lLlRSOaOU17uqUoGsUsqpqOF4AJ2Aty+0jxBCAL8FnMA6VNH0vwC7gXxUA9dhT/N8oEWIuuC+OlT4zwAAIABJREFUfCSlvEpKeVWzZs0q83YuOfYn36gpFzf3Ck7LsD9UjHAuX4XFk5Etwu3CuXzVRe/DphcmM2xv2gXbXXMoQ/OFCp6YRrlLmfHO3Er3IynrJ5/RSwBWt4vYCIvGSyPwD6D38Wxm/ndctaWjLwxyrmxUeMbQkJmWlUe0S+spFRMU0uSrX7HcNzqSgM2tvsej9bU/tBLYEts2ZN+spdrztSk4HtJA4K2PUNzcumIW5yb8o0rGu9bTppS5XaAaDP/0rZqSNnX2N1yRu8+3DeDK3F9IHz+pUucP5outh2jsEeoG7eDVu6oaSFxG1fXOLifsDif3/KQ+d0otNt8AXkRF0+bO4SxskKhpH0qUW4sgv14sj6cu4J5ty+k8/f+Y/Er1GYwvZZIT4+mZm6WpizgfOlmGQF0di1z2jXn9TExM6gSWqChN+XijZux64NGQvz8SdTE0UOA5sqgQN9pxYsK+ndXSv7buQt8ijhtBW3ftC5m6HOjZVjVe9GoZy+yHk8NmzMjs1h9FqHOQImEls1v/sPQDoFViG8ArXi2JuXmIzxHAbbXSdewTYetbKOwOJ5aCApqeyeOrDz43xzJUzijlfSpGV+G8f0A1MAngT0KIPmU1lipPAD+jGqUelVK+BmQCDwFnAa+yXwPU92VUV+fp3kT7sSld1BUShfA/VIwI1K9yW6zGelY1zA1rFxkaN8rjHRG8vdf/vVnpfhyLbOA7hwQUi5XIh//g2x48MPGHErm5/t2yRcnLw01vr6V5gFaB7z0bGDLVrBL1y3XciJIi8LilR7hdDNm/CQl0y3No2kkEnXdtMTzGjHfm0iloUmsUX2w0eBu6N52x62fw6azxZH+9ulx9DibmxLFytbs2fSV2h5M7V8029LTp/88XqyU2v/2en6hfWlTmPRlIiwIzlj2QtKw8XlilShZGKi6fnlTOyxMhJYWGK5cbfn6hVq/VNpLXVn3I39bP5M0VU/n7+hnMnPVcpe+5y4mkhDhi3Np0zYVR9UK09nNHxjpTh8HExOSyx+5wIo9pxxnHBw6h14z/cKp+o5D7bRr5kC7CwW3VCp63DZGht6Kktu+D4hHhVqxWUtuXObUzqSQWm3qNuzStF1bvmjVxndjQoR+nohvwwH0Tw5oJ0JvlUQBYLJw5lgce+Q9FwsqM3LD1LRTZX68m6Ugmzc6dqtL843KiMoYaBcgCDlX2pFLKk8DrnuLEsnSlhBDPCiFGe4qNPX99hBBWYADqHMCOPzzvCuBAiLo6T/O12vC3qJ0/40aQ3r5P2B8qRnRv1dD32moRmvLFwO5wciJSH0ZmhJFhKniC2s+xg1KLlV19Kx53PfDsQU356LU3weTJ7E7o4Tt/KHqdyMYx6b0KnxNgxJQNJD63lLfeeZR6AVoF3gm4kSFzwb/n0+5U+Qw1BZH1Pb5wWk+vYF0eiZoRzYh206dqjFChroWx15R69ihXCYnLKp7dz+5wsqJZ93K1PRkVy70fphJ36qShkdOquNk+88sK9yGYrisWVUj0L66woFYIVdYWzpwv5c6MdYA2s0eLl58jc9EKhu/dqDNEuSxWSoWV89ZIlBCZVCIVFzbP/aaG/ZYyMG1ZTb6VS4bCGO2z/VDrC/8WtTybZ4qdm5iYXPZsnruU/kfVREUSKLVYfR5Q3oxjRsT/uFZXd7RZa005v1H1hH81jLYhvLpXUtIwujKyxSYXwmJTr6t0G2uMXSySE+MpqBfLqXqx7EzoFV5NpEGDkEJ4PNqjOJ19CKtnBhahuFVNqVpGSs4OhFR8kUApOReS2L78qYwu1CYpZWcpZVUVeacA06WUL1+g3UfAA0KI9ajOD//jqTsNNAHmAl962ryLmuVvaYi6Os+GRK0BYeMVN2BDsqlt7/A/VAw4vHi5v1Baqi1fBD78fj9RQWFo5QvVUQmemlpRjS09dqRV2DDVpUWsptyupxpCFFNwyqi5rg8dv5xXYW+pEVM28Ne3/0LmP2/nygCBci9SCHYeKdDUzXhnLhPffZwmRWd0fTAiWrpxC61RygghoHdrY6Nkx/xD5fYK0hwz6HWfFV8w4525FdKYyv56NQ/avy5X22KXQp+Du2h2Vu/d4Q2r27e30vZ+H8fPFOvqytKgEMhaF7obThrM/JTGRWcBrYi5N4R4d/uemvZ5MY347L5niJRuYtwlOoH+sp4ZzWOr4nR8+VDauLGmLOKblNnea9g7aeqhmZiYXOZ03LnZJ98ggY033OHzgCquHxvyN6btycO6urNNW2rKLZzHq2VRqukH/6sxBETOmVXlY5rosXk8pXC7y25YwyQlxNE42orFagtrGCEAKSnsb9GBvBZtYc0aGnXUSn3URk2pM8nXIj3hj6VWG2eSrw13l8JO2ELapJSlUspHytHOKaUcKqUcKKV8XEqZLqXsJaVs4Kk/K6UsQBU2TwNulFKeNqqryfdzqbCu90Df6xeGPs76gbcD0KFFeGOTQ7HH7Y+htyI15YvB1hwnV3pWpwIpr2Eq0BAggv7vFBSKNic9hzumbAgpgJw5dARu1XxAqcVK5lBVGLtFgdb1OpTxoW/uLyyaurCcPVd5+p2/MMixjUiPNT8QAUgpabplo6a+0edzsfp8n7TtjbA2b0qEvPCPq5CS2LQfDbedja3YfRuchc/bP5vipvmH/6bR3/5C5ohR5RLW77xrC5FBhstQdD+WxcJZY2lrYJTyaUtlbS/Xscqi5yG9SPSJ+JYc6tJbV++9BgeqFJF9eXHTBmMjY6nVxpkB1xJzVDvQdzRrT+Rpv3E48F73Xt9DsU01+/juvdGjqevYHU4KzmkNqU2Lz5Zr3+h9emO5iYmJyeVEW0uJZgzZrG1z37aWb74KGI/9cpu30x2rwf2/9b32juOqvCiVmkpf+/facd6x8nnLm1QMq9WCggi7pxRAJBKrzVor5o4F0bEciW2KvXV3uo59Qr1GgNtqq5WaUmviOrEh4YpaEf5YW7hsdJY8xqsFUsrcsurqOo0i/K/3x7cl3utea61IsM/Fo0mAWLMihKZc09gdToZsWEKkUrHViGBDRygi3S7f6tSc9ByeX7yDHt/MY9QrY1j02MvMSc/ReOwEeiQFeiidj7ywMcHrVTBiQdmC3MEkH/QLYBqFJlqBzMyDGiNaeR8q3uvkigvtEeHGL+Tuslj5qklX43YhUiUHn08C0uI3mRl9PsP2pjFq+3Lu376cTvf8+oIriGnl1E3weoFd6JvWpHOHch0vFHaHk24ncnT1pwcOxv3QH3T1ql6S4GiWfkW1riKCRPNP1lM99B67Yzxj9kVyRZDXYJf8QzRTzhsey2tEdlv0n7wLgb11+UI/q8Kc9BwemJ7OnHT9fVEbyP56Nb1z1TA89XrZKD5XPpHc9mfrRuZcExOTukuD3TtDl8eMQXz4IUUx9QkeCTkb6o0FHcY/zYIBdwCqHosE/nKkatIYe9+aqhvbdMzNrtIxTYyxWgQKEL8tPeyyC0JKFEv4TQl2h5PzUlB8voRR09JYmZHrmzu4gcyjF2/uWF6SE+M52SCOc5Ex/NyuZ62LVAoH4b+TTC4qQwr9oUEzFr7CdcfVyVVje3qVso/VFIEaQiXWiJCaQjVBWlYeT/0wx9BwkRcda7gqdaGyF98xPatTy3ce5bnvpvHmiqkMPLCN15dP4ecJ/+StFXsYNS0Nu8NJ9Ib1Pg+kCLeL6A3rAcjq1r/cnlvdjx8oZ0uVcy1a6+p8mcg85T9u/lIj0Bd3/Ei5ju3dP9Ii0PthqexK7O0bZJUV2heodeWlRFh9/fVSHB2DZcMPnH7znwC6AVzgeQRqJsCt/yhbiyun2xUURGlF3cv63EPdI97/Tw8aUub5LsTcTQ7ORPg9Cr3H7TL2CZ8YZPD5FSFIb6f3oqqL2B1OLC5tpsgIt3p/9TiRxbh1nxIdlEmyqHlLUjL8g8PAz9gCRCpuEk7rV42tyBoXt/QavH/Ye5LnF++olYap8ytXY5X+0JSFfYdiHzyyXPtaG5QvoYKJiYnJpYocObLMMmPGsGvXQU5Ha2Ueuh3Se/oDRBeoY30L6u/QoO8qrqcZyIl9+t+VlgXVI6BuoiV6SzpWJM22pqHcNDishimhuJG1wCiVlpVH/ZLztCk4Tm9HBqcCMrdbFSUsmdvLgyKsWKSi6pOYlN8oJYToIoQYKIToVdmTCSGaCiHOCCHMJ1WYaLfBPwGKdJfSc940AK7P3lYr1f873uafoD/5m5c05ZomLiaS+EJjvaaYCAubnnsTxSOs5/8T5Mc1v6CRyLt9fpaa9jzp8G7GbP5SY3h5aNNX/Hf+S4zYvJRnP/+Jkh07Ne7bEb+oIVoFNw3VHTcUbpebo/WbcDYyms3X3XKB1pA28qEyt3vFuc+vVO+bZX9+lWsOVCz8rMQtOda1t2Hf25445HtI2RQ3N2361vAYe3sk6fYvtfpFNr3bov/3X5CSgvKnRwE4HhRSZfSzIHftLrP/vVs3QhH6R6nR+ykrdbPXYLUn40CZ5ysLu8OJbfo0mhSf09Qf7zcAUlJg0CBDQ5xNKpT+bIosgjq4yW7SRlPXqET12hm3fiZ/2LxEH5o6INnwupaF9xg1LW45f3MOo7YuZcb8F7l3+3KW7zxao+erKJOW7abtjs2aZ1tU0zjOP/jHcu1fMvzXVTr/nPQchryzjiHvfl8rDXYmJiYmHcY/zY89kgHYNG4iHcY/rWuTlBDHqUGDNQumxUOG6dqB6hEeyC2/bDRsF4jd4eT5xTt4YfEO3QK2S9GPborqX9zERHWF/KWqgcUCKMXFF11rNxChKLXCKDXYuZ++uXtpdeYkM+e+QELX9uAN3wtT5vYLkZaVh1sIrFLB7VbMTMJUzFPqMWAt8I/ASiFEpBDiFiHE8KD6YZ76gIAxioD6gJmSIQzYHU725mqltZqfzQfAgqyV6v+Bccq/+eOtFzVuuWDtep9oYzCFg29mwJvPYf3xR8SjjyJGjEA8+iiWjT9yYtoM3BZ1T7dHxC74KN4JWOKqrwC4cv40TTYvgK75B7nhwDY1ffyH4zWhdAB9DqnGkm7WYtyevSVwJmAgEHzuRqWFtCx0Ur+0mKt+XH5hw9S2rWVv97yX3vZ1LPvzqwyfMoEIxe0zsJTHgyu2QxvaPPOk4TZbUBhV/ubtxt58jfwpkb3nrO8q9vVPAmLECBgzBoComGhcCCJcekFwXf9E2eGbLRfMJD5A1L0sgr29ZNBrARyLrLznR/bXq3l9xfu6B/tZzz2RebQgpNbX/Ttq50rSxSY5MZ4DjVsaerUBRARloARo9uQj5A6smMHc+3kfstacAKfd4aTHN/OYuOo/DDywnTdXTOXK5Qtq7HyVwfrJNAYd2Ka5L/vt307k5vRy7b8jw1FpD9856Tl8PmUBD876Jw/OnMznUxaYhikTE5Nah93h5ISIxiUsvHMsOuQzL3H5YvJG3E1Rw8bkjbibpotDPO9t2mmYVBTDY9odTqau3cec9Bzu+yiVzEUraPTe20x6+RNN+3qnnboxrPPZ5yv6Nk3KQbpHMkIB3BYLqeWUkKgJhKIYLspebLrv2YpFejJpSzeJOb8gDdVjaw/JifEoVisWRSHCajHD96iYUeoE6hj6XFB9DPANMD+ofg7wFaoRyot3BqiPITGpcdKy8jhvjdTUyV+pav+KEFiiomhz53CjXWsFDX+y19ixvT+8gT+yze1al1jvY00RFtYNvlstpKTAf/4Dixer/6ek0H3kMPYtXEraw88w561ZLO45yLd/sKGm08mDAHR37NIJoQcybG8azc9oHQzPC3VQ0ebO4Viio1EsVoiuh/va60K+z8DQNIBum79n0jJjTyC7w0n+OX+YUllaWT2PZdNt/ieabRdyRvXqOzV/YgyMGcOJ+o11bY627+wzuAEMOJTB5ucn6dq179o+ZB8lqAOwceN82z6eNAsrkibnz1ywn8dbtC9ze9LmNYb1mV2uKNdPYYnFqvlMuh7ZV469jInesB6bwVkbJqiZSMpyYa7XQS+IWhdJSojjjizVIGJ0bwTX5ddvDCkpmhDO8jhie9scX3fhFerKkpaVx29/1n7mg1O/qbHzVQYjY2jMyePlXiBRco9x70eplTJM7V2ykrlzxzNq+3JGbV/O/NnPsnfJygofx8TExKQm2Tx3KbfvXo9VKsyc9Ryb54ZOKN508QLqnXaGNkgB24MyyEYrLk7/+31Nnd3h5M2XPuHchH/w+ZQF9HZksGDWOP6+fgazZz3LJk8f0sdP4spDGZp9C21Rht5cJlWnZ+uGPp1YIUNnpb4YNDh7mkYF+WHXtsrs1h/F4wRQLKxk5Z1Vrw+1N3wvKSGONvENsEqFsf/TrVaIxYebihilvMaoYNeC80H/E9BOBNV7l5jDm8eyjjLYuZ9bMzf4K4TA3aABACcGDsHy3RrVyFKLCMx+dvW4MeXKhlZR7A4noz5O452Vfv0mgOgQBgvJhUNuuo8cRsrHbzP6mfso/uS/zB10L3kxjSgJEjt2RtRj0rLdRJZqv1Yi6LVA717Y6rwntDAlBct3a7C8/g8s360hbsKLyMgopBAoAXHKRu8lpvQ8XcY+bmiYSsvKI/b8WY3HSKh1h/O2SCKLi0Jer1B1W+/5o++es0lFt12+OYmC6Aaa/t+27L+647V2ndO0CSbntX9q7u2+8z4us30gHTK3lbl9c2O90colLGQPuxOXxarzhgrGHRGlqW99vvKJQpc17aYpe42gzZ5UE53u7Z4Uct/tvX/F0HfWkTh+KUPfWVfpPlwqTFq2m24vLKPT88sYPV3rlWMr0XroFVr9Dr/B98yZFmqon5F7eHmSHpwuctWYd05cTCRtndpwvdanjtUq7cCYBP33p1HRGdp0bmvQWiXwug7et4k+Obsq7Pr+r1c/4/bP3iLS7fI/Y6XCiFWzK3QcExMTk5qm37qvsHiyIEe6S+m37qsqHa95g0hdZujgBbbNc5cya+7zPLN+JgtmjWXh7HHYkFiACMVNnzkfkvbUK1wzabw+gYupkVNj9FqzxPc6QnHRfdWX4elIaipdcnbTxHk87NpWa+I6saltL07ENOaB+yayddDtvvFvbQ3fszucnDt4hJiS86yc9mWtGpeFi4oYpbyj9GCDUmnQdi+uoP+RUgaK4ZtcZGLTfkQETvwtFs71U4XD864fXOsMUgAR777j++GMUBQi3n2n2s+RlpVHT0cGj25cQM8DGbz2dQZ2h5P2Dn2qcQUq7FF2/4D23L92Lk3PnWJP/+s12zqcyiVn2RpcVn1Ea6ifdO/1iLn9Vn9lSgqMH6/+n5KCZd1axMSJLB58X8h+CcAqJSN3raPr2Md1D8S4mEgGOrZp+lISGcX+RO0KG4Bii6DJOWP9rVDnloAtzu8dVdqwkaaNs0lzuo8cRqTQqvU0LtFn5fq5Yx9PFjn14RI4ac2LimVp8m2a9n1OZBlmEzSiSRmheXPSc3Bl7tHta5MK7Rx72DrudV+mPzAO3cvvppXpO1JPex0qwg3F+kSjp6Jjfd/tVY0TyW3gdxEO7Hf++lTuXDiF1R88wp0Lp1zWhqkHpqcz4IlR7HzjVnZPvp073n1OY5g63SZB0744Qs1wafSdPHmN6m2ak6+9L8urK1cQFVMjOk92h5Op6/YRF3T/Nik8zRsvTa81A6A1t/9ed60K2naAvLwLJorwGpLGrfusQq7v7732GU+++kf6HdU/4zv8vMkM4TMxMalVNImJLLNcURL/9Hvfa+9zNqN5oqZNx52biXKVYEViRZ85uOfen+g47d8aT2/vsXZ2DF9I2eVO3tlizW/jiYILy1DUBIcXL/eFzIVb2yo5MZ5TMbGcqteQnQm9uLFrM982K5LurWqfvln216u5+ZdUotylfDa79mk6h4MyjVJCiCZCiPs9Ra/xSWNQktJn5QhOf+X2bDcNULWE1PZ9cAcYP7697SEKe6oZt0RE7ZT5anE2r8xyddBl/w5mz3uBZ9bPZPa8F7Cmp3HPhxtZX19dqfda2xUElkcfrZJHmZLn77/qfiu5Y+Vs4s9XLF2pS1hg1qzQDTxGqs5d2pY5OfYOJIbv+ZG7P9iomai6PvyAxkVnAf9AI+qpv9I4OoJgGp47RX231i5dloeUV0/H5fQbstzFQRnNpPp4Oh9ZT3OscxFRDJy8hq4v+D1csg/6r2vwQy2++AyDnfs1dQaanL5+BW+KLi4k/X/uMfTS275gGUP2GmvftIyNZsCbz7F9YGjdLtGvH7v+PB63R5Cx1GLlrebXVNpgcOXm73R1UQEaSL1aNVTvHfTvs7tjF4+lf0HHU0d5LP0L7lw4pVJ9qO3MSc/h6RcfYNCBbUQgiVTcjNy1jpHvjfe1yfu1mi5bohpci6JjfOVAJNCqXQsArLNm6s5VGFUvZD+8370/pX/BA7J8GSvLi93h5LcfbuT6tYt0EwkLMH/Ws7VmAFRwvsT3nZWoA4dWsz8ls1t/nadhKK45lEF9+6Zync/ucJL88dvYPF4HwYbGhiWFZgifiYlJreLnm+5AAd844eeb7qjaAceMYU/LRE0m5eJdmZomsUXnypRjaFB8juZBi5HedlGDb6xa/0xCsiHlFs+cBEqsNr5PCY/sSmr7Pr5kT6VWW1i1rZIS4qgfHUmkVTD74WSss2b6ft+tbhd735oatr6FIiVnh8/7sTZqOoeDkEYpIcQdwE5gmhAi0HzeTQgxOvDPU18/qK6B5zgPGLQ1CQMdbxvCe9fe7yt/1Kgne496QoVsOufbWkGDx/9UZrk6OLtitW81KMpVwktrPuaKg7u5IcuumbTkxLXy6UZVlkh3sO0WhuxN060yXYhj7TuXq12/B0b4BjJejM4R7S7lra/e1oTAXLV6saZNXmwTmDyZ03HNNfXe2HYjiiKjfVnJAjW1vO+3y+G9AcfR9sxbdkvtcEiUljLn9XvIePM2/vriaEZPT6fNNtVtOFQ/uu/RCrYfim2mKfv0wtAapryf/zUrFtLxntt0hqlbtq3CqvGFUnFHRPpC5k6nDAzRKyA5mYIiFwihen0obu63L+WD7/eH3qcMcqP1q0FF0X7DSOvPZ9L+zAlAu7JZYo2gU95BTf3vt3xdqT5MWrabQW+tDalVFg6emreNzs8vpcsLy1jzyWL65e7VfWZDM/3aTlusTQDYfft9WNd/T5NzpzT3LXjuEavV5zUZFxOpuYMFEFVcdEGjsAXoPvODSr4zY9Ky8uh7cDcvfDdddz7VQ1IharbeiBYOGi6YqykLT9jHmrhOvHzzo75kEYEEX2dB2XppXuwOJwvHvMQ1QfongccCGBIiy6eJiYlJOAjUDZJCVIuOUExQzthOzsOacvOtZYdjSYMQPe+zud8DI6rUN5PQJN42hJzGLdnXtD2/f2DyRc1KHkjH24aQ2awjOY1a8NDv3gxbP7zYIqxECElSQpzOcz24XBs4k3ytLylWqdXGmeRrw92lsGM4hxNCPAUsAlp6qgYEbB4EfBr0BxAfVNcEdYz3mUFbkzCQlBBHSYeOvrLF5Sbtl+MA/HT4TK0J59AwZgwnf/8wAGvueAj7sLur/RT5R05oVoP6Hf2FBbOfpYtHhNyLN1NhVThzv2qXDZxUVSZvxQkRVb6GKSnYNm70rWYY4X3vI3et4+cFqvut3eGkQGoNlYVXqqGepX97BldAVkGjybr379iENxDR9VQBQpuN/BF3+9oANPrdvb79XH20wuCuPlcAsOEabSx4k8LTtD2bT4RU6J/7C0+9OJqfT6nGPgVUwffA/thsMGiQpi7Cqh9MZTVuxfYD+az+eBFu/N5E3klvpLuU0s+0ela9WhmH2n3d5VfYW3dXCweyddt9hq/Ro4nesB6Lx+FUoH4O13ww2fC4ZWF3OGmxb5euvtATogtww3K/ASDQa23C0DFEeFZsvES5Syv8TJi0bDcNX3uJT94YRcPXXqoVhqmn5m2j63sT2frWXfw8eQRPf/m/hu1iXMXMeGcuc9JzOJ2uGjE/KW3OHEsbzrfRC+kDbL3br4mWdctdKEGmLguSMxGhvaV87fbuvWCbipDzzWrmzXmO2FJjnTeAjvt31opnfo8c/z0rAIuUsG4dyYnxLL7q19wzajLbW3Ut07jnFpYy9dK8ZH+9mokrp/oEUMHYO7KlfaMZwmdiYlJriE37USPcHJv2Y9WP2bdnmeWo9mUnP4lQjANh8rv0qJVyIJcLSR2acD4ymtzmbbn90d+ETSA7KSEOV7165Ddvw9gJD4VfqFtYEB6VINeo3wF+bzL37x4IY8eMWRPXiR8S+iGB14Y8wpq4TuHuUtgJNR/2LhNuAfpJKQOXMk8DvwT9gRq+F1jnlXYxamsSJtofPeB7HamUcqZQjUVu8N1K3prwaa2YpASTefUgAI4dOFqtfbQ7nDy/eAe3/rRaY5TyehLYgiJPi2Mrr/XjZcCbz1EY7U8BbxQ+EkioiVjzisgJpKRgHTu2zON5+/DSrFcZM2MLm+cu5cojfldut7DQftIEQBVx3//5Mk55so0ZvYdSYeWXL76lw/inVRH2ia9jWb+eposXID78EHHzzYgPP4QxY3z7tJs0AcVqUw1LVhvtPOfLbtRSc+zgh1bf3L08/cMsX1+klJoUtTOv+B+/gchDnEXRXYsTA64jKSGOmx++k8yWnTTXxUuj09rw0WZPPmJ4TUfsWsexJ/5K5qIVXLtwmkELKOrcFVJSOH3spM5F/vdpiyp8n6dl5RkaB73XEaBhdIRO3NQCvLz6Y5yNtJo8FmSFQ7yaTnxFEwLYdOIrFdq/Jug7ZRKPpX9BQ1cx0e5Seh3P1n2u3nLCJ1PZu2QlY3+YAcAbK9Sys0kzTTtQf+DORvm/yx1vG4IjTnuvCqDQo0cViE5DqUHVny1eRk9P584FU0JOGLz0OpEd9hA+u8NJu1N+HTTfdRk0iKSEOGY/nMzWNj34x+BHKLL5PdHSul2jOY4iBEt+OnxBQ1J0qSj2AAAgAElEQVTU7Jm654fR87fdqdwa0fkyMTExqQyp7XtrhJurI1RqZfsrAf9z11v2sqNPaMOS0bjPe5yfbhtV5b6ZhMbucCIRFJe4ee2bjLDO22xSEh0dGX6DFIDFAh6j1A0P3oEbwZHGLVnz2Ivc/PCdYe6cnsHO/Qw8sA0BTFj1IbFbN4e7S2HH0CglpcwEHgKulVIGG5LmSSl7BP556g8H1R32HMuorUkYyFy0gnvX+DML3bw3nd65avr54Zk/8ums2im0duZndSX93p9WVEsfvcao33ywkcxFK2h+zviBHvyDG9muTZXO6yUz8xDuoKOXlbXOKPSuzTNPVuykkycjxo2juEMixVZbSONUq7N5nFy1joLlq4hS3D5B8symCUxy+kXJu48cRlHT5rr9vceNHPsM3UcOUwuBIuygGqJWrNAYpLztrD+sx/LGG1h/WO9rf1d2mq+J0XVyWSy+zIReg2KgoP+orct094zyhz/4+isBl8VK4zF/9G2PsRpfodON4rE7nNz9wUb6v7aSPt+e5lj9JoZtr9qwHOfyVViDjAPeIzs6qI/DlAL9RDpCKvznjYqFV01ZsxdLUHhoZp9kzYpl3Pi/+/oQ+A4j3C5WJvg9TbwDzhtSKyZc+Rv7Ms1g9Z7NlQsBrE5u2fFdmboYgXTIP8xt21dj83xmEYqL27avJrWhP0Oc9zthBfYrfoNTUkIc+674le6YDYov7DZ+MrLBBduUl5SP32LAoQxDA6UX77aBacuq7byVYdHWQxQHJXk4E9fUd896B7pb2/Tg1cF+A/BVe7SDtwjFzZ07vuPlJWV7f3XM2mk4kdJ9H5A8uW9txd+QiYmJSTUz4525xP3rnwGZkGW1hO8lrlIz+ImgspdD+w7pxp9laYV6j9PNGh7h7bpCWlaeRzRCUupSKpx5tjoRUqk1mRZLJShuN3aHk90Ll2FD0vpULjd+8EaNZG6vKt1XfanOV1ClXSyzZtZ5D+2QkUNSyhlSytJQ200uPdQJsn/S+vutX3PzHlVHxYqstUJrPfPUL2l19NHucDLq4zTmpOcgJYzc+d0Fw+e8P7jVpWeVlBDH9oReF9SPChVecqJlO71BpzxMnkx09n6cjzxueFyvvs3ns8Yy+BetIajXiWzavfWa5nCtXn7O8DQFUfVhcsXDzwC9AQt/lphQAyKL9Nd6w+0Cw6isUtEZVzqMfxrHG+9ysHNvdl1zE/sXLvUb0YCMbv017b1nOHr73bzx0nT++O4zTP/gzyycMoaW5/IN++ds2Za44UNxWa2a7d6etS4u0L0/ArZPmPNauVfAbvjnWr771yg6ndJ6d0SeDRLQHzNG9VTr0QPRoYP/OklJq4ITuuP+cqxiAvz1XNrBaGxpESunLQ7RuuYZPT2d2HOnQ24Pvp9incfhWK7GcNGoIJ8e9bTaG97t1+3VimvHtdRngIuSWkOh0T3ctORsyD5WBLvDye+2Lg3pCRZM81i9F9fFpO2en4g7r2YH9F6XhpMmGraNLzrr84A0kj8fsjeNvgd3hRygT1q2m455Ws0U71FyAzzcvNeq3tdhSrNtYmJi4mHGO3O5f+zvGOzROLWgLiIVrdYnNakonc8c05Q7nNZm77U1a1qu43iNZRKQEREVyk5tUnGSE+NRhMAiJRE2S4Uyz1Y3FkVBWsOvSWx3OMk7V4J0K4yalsaxxUsB7/eltFyakxedXO33rek5Z5330C5L6PwNIYQ+97vJJUvc8KEQENYkFIXIU+qEWhECS1RUrfwxaXi9aqBwCwGRkVXqY1pWHkUudYLZ//BubstYF7Jt4EQuo/MVlTMEheCMiAjp+hy8cp8/4m6kRxNKsVhpvmh+lc7d6j//ixg3jqJI/YTU6+XSP1cfaTt0t1bD4L3cSMMJttVAr6lKjBlDiee+NXIZt0qtwaDEYmV/9yCjktD3tMP4p2m/dwe90tdoDFIACQf0WkiFTZpRUORi7uznGLY3jX5Hf6Fb/kHDz9FlsSLfmET3kcPYE9/e13fvdgjQ0xozBvu9+nurzdm8cnkF2h1OPpo8mlaFTl1fotq11e8wZgzs2sWMJ9/wCZVakdyYbde8BwCZfeCC5/dy27/XUxqg5+XtS9zU98p9jOpm5HvjiXHr11ZC3aFxxYWUHD+pqYvt0Ib+CcbecI1/0d4nJfX1Hk+nG+n3DfaUtObnVXmFzO5wctd/NhLl0r9fI6FwxWqF0eHNPTJg/Tea7IASAX38YSmBRtlN7XtTarX59OwCEUCLc07mz36OLvuNFy3avfUaMUEZQn0hrC59AopGh/RacCYmJiYXk3rzZmvGON6FrbNbf67ysZ3XaD178yzRvt+hOek5nHQYZ4UNpSda0LYDlu+/N/WkapikhDgsVgtRVsHLt/YKa+ickArSEn6jVFpWHopHU6rUpVAY5c+YbJWSVonVE+lSrbRsqasa3rtVGDpSewgldN4CeBb4WQgxXwjR6+J2y6Qm6D5yGD8NGOwrC6D5T1sAOHXn3Vi+W1Mrf0z2tukCwJKeg/jdfRN1+kAVITkxnqSDGcyfNZbPZ42lYel5w3bBk1YjYeyqkHxwp+HECkBccw1i4ED1/w8/pOniBVh+/BHxxhtYN/xQPZ/R5Mkc+vVdhptCGctybtQaA6/95F3DyX1hvdgqdy+Ysn70gh9i5zp1Y+vQkb5yqcXG+uRbKnS+xIP7dHX1CpzEfT6XCE9Yo5GBrNAaSdrDz2g8rzo5tQM7t9Wq09MSkyZRIvQGnTYf/Z+vzu5wMnXtPt9E3RuG+vYrn9Il/5DmHN7PLFBPKpii1d9pBNYD34v3da+j5ZMBHP7eev72r6eILtW77XcsCe2pVNPcFGBo8xLqm+ytv+KwNi32lrgOMHq0RqfMt0+J9v2eO6MN1VOEQLnl17r9CiO14ued8g6xd8nKED3zE3wPBPLh9/u5d/tyrNJYSyo3rqXmmbM76YawP++dhX4jkXr9VZFzL4FeT1vb9OCzf0xn8x+fJmPQrbpjCcAm3bT6aqHhuQKN6sGh0cXtO+jatz4TvpAIExMTE4BOJ7WLFd7fqb5Bv1OVYUtMK81vQrf8g8ROeBGA+ZtzyDcYy5ViCTn+OV2vQdh/U+oCdocTlwKlrvBrSlkURdVyCjPJifFIIRAe77G+EUWAx4vPYqEDReHtoBGjR2u8zG7MstP/cPiTA4WTUHfSg/ijeX4D/AT83bOtvxDi+cA/T32joLpGACHaxhrUmVwETva4wvdazXSkTmAyrh9ea39Mdp9UDUerOg9gc8tuVYqfTjqSyYI5zzLg8G5NBiYjNKFtRdUbI1+vnj57nu98770H338P6el+w4VBWFtV6TL2CZSIyKCkwMZIYEMP7bk7nNaGOXn7n/3IX6qphwEYrCiAPusfwPFJ79K2hV84WgoqrL/gtmoDhAQgXS46/JQWahcArBZI+fhtn0HK7nByKLappn+2wYN1XndJCXGcuuIqnaGy4/6dALyxbDe/+c9G3l6xh1HT1PDT336YSuaiFfzr89cN7+PTUfXLvF/adm4bUsvM24+fW3Up8/16GffeUww6sC3I60XlWFL4niv5nuddqNBPguoFEB1k1CndYoeUFI4M1GaBBBBx2hXKrH7alL6zH3yO5k/oveCy2nTWnNOKZNCXn4XooYrXE+otzz0QOBCdk+agyZzPmLhiqu4zkKjZZ44mdtP2vRbIQDRI8QuWS0DaIjSZMpMT44mOsGAVEGGzcM19vybl47c517lbyOdWi4bGmUl3pQzRaIv5VvrHjSPh43/7MrN4OR3forJvy8TExKRaaGLRekn5wpzvv6fKx2483P+b5n029tu8hjnpOfTO2cXrK6bqPLyLAhL1BFMQp9cZNal+0rLykAKEJOyaUvWKC4k/mgOpqWHrA6hj6Mb1o7Ci8PKtvcjr1htQs++VCiuZQZIctYKUFPb/agjgzarprp1hhheRUELnk4H+qN5SqZ523VCfS1cD/wj6A4gLqmuMep2N2jbyvH49oM7kIhDl8IckuBG4LarI7GfpB2tl5j2A3h3USf0te37k6tw9lY6ftjucfDrxU0L53Bh5LnnrDsQbhEFVhccf10yMvJRYIy6ecTAlBev368jqWHaUri+kb8F0Tf2ebvoU7M4uPRjwprHWVFXY+FutnpeRaLOXIz9uodthv4dPhKLQfc/WCp1v+//crTufBUg8dbRMQ6ZorjWepWXlsbznQBQC7qeASXcgLd7/l+4ejDtfwOjp6Xy0PotR9m/4bP5LjNi8lPmbc+h7cBfz5owPKdQffQGP6ltaG4dfgv+ati0qW1NqTnoOvV7+lpRDO0J6Wzmywhcjv6l9b01fykNw28QT6kp17mm/V6X3ujV7cZy2bbP6mvKe3DOszNDqBriEX2MskKt/2VRmCF9aVh79D+/m8dQF9DqQoRmIrv1siaFBCiDruqFkL/iGmOfHa8Iru21eF/aBZN4PqZrrvbPftZrnnzcD399u7sbsh5N9YQpxw4eGvHcXupsxJz2HB6ala67n7mtu1LU91rG7qn+XksLRLr012/JbJ1T6fZmYmJhUlTnpOWQraqrlQO9OMW5c5XU7A7j54Ts50DxBc3xLcQmfT1nA9V9+ii2o/dmYBuzsf53uOBJwCQu2Z8fptplUP8mJ8UgsCMKsKZWaSmvnMVoc2o9y0+CwjifsDif5510gJa99k0FGdqBGqmTnkYrpo14sLPeocw0F1bM+brh+8bMuEfzM8SGl3A5sB94SQnQHHkHNyNcYfyhxHrCU0IvQRqgLw+q5o4D6ZTc3qS4yF63gV+v84q2b2/bkq5438MbK9xm26weyv+5O0pN3l3GE8NDHeRCAX+/ZwK8PbMEyJgUSKma4sTuc3PPhRp45mW+4PTicI3hF/cqcnRXtdtl4BhTi3/9GFhX5zhs1WD9xqlFSUjiW2IPO2bs01UaT+B4F2jC0Bv37oqR/q7FsNxl8Q/X3EWj0l8f5OHU7f0z9PGQmNe9nlbR5Dd936Mft3nqpsOxICRUJ4Gvw3jvs2riOnsezfcaWYP2EQHyf38svaOqTE+N5q3MSf0r7nAi3C0tUVEijFCkpHIttSsszJ33niZRu7nz3OYZE1mP09uVIYOCBbUyuF8mvNy4h0pO4IPj+BYi+c0TZb9KgH8EP8pbHVWN1oGaB3eHkxcU72H/iLL1zdv0/e2ceHkWRPv5P98wkISFACCAQIBCucApEIPGMIiAKiri6KuJ6xvO364mAx7qrcqyr63cVFS9WDQFRROUIEZFwJgECyH0GEo5wJQMJhCQz0/X7o2cm05mZHJDMDKE/z5MnU9XV02/3dFdXvfUe/LLwfUw292DejnPocDy3ajnqkS5rl1X7myngVVEN0Pq4qtgINmrXcI5Ed6NdJYu3nh9O0ZT/uWQ66SVHUKhYAZKFQkuT+yuzkc2iuk6kfuNRjq77t/JYygRMig2LwciKGzrDjV2Yungnd/0+2+M52IDOqyrcAjdH96Tfga32VTmFjCdeIWHLyirOvv5IycojJne/pq6sUjwvUBVTlWNmxI4Zzvp+1zNws7vsNyz7gTeMrbjm4GZ+6NgPuIf7B3egZ/IMt7Zthic6Px/qO5h2eyv6eUthYC7S6OjoXB6kbsvn/RM5QMUY5Hh4C9rUgULKQZOzpzXf3/bsKeakTHDLGgyQ07EX5cGhHsdCW/tfx4BKsTl16oe46Ai2mwyEmWTNYo2vOTI/lbb2PIC2sjLy56cS5SePm8ycAiJQEx9ZrAqd9qqxJWXUsY6aICvw5redS9VxhoSaRTj2lP/Gy4FAjRxBhRC7hBAvAjHAVMAROKM5EAt8KIR4uIZ/Dwkhxgkh7hNCjBFC6L2Yj6icnj6y5Awd7fFu7tryG2Ne/ovfV849YdyoxoWRhUC2lGtijtSUGSv2Y1Ng5M5VXttYZAPngkI8TmKbKvWQiHLaNDh/HmnYMKRGjZCGDYM036ctLTSF1kir3LKT1lqs37jRKKagCjcYk6neAifHRUcQN/sz5n84l/yXX+d4pfg4oA0gfupIxSqJDTW1cW2PZ/jkE41LT1XKDQEce/KvHt3yXn7zYRb9J5njL71abdw2xeAeV+qW3WsYu3mJpu7RtC/pbR+sVpZNSBLS2LGQnFz1SSYkYAlvUuVvH2wtY9Z/ZpOSlUe3VxfTccIi7vpkLY2y1/HG4o/4PvllOp/Or/JF0ri46sn9M7Oy6fePX3luzqaq5a0lr7/yGf08BOx3pdQYRHHHLlVeg0b2n6TMqmja5Ue4u5RG5B/SlGUhaN88FIvBWGEVaTIR9eKzGvczx+83uFKWSFfa/PI9wYoNGTV9sCN20q75aQzd69mttLSlVsbWx7XPgcM91B+kbsun20ntAKxT4REvrd1ZPGKcx/peJw8wd9YrvLh6FnNSJjpjdXU/WKF4d/6OLv3VYaG1HOx5aBe/3f5QjeXR0dHRqUvGiaM0Lzmjeb/bgj27J18o1pBGmjGOY3Ls6Z3eMjyYkCD3MYqO75ENMiFG2a9BzjM69FGTpgAWg5GMDn2q26XeiI+JBFl2xpQqiVU9QGySHLBJvADOfTMLqHiWzn7svnh2OVGr6GRCiNNCiEmoyqlZqNdxIJAlSVLtIgnr+JziwddogvV2LjzMo9m/AGpMkwtV+NQ38nWqubBiz77n1dLEC9m5Zk79ls6nP75Nu6ITXtsdbtMJSyOt4Z7jZR302CO1OmatSEuDkhK/KKQA4sw11Mz3rOTml5CAcUU60pNPIj35pBoHqx5XSeKiI/jTs3cT9a9/UjhSawXk+J3OtI6CpCR6nqtIdWwA+hfXfLLrIHbMcMzhzT0Gfnf9s0kS6ydMoc0n/1et3NVdn7Bm7oFF1YGicB4bIPJ8kdeA9LuH3F69QspO8FNPOvd1/J01BDuPawAeSfk3k+ZvZemHfyFn2kh2vjuaeckvM3ZzqtM6p6rBafvj3uMNxL62mJveeYnfp/6J6956oU4VU7el/Nf5gvNkSQZQ3LQ5zSa+7HGbo9z4iccBaNapvWZ75TLA+mtGaK6lIhvo9vIzHJi7kG2j7uPk2IcwrEiHpCQyBt/itr9k8a78rhwryVH+29KvvL7Id0Z105RDFYvmPEPrQ9leQ57dt5xmZWc1daHlNQ9G2vWOYW51jvvQka3KpFi5eZ2q0K18riVBjTTPoyO+iqsVwJXLfkJHR0fHH7TamOn2bg0Jc8+afDEcHna7x3pP8TrbPjKWZkmPoujqKP8jSSBqEhG2/ug06maON27OzlYxPPzAFDqNutlvssRFRxAVEYaM4I2Rvcjepy5ML+8ykD2z5gdszORjTVpoxmTHw/3kihkg1EopJUlSM0mS1gI/CCHGAaOAo8DnQIYkSfdIkuS/u1KnSopKtS42MiAp9smuLF+QwscXSFeraWs39r6aXcm171zWzV7E3G9f4Za9mVXe8MeatyG4ZaR7bKmgoDrx3w9U2j4y1us25wTbW/r4hAT45BP1z4edflFwmMe4UlJXdRLefe8fmvZdd9UuppTze72sSgqgvHVbto26j30/pNZZHC1PChLZZtW4LDoyULjJav/ftqwWvvPTpiGNH48UFYV0/fXsmbcEk9D2Ez1OHmDDB38muvgUMhCiWD1m3nHIXfl3kRFsfOsDt7bXTl3GJ7NeY8zOdCJKixmzI50b3n6h5rJXwXNzNtHfS3YiVxkPPP43SEpSY3TgrpiygfPZr0gMIKGYguj68jNu3730wef5ZPBdHG0cSVa7Xnz+zv8gIYHYMcPp80sKrZJnOp+TGErcjleVUuZA++4eyx2KjntqDrgrzgpbtKmy7CsyJ0xh4NSJbveQElnzAdn9gzvUqF34ATVb4Z5KcQHD4gdqysMeu5PTIVqlcFhpCVMXX97ZcHR0dPzDH9sOuvWRhu7dPba9UNq0v8Lrgowrx/sNgqQkYscMJ/1x93FKeQs9yLkvEZIEojaRc+qeuOgIbAYjJzt14+U3H/ar1RZAo2AjshAErc/ild+/AOC6nI0BG08KwPKCmkNOoGYKtzz/on8F8jO1zeNYBsQDfQCEEIuAXsBz9u/6CnijLgXUuXimLt7JgH/+yvGfU50p4EE1ubTZU3mee+hRWFa1a5G/2JR/DoCic2W8uaD26U97/DofYw1yzLWPaEToy2qH4HRJA3juudoJfKmRlMS3D0/0urk4KBR51aqAujciRgxFQWvhA6rrHkDhFe01A6aCVhcWqP5MbG+NlY0AhGxAXruW4Pwj9PklxZlpr05ISsJcKQ2zqYYh+ypfgxozbRocPgwrVhA7ZjjCoA01KAMtys45y9WtkXqS9sS+PM1zm51rptX2TdxwcJNGwTV0T0aVwb5rSt+PphLkkkXP8f1FTVtQGhRMYZPmrJswpUKZOG0a0tq1lLduq7mfjIMqssM5EgPIk99RrZ08PA9jBrTjg5sf5dpnvubBv7zLwPtu8yqjQxnser3MjRp7Pf/cPRX1ChK5e/KYungnB4Obua1qC/tZV1acFfbRZqAxlpbga379Yj5XTZukyX7quAbhb75e4+/Z9WPNLEv75PxB3tQP+K3zIM2xGOuujC8xBmnKjRQL/V+rh2yiOjo6OtVw05YVzs+Ofivizdfq9Bjbu/V3q/NkJbUvuLmzLmrSS852apBzA82eeLRO5dKpBklyGhX4k2BLOd0L8og76nkR0JdIBjX4e0LeVow2dfxnUGz2eFKBSeyY4ZwNCuVU05YcfftfdTufuASprfueI/1QqUtdkRCiXAhRAMwGEiRJ0nMpBwhTF++kyT9fJ23q3dy19ieEJDlfMq4vntIHHwoopYMruUvVOFCJORuYmTyRAwt+q9X+8gl3lz1PXXn7njGq1cSMGUjR0UitWkEdZTkJdE4WlXndVtyxc8DdG7FjhrNv3hJKmjZXlYdhYUgzZjhjOlnefgerJKOgZoWxvP3OBR3H8vyLWGSjUwFW0rM38ur6VdCdG3S183NtjeRtSG5xrWrLkZYV1jXeLKJcqckqa7Pzxbw2Xx0YZOeamfr6V8yc+3e3F5BQ1FhD3tjSLharJFMUHMbBKf/x2u6OHekeZTK/MolGZaVEnilwt25LSCA4/wjSoEFIRiPSoEGQleXWhokTvf7+cdERzH48npeGd2f249UEIE1KwtyqrabKYFP4anWOx+bR3Sosg2QEZ8Oa0uSfr3uMm6UgIa1d4yZnbrR2lT3q1BG23DjKu4z1wOnUpR6Dsh9qHV2re9ecurRada3j3m2/PJVergGDZRkK3NNoN7OWuu07cGdWtQshKVl5jPsyq04Uqjo6OjoAzS0l2nF6cGidjz32LMtwe8d7yqLb18Xy+PwXX2n6XqOwcWZ93caE1KkaKQAspcjIoEXJaVrv2wFD/Jt9D3DGlIq6cwTCaF9cNRoDNp4UABkZhJWfp8WZk3R861X/X0M/4zH7niRJicDrwHHgPHYvBjsCCJck6TMPu3ZEVXR9K0nSwSqOqwBbgJkuii6deqDV5Dd5OGuepk5BQrZnTJAV1YJoX8F5WvhBvpow0K6BlwGTzVrrLArtj3qe5IFLrBlZRnK4pyUlXfTE/lLjrtXz3Ooc1ybqxWd9K0wNiR0zHMa4Tywd23b9sBhz6lIiRgy94NWH2DHD2fX9wov+ntrQfsrfsV2dprEkqQrN4HDs/Rd9fDF4MGL+vguyiALVksym2DQvl8GHtzP+/57judZfcu2pfcxKHo/RQzyExrYybpz5Hjw6123bH1Gx9D26G4Dw8hLCJ71AVlEZs68cTvqekyR2a8kH96qrvuebRiCZtcro4kEJdJz4fDVnhbsiqpZ4yhbnjaLnXiJikuqyKAGtS8w89+1b8GKiW9vBTSquuJBk+qxcxFW5W92sjQAM41/2OHkJLT7ttAB1rHK3y1xBSlYe3VuH88J3m8krLMEgS4zs24YP7u3Pc3M2kb7nJFarwtlyGxJwXdcWfPPo4BqdY2V6rFvusd5UXDsT+4gRQyn934cEWcs1z4qnVX7pzBmGn9jvrFMMRmQPruqN7xqNmDVLK5elnPs+z/SqZHzwyyxW7lWzBq6y/6+pa6GOjo6ON053iSV0y3pnn3amR28a1fExErd5z77q+k5pcv89zs/hs752fna8R5rN/gbqKIyBTvVYBVitNrfsyD7FHoNYAkR5OVJ6ul8XsM9bFGShkCJHcfzqP/P8ymTG3/ocY9vGEuc3qaohPR3JPh+n3B7XOcCMAHyKEMLtD7gDu3eX/b/rn6e62rax2f+yANmTDL7+i4uLEw2RgrBmQqj6dCFUQwTnfxuIMoNRCBAjH58uNhws9Le4nlmzRggQNiRhCQ4RYu3aWu1eHBymuQau18Hxed81Q+tJ+EuDU+HNPd4j54NC/C3aZcnhiNaa36Hy/Vq5bDMYhBg7tm4OvnatsFU6hrfnxuYij1OusWNFqb1fqSzzL31uEst7XOP2vW7n5uEZt0iS2/F3NW8vXhn+jEjv2F+8MvwZ8bfZG4UQQiy57g63toVDb6ub61OHbDhYKM4ENXK7ps/9bbp4/Ov1YtKPW5z9snX1Gme7MlOwOBHa1OP1KzMFeT3eznlLhKXS72VBEtMH3yWiX1koJgx9Wmxs3U2kdo0Xdz7wrrhmym/izgfeFdOuf1DsbN5eWOzybWjdTYz7IvOCzvm8weRRbosk1fq7ds5bIjKG3S2sXu5X12tqs5dtIFYNucvrd7re+45r9MrwZ8RHv+91aztl0Q5x5wPvim/7jRDf9hvhvGY6Ojo6F8v0e1/W9NVfjJtQ58c4MPn9KvtOBcTmnoM1+2yK6ev2ft3btnOdy6bjmQ0HC8WaDn1FZrteovtri/02d9s5b4nz/VpiDBI75y3xixxCqNfky4GjRVFQI9F54iLxn2vuEwLEM3e84vHdHTCsXStsSOoYJaRRree3lyLABuFFF+PRUgrVQmo+UGD/c42++oE9dP8AACAASURBVAZQBHjznfgT0AOYhhqDqjJG4D7UDH5XoQZL/9nLd+lcJCZruabsuopcHBxGVrteDNu/jphjB8nMKfB7oDpPZEf1oK9kILtdDz4Y8jAv11LrvWdQIv1XLfKYrcxR1yT6wmIONRTkyEhEcaGb1cWxNyfT0U8yXc4Yo6PBfMxZrmxO7xr3SBhNyCvrMPNhQgLy2LGIWbM8uvq6Pjfy9dersXn+/ncoLobRoyE5mbLFaQSZT2msVwRww+7MKi3OHe2+nfI/ip5vSXxMJHHREWTnmukmB9HYpn2ltDh3milp0wG4/uAm/m6QyU7oyPLQdgyrJOvhkCYEWu+WmVNAN5t77Ks2m7L4OCQagO+zDzP78XgWFzbFEXHpPwn38Oya7zTf5bisQfd4tyKNHTOc3dE96Ja703mtDQieyprHkD2ZdDPbs1Qeg6H7snh12NO8kzbdzc1ywLE9PP/ag/Do7lqdb3aumSsaNSHqbIHz+A5OtOlIW287VnE+jBnO+mtv5ao1qR7beHJNyWgWzbVevvN81+6E7t3tbCuAyWnTSTmew1+vvY3/flgRpytv8TLmpEzApKi/4b2bUxn30HvAkFqeiY6Ojo6WXnk7NGOy688eqvNjdJz4PPu+n0fnTWs89pUCaBmuTfhyuHVHrszZoqkzWLUJUnTqj8ycAvpJIAuBxar4be62LCKGtkGh7G3RnilDHuPGiM7E+lwKlcycAtqdLSTYauHujYt5OuN7AP696D8cfPBGoIufJKua7LaxNImMwqAoTLrjxVrPbxsaHpVSQohM4C5P2yRJeh04J4T4h5ftZcA7wD4hxFde2uwBHPaft6MrpeqUg1P+g/Tjj4gxY4ioYgLYpOwcQ/evA2Da4g84+NAQAvHBzcwpoIfRyJbWXVnfunutO+BVV3SnP4ucZedk3mBAKAqYTLR89vE6lvrSImLiS4gnnnBem8LoLhQ/8XTN3J106hypVw/YrLqReVKmAkijR0Pr1qrbaV2b+yYnI0VFYf3XvzCgVe44ZJAMBpg6VT12JXfXJlPfQTzxhNvXWmQDTcvOutU7vt9xbgPXpPLLmVImR/fhrmfuwVxSTqOI1vQ8lavZL6KsWDNof3ZFMq+teJBJmfM09QIwPfSX2l0DHxAfE0kjxeJWP3bjQu7auox9ke2YEf8nPl3RksiU/zm3v7gyGYMHB0qLwURQcnKVx/yp/y2Mz1Uzyrleo27mI5rfWBaCt9Ome4z/JIA+x/aQkpVXK1e1zJwCul7RmXZnK9xuBXCsbSfaHvHuZl0d1h49EWtSvbqcVq6P37XO63f9b8ZCnripq3Nw5Nh37OZU7t2cyl/BqZga9cdvmBSbs40BmPrLe0DdZJHU0dG5PEnJyqOR+ZymrusV4V5aXxwbO/UlxoNSyvGGaXtDvKZ+e6vOjKzUtrxZoC35NFziYyIpRUJCYDLKxMfUPGttXTKwY3OEJLG1TTe2Rfdiop/kABhi3k+X3WswKDb+ufRTDPaFIqPNSnjmGgjQAOKZOQUMCmlCmdF0QfPbhkatAp1LkiTb9/FmYQWwAnUcN8He3hOOpWEJSKyNDDpVk/POe0RPeoEOG1YTPekFyoNDvLZ1fQEFC4XY3RvrX8ALID4mEoHEgCM7GXhsd6074Ju2rXCbUJ8eehvyqlXI77yDfLn78EJFgPdhw5BmzCDy4F5dIeVHVsbfis1r9wlnTSEwfz588kn93bvTpmEUgoLRquWNQFXkSjNmIE2eDFVlZExKwhLW2E1t0ry0GKmSqZRw+e94TrsXHuKlld8w99vxnP7bC0SEBnlcxa1cF3HuNGRk0OHMMU29xRgUkFlN4qIjKI5opblOEhB1tpDO5iMM25fFnJSJtJj9P95O+9jZxuCIQWDHaSX1YvXPbPzmdE3ZkzVcxXG8YwDOPle79MV7jxcTbT6qqTty/bCLUkiBGl/KJntS03mme+52r9viYyKRwe03kVDP+bUvJznrw8yn3PaPOuOeWENHR0enNqRuyyenuWo7qgA2gwEccU/rmGYjhqIgufWfzndCs2aa+tGZ7nYEza9yz+KnUz/ERUcQGmzEIMEbI3v5TYnRr30EkhC0jghj1mPVJHapZ2J3b8SgKGqsZCEQknr32mSZjA59/CZXdcTHRBJiLSXanE/c0V1+UzAGCrVSSgFh9v+Nq2iTDZQDnYHRXtoUoboBxgM31FIGnSo4/3WyZrJW1TBdsyXIBB4CvwYCcUd3EWopZcDRXaTMea3WqUetI9S07A6LCWE0EfGPV6vNpHXZkZQEaWmXXZD3QKTTqJv5vZN3I97jnXv6TJYW8+cirV2LNHky8qpV6v1Rg+cm6P33APfJvaeXjs1DnboCorqWFf13OsfCmru1qaxIMSL467z/uB3D2rVblbL6k+Off+21l5YAo2Llnj+WYqxG5SL161ejTKGDj+xwO4YnhZRrvaj031E/bt38ao/nStQPyXQrPKypa98zplbf4YnYMcNZ+vTr1Te0E2Jzt05zEBcdwfmuapZCT1c88nyRM8teROlZt2tna9mqxnLo6OjoeGKcOMqzGaqLttoX1zYXb80Z9tidpN7ygFu9AJAkt7lBu9PH3d4Jl7u3gS/JzjVTbFEQisI/F26vNjtsfaEIgUEotI4I9b91T2IiwiCr96PJqAkT0bttE39JVS1h2evoeeIA7YpO8HXKJMKyvVtxXw7UVilVCtwIeM2vKIQoBxYDdwkhfvTSZqEQ4m0hxDohxGFPbXQujFPGUKDiRXGoSStN2ZVyg4mN16kKG9uslMBVztgzPMiAbCl3lmtKkz49ALtCSpYxTP8ocM9VRwd1YtympNCt3vEcd/nqI98KdCEK3KQkjrWsiNXmyTXA2S+5WIW5KkMc/0cu+prE3KpTTjvaxp7KdRswh33pKVlsYBA7ZjhHo7tVqZjqk7/H6/7O/T7+2GsbV0JuvEG7n7fvqySDJ4IUG73fWFKj46Zk5XHz2oWa4wios9X/VKlljduWBVedwypszy6k5u5KULAPmia8on4uK3O7Xoc796qxHDo6OjqeGHZylzNWnQSqO1Itx761wWY+rSk7+rXsPz/u9t7fPShR02ZPv6v1MbUPycwpQCBpYkr5A5sikIUAQ1U21T4iIYGcobejSBKWcX9xKjeCEAHrBQRgTl2KJFTLd5PNijl1qb9F8iu1UkoJISxCiBVCCO85RNV2Y4QQP12caDq1JTvXTFiRqjF3TCI6FLm7EjheJHmtO5Lb/UoADAnxbu0CBvsqjQIQFFRri67S5SsAu1JLkqDAPx24jk5tiCg+7bH+SJ+Bl8wA8GCbTm51brGpxo7FOPRmZ9kTzc6f0exTFQahaI5xLCwi4K/XllH3e93mcBvzhONaHOnWp+bnmJaGNGyYVilY6fs8HUeg9sGubWQg/V/3eNzHlZSsPH74aC698vdqfpuC0KZ19tvc8/vsGrdtFFSDQXRBgZsFn1NJuno+KVl5FASFuu0W3jGqxnLo6OjoeCQxEcU+2RdwQWPf2tChuXtfZkVCmjrVrV588y0/9UrEHBLOT70SOfvTQrc2OvVHfEwk4WXnaHW24IJCmtQVihDIwgZybe1b6odjTVshkNg65A6E49kxBa4XEKihB4SkWnhZDEYiRgz1t0h+JTDuJJ06ITOngMz2qu+sY+LQrLhCSeU6mVAAzp+n8A81tsaWfPfgwwFDQgKnw5pS2DiCg6+/U6tJTHaumY+LVbNSGxKKqX5f7Do6dUVkaZHzs0MpYJUMnH3zLb/JVFvKIqu2XsmJ7Q/JyZCW5hb/Tttf1exV5ckVrXlpAPdtdoK3/lGr9pUtydrddE3tDpiWhjx+PODuXlkZp8tely4cmvy+mwtfZFkx/5z0RZWHWzxjHnOTXyaoktorvOx87eSuglih/Z2Fh8+O/40fqpl1lrVdB7d9AcKtZZx97kXi8ra57dPqGd39WUdH5+JIkaOY1fcWADLa9+HXj2bX6+LKgNf/hg2tBfO562/06JYVFx1Bh0U/MnvxRjos+tH/rluXGXFHd9Evfy9tigsuKKRJXaEoBIylVHaumWM79iMLhX8t2cW8njcCcP+f3ya7rb9yAlbPubhBZHboTUFoU/4ydgrn4gb5WyS/oiulGhDxMZGcaNoCAAWJU+EV7geVB9Yy0KXwMA9tWADAf//9nd/8kqtj149pND1XRPOzZq54YwK7fkyr8b7zNh5GsqdcXxvdlxl//yzgrSZ0dACksDDNRNhiNLH/h0UBGbDbG62fTfIYL8qB8WyFIiH4v/8HeLbWMdi06aZrGtAaQGnXvhat/UPLc37oe6dNQxo/3uvv4xYA/ZFH6DjxeRSDwW3bA5++4fUwd3y0mvfn/MOjtZc1pGo3utrQ8m9PAdW7JUrDhtUo9hZAyOuvun2nazytUGu5ZsHnVEg4KbJuKaWjo3Nx7P35V+7/Q3WNvurITjLq20UrIQHj2rVIXbsiBQcjDRtGsxXLvDaPi47gmRu76Aopf5CejmS3CL+QkCZ1hSKEGlw8ACylDiz4jTu2L0cGvkmZhKzYsMgG1reJ9Zt7Y03IzCnAKskYFAVF8Z8rZqDg/ztJp86IO7qLvy+dAagBgiOKtTFpzgSHITVqRGlHNbCshOrqAvDR929xYMFvPpW3pphTlyIhkKmdz+3MNQc4kbac9xe9D0D8oW31GCpSR6duCbkpUVMOGnnbJaWQAjVeUlXPXPMzLtnLkpKQBg1ys+oE9bl3pbILoCdFhKOu0ezkmorrN06GVT2wrxxwnMrlC43LNG0aRsk965LrIoYApOBgp4Wp0UPsqqgi9yx0Dp5/76+0PH/G431wzh5QvE5ISkIaPx7s52OrlE2qvHVbpBkz1GQOtfnOGTOQwtVU7K73WrBSoc5znFuL0mKCXpt4ESeho6OjA/fvSsdo72NMipX7d6XX/0ETEmDPHigtrV0/qeNbEhOdLl/17dZZFTZFQUbQattGyMjwiwwOEvK2qnHXUMeLPU8cQIBf3RtrwhDzfq7J3UKz0mK+nf0qQ8z7/S2SX9GVUg2Jb75BdgmM6PhxHYPotHHPQUkJjVKSEZUmIiablYS8rT4UtuZEjBiKQEKh5j63KZm5LPh0Hs/8Mh2Tok5ojYqN21K/rWdpdXTqiPHjkUwmAPW/3d3qUsNmCqKypaaDArtlp5OsLBg7FkXSqjBMqsNxrTnRtMUlYRlpe2CcV+VaZSq3KQ6/yJhZsbEahZEESE8+qSpjnnwS6cknYfnyimMkJVEcFKqRozDEc0Lev83eyNV5W7wqJk+073zhcnti2jSkNWuQJk/m8OT3sBqDUCQJERRE8I8/XFhm0aQkKCpCocI91PUPtL/Jnb+l1MqaV0dHR0tKVh7jvsxyZrm8HGnWKKjKss5lTEICed37cqpxc1i2zG9jHHntWgCuyM5AuWmIXxVTUXeOQMiqPbYky3Q/lYtJsfnVvbEmxO7eiGy3egtWrAEdlN0XGP0tgE7dcbKoDMcUT53gqDYHMmrAwg6UqhsTEjh6RQeaF54gxFKGJBTk4CCi7vSaVNGvxI4ZzsHW0VBWzp5/fcSwaqxFUrLyWPTZj8xJmYhR0VpYRK1epnacl8BEVecyJyEBVqxQTbMTEy/ZezbotlsRP3nOe2Ed6MF/PjmZQ73iiJ70AuA9zlFNrB6LQptyRY0l9R/DHruTI19cT9uslc5zc3Ofq4Rje5OnLjIV944d0LMn7NoFLVrAzz9Xf6+ZjFBeUWxWepaUrDzuH9zBWTd18U4aff2Vc6GkstxWyYDpob9cnOyeSEiAhAQ6AiTG19nzYzMYkW1Wt3herjgWgyz/+xouMatGHZ1AICUrj0nz1QXSVXtVC0zXfuVyYXWT9oyuVL7Tb9LoBBrnmzSjrHERLf04LixcmEZzVM8ca1kZ+fNTifKjPI61TAnhdG+UHO6NATp+PkgI0djHtIrCQULUsctlim4p1YBYkTACq1SRrSPttgecFlE2VwujjAzaHj9Eo/LzKPaHeM838wL2oc3ONVNiUx/YL1blVBn7yjGgGbFpKUGKVXODSwBC+M3/Wken1iQkwMSJAfts1ggXiy+ocIESBgNdX37G4y4dJz5fI9uo6iyL2pQUVtMicIjKXKHGO8Ke6U6SKQkK8djWkQVPGju2xvGRqmTHDjVq6YkTNbrXDkT30JRDbBbC33xNU1f84cdMSZvuceWr6Ioo38RHq8PnJ+jePwM1s2YLMepDKx2dCyF1Wz7jl8/k9xmPMz59Jt+tvzytpdoc2FllWecyR5LV+YwfyYpSxwE2JCwGIxkd+vhPmPR0JEUdNUpCVHgD+dG9sSbk5xxxLkTaJIn8nCP+Fsmv6COnBkT5wMF8MUhdWzkRFsGeQTe5jKBdOi/XIHmKWj/6DwI20Pm62YvofiqXDmeO8XXKJNbNXuS1beq2fO7dnMqQvVnOOlcXC0WSArqD0tFpcDgsviZPRho/Xo0bNXo08qpVVSoLSps297oNKhQzp3r2c4sf5KAksvVFie5z0tKQ1q5FmjwZw5rVHI1zz6pX0CYaefJk1XQ+2T/xssQNN7hZcl21cblze0pWHn9Z/7N2H/ufJMs0nf/9JRcfjeRkzlx/E+A5s5/r50OdtEo7HR2dmnHTzPd5et08Yk7n81TWPIYnfxCwY9P6pHloUJVlncsbSZaR/KyUannjtQCs7DSAhx+YQqdRN/tPmMREhEFdAhOmIPZ26kVxSGN2Jc8P6EXdiBFDUWQ1eYzFYKpReJqGjK6UakCYS8ox2gMCNy4/T4v5c5HtTnwGxVYRIDwxEcUeJE+R1FhNvfN2BGzU/5ht65GFeh4mm5WYbeu9tn1233KmpE2nzTnPFhLFoeEB3UHp6DRIHBYr06apcaPmVz9QODfydq+T/1OtO5D12IvsmbeElts3cXjye04llWaYljC4zk7BZ7hY9+QFNXFTtp0OCfO79Vy/caPdrndBsBpXKjvXzK9fzKdzwSE3FzcBsHr1JdsHN1uxjILRdwPac7faMxI6VjtLjhzzk4Q6Opcu2blmRq9fqKl7IHthwI5N65PDdsW2qFTW0QEIOXuG5udO+zWOU2xLNXtuQcL1vPzmw/7NxJiQwB9/fhSA+S//ixOKESsSby7YHtBK7dgxw9nTZzAKEsf/OfXSW6yrY3SlVANiiHk/D2cvACDMUsqf/1CDrQrAIARtYtRU1dltY8no0JfioFBAHUgHctT/6DG3qsFqUQOdR4+51Wvb9stTq/yu0jDPAXl1dHQCi1bPJCGMJs3kXwA2SaZg+mckfP5v5wu848TnMaxdi3T99c7sayIomFbPXEBg6wDC9sA4rPYFBKfy58/j/CmSSkICJeHqANSheGp7tpDsXDN/nrGWnns2agYXDtnl5s0vWYWUgxbz56oWf9iDnYeH87cnPwAc1nsSi1vUYVZBHZ3LgOxcMx/8toegSnFAw61lhG/0vhDZUJEL1HhaEmq/4ijr6JCRQYdtG2hx7jQM8V+AccWiPqvdopr5VyGF2n/MLgoD4Pet+Vydu4WI0mJmJk8M2MzyAGRk0H3bOgwIOr71qt+zGPobXSnVgHBE8Qf1RWZw+QxgWZ8NQGZOAccbR6BIsjPqf4iwBWzU/9gxw8mJ7c+psGbkfveLV01ydq6Zn2lZ5XdZJD22v47OJUFCAvLKFc4McLmT3yfzsRfZ98Niz32A3U3QkX1NTl9+yStAhj12J8s/+4E1va5hZ4cerJswhcFTJvhbLACKOnXRlEvaR5OZU4BVgf+3OsXNSsoGUNBALB6mTVPjeQgBRUU8cGwzoL5rjUJxlnV0dKonO9fM/Z9nsnrvKU41auasd/QhUQu+949gfuTMMVUJJVAnasXHG0jfqXPxpKcj2133RHm53+LkCqs6x2y5bo3flSmZOQW0MecDMHz3ameImkDOLA+ov6VNTQbjz98yUNBn6A2JxEQ1JaZic7rmGVx8jvMKS+gKxMdEst9gxCrLKJKMJBSEKQgpgGMtNbaWElp2npancr22WT97EQ9lL6gyM9eZsKb1Ip+Ojk49YM+kBtDR/lebfRoCwx67Ex4LvLxLW66/jagtFRYMv145hPiYSN5Z8iGNKlk7AJjvf7iaJYNLl6v/WKHJmnj1Hyv8LJGOzqXDjBX7KbNPcLe16UJ08QnN9i6nLr9g5z2P5wAVfUqvE4HpyaDje3Z1H0Cs/XM5Mgdcyr7EZLdgvGLlUpSbViH/vsxvY68h5v3EZMwF4JY9a1WLeSGQg4MDNrM8oIbTMRgw2KwoJhOGAJ6H+wLdUqoBkd02lt9j4gAoM5hY2P06TWpx0aQJAHHREURTSiNrORuiYjlnCuH+e98mu60/urUa8NlntN67g1BrGeKJJ+Czzzw267RtPcHWcreb2jUmS0jf3vUmpo6Ojs7lgm1DtqbcNjOdpduPcfeWClN5V7fDls8+7jvhfM2YMYDLu8Ze1tHRqZqUrDxOLU3n7bTpvJ02nRize/apYJvFD5L5l93XVGRiBTiY6D1shc7lxbajRS4lUansO84tUxdfZCFQyso4Mr/q8Cn1SezujZgU1eLIIAQFTVtwKqKVXxVlNSG7bSzJ/VWl2aNjXg/cebiP0JVSDYgDC34jMUedKATbLPQ5tg+osBpqlbMLgF0/phG3dQ2hllKuOqymmbXalIANJnkmeQ5QcR6OcmXayeWeA+ui+uQrpiCvKeh1dHR0dGpOs7Pa4KFD92ZS+smnGIXNWefoj6UnnwzogeHFsmvwTfaUImCTDewafJOfJdLRuTTY+/OvzEmZwNjNqYzdnEq3kxXW8M44egOv9o9wfuRM526Aeg0ssoG211zlX4F0AgZXdzSDovjNPW3TFaoLvw0Ji8FIRoc+fpEDUC2OjCYArLKB03IQilefmcAhM6eAg03bALC1ZaeAnYf7Cl0p1YBIyNuKQamYEESfVv1rHS/286NGA2BOXeqMJWVAEGYpDehA59kDh1RZdmDa8ofH+rz2XZEnT8awIr1BT4x0dHR0fEXrrtHOzxLqYOL5X7/QDAOdlkMPPug7wfyAmtnWrpYSoiLTrY6OTpUMWP4LJsXmTBzgOilx9CWbt+YGdAatuiY718zJ+Yuc18MgFMIz1/hbLJ0AoTj+GiyyAVCTPxXHX+MXOZrEq4rSJd2v5uEHptBp1M1+kQOAhATSxj0HwFdxtxNjPkor83GUm/wXCL4mxMdE0vasGj8uLn838TGRfpbIv+hKqQZE1J0jEJL6Gldf8PZAeIDNYGTw7TcAEDFiKDbZ4JwwBHqg86Z/fZqlXdXU7n8f/hRN//q0x3bbE4Z6rC80hPg9hbqOjo5OQ6Lry89o3PMAGpeXuLU71T6mwfe9S1vGotg/C3tZR0enelodydEosj3ZNsQf3HxZWRBk5hRQIgcB9kDnQrDbFuxfoXQChmURnfmur+re+cg9/2BZRGe/yNGpeSMATg+9lZfffNjvGfgaD1LD1zQrPYss1EUif7sVVkfc0V08vOEXAD7+aSpxR3f5WSL/oiulGhIJCWR36gc4Jgrq611Gfak5ovrHjhnOpmtvVScUjvTppiAI4ABrx5qoIXIPRrbz2ub8Q486JwauNDvvH39rHR0dnQZLQgKnu/bQVClIzkmlM5bUa6/4VCx/0G7lUgz2z0ah0H/hbL/Ko6NzqdDFbtFfFTGn8+n04ywfSBMYRIQGcd1BdZHY0Z/2Pr7PfwLpBBTxMZEosjp9NyD8Zl0jrGpCk36dIv2ukAKIaaMmsjod0w2BhAL+dyushiPzU5Hs2fewWAJageYLdKVUAyI718xJU6izLLtYSikGg0bpdLp1FDLwxxVdyQ+PDOhA5wcW/MZ9m9QH9bO5/+DAgt88tgtan+WxPrTNFfUmm46Ojs7lypHYfpqyqGTnUNK8JSQl+VIkvzByn9Y9YOTW5QHtMqCjEyiEGKre7uhR2i3332QtO9fM9OX7fOZCGLQ+i4TcLZq6VuEhPjm2TuATlr2O+zYvAeCLuW8Slr3OL3IIuzJFMhj9cvzKyEGqdeF1JYc5Gh5JTvMo/7sVVkNGhz7Y7K6YVtkQ0Ao0X6ArpRoQmTkFdCk4BLibQG/qFe90ocjONXNqjxpMstn5IhTJENCBzhPytiIrqg2U0Wb1GtSvy44Nzhva1aXkivgB9Sugjo6OzmVISa++QEV/a7LbqjrKYY897Huh/ECrv9zn/CwBkoTTMllHR8c7fwy5UzNec1C5rqixfywxsnPN3Dsjg3fTdnPXJ2u559O1pGTl1auSKiFvqyb8hjAYGnxcPp2aY05disFlTuSvGIaK1a6UMgaGUip4724Aei39ibbFBRSFR3D7k38KCCsub3QadTMfXauOHyaNfD6gFWi+QFdKNSCGmPfT+dQhj9sMbdo4Px9Y8Bt3b/kVgI5njhFVdCKgA51H3TkCYbQvp5lMRN05wmO70/knNWUBSMHB+stcR0dHpx7YsTUHcMmyV+k/zZr5WCI/MW0aZ25SY3woQKkxiF9rEVfK15YYOnWP/hteGG9d+6DHsAuVidm9ud5l8cSMFfuxKIIBR3bydMZcrGvWMmn+Vt5N2819n2fWy+9dHH8Nit16wibJ5L31boOPy6dTcxxxgQGsBiMRIzzH061vhMWifjBWY+7oI4K3qdaFkhBICMLOFfHPhdsDuk+Oi45gcBc1PM39cW0DWoHmC3SlVAMidvdGp8ueK1bZQM6tdznLapa+imFAoAc6z24by489bwTgo/i7vboZtti3Q2MhdvyKdrB8uf4y19HR0akHmuepCxmV3zrOcgDHKaxrfhj3EgCnQpvx1YCRJO0LIiUrr9r9snPN/HlGBu/9upuxX9TPJFenftF/wwvnuuU/ep2IuPYrIZZSX4jjxvGiUiYu+4Ifkl/mpZXf8EPyy7y34N88nTGX3rnb+XHj4To/5rajRUhCPXtFktgQ7j2Wqs7lrNu77AAAIABJREFUR+yY4ey/6VYA9jz9IrFjhvtHELulVItfFwaEu/qBzr0BdWFIAMHWcnrnbg9YLyAAMjJI+PYjAAa880pAXEd/oiulGhKJiXjKXaJIEr3bNnGWNZZH2C2KggI30PmBBb8xettyAJ5c853XmFK7W3fRZIPK6HuDrpDS0dHRqSeuOay6Uru+dZxZXXv0uKz638Jv1eDmLUtO81TWPN5b8G9St1UfxDkz5xR9D+3gybVz6XkwwAfQOh6Zsy7P+Rv2CvRJUAAxdfFO7ln1g8eMe+WVpicnGzXx0Kr+eWL3MpI2/KQmDELt68bsSOelld8wJ2VCvUwiYxbPwyDUhWOTYiNm8bw6P4bOJUxGBt1WqDHWes/4j98UGUVZ6wGInD8Xhgzxu0LlwOkKxbUERJ8+FtBeQACkpyPZA8ZLFstl7/YfGI6gOnVCdttYDK270O/YXk19EMJuBWXXpicksPP6EfT+fQHlspEz7TvSavY3ATuBUC27VI28UbHZY0rd7dZOLj6jyfwUcv6sz2TU0dHRudxQmrcAs+o27TqxtAHGHTv8IpO/uH/9QkC9DgJ14rpv4XeMA0b0bsP9gzs422bnmsnMKSA+JpJ9Py9l7qxXkIWCVTbweqvGcGMXv5yDTs0Z+l46+06eIzzEQNecbcxJmYhB2Chfa2LV9Z3137AG7PtlKZ3MR5xlQcXzY6rk1NfBnE92rtnn7i29MrWLoK4uyibFxqjZ/yX7mbvrVC5bfn6VZZ3LHE+KDB/P37JzzRxeugZQs7uL8nIkP8jhSv/jqvJJpqIvqfAC8pM1WXUkJqIYjRgs5SgGI4YANQ7xFbqlVAMiM6eAo01aOsuKpL4+hUlrBbXrxzS6pata9iDFyuHgZgGbeQ/sll0G+60qy15jSvU8lastuwx2dHR0dHTqljN9PSeRUExBPpbE/7QoqXDZckxc7/19Fqv2nmLS/K10mbSY7Fwz2blm7vs80+nqNXzxtxiFgow6yb1xwddMXbzTL+egUzO6vbqIqf9+gr3TRrFqyl08njmPIMWKQQhM1nLEZb7aXROyc80kZi3xOAlxKKZcCbFZKH7uRR9IpmVLi05Vbh90eIdX6/0LJdgoV1nWucxJTETI6j0hDLJfvFwycwrY3jIaAJskYTWa/O5t0+KWm1R57OVA9wIC1ZjkrRsfBeCtGx8N6Lm4L9B7ugZEfEwkJlGxupTZvjdWSeb+e9/W3Ohq5gZ71gSg7dEc3n1zZsDGQdiVX4TdvR4h1LInwmzlmnJwpbKOjo6OTt3xx013eMycFdTUP642/sRTqNeoohPsnTaK/dNGkv3e3Xz/xOv8c8F2eudud7rrDTiyS7PPwLztfLoyR1dMBRCjP1pNxwmLnH/r3r2HAcf2YEDQpLyE4XsznW0NgO10YI6lAonMnAJu27FSY93uigyUywanxQNAr8xlPpPPwd4y70GcJUBCcH3m4jo9ZplVqbKso4PkyenVd8THRHKwpWr9+/2Vw9mf8pPfvW22t+sOwG9dBlMc1IjcmF6wbJnf5aqKzJwCdrTsCMD+5lGXveu3rpRqQMRFR9C+ScUKdYtzZ7DJMuVWRXOjFw++xpm5AaDV2UJmJk+s89WeusKcuhTZHphdFjav6U/z7YH/HIOb0gcf8oF0Ojo6OpcnnUbdzHlDkLPPdU4gH3nEf0L5ifJusW4TawNgQiADTcpLmJI2neHJHzDXHjR5bvLLRJw/o9mneVkx7y34N0u2H/OV6D4hJSuPcV9m1Sj4eyAx+qPVbD58hvHpM/l9xuNkfDiOppYSu0LCUxRPuHLTah9LeekRERpEk/JzVbY5FxQKVIzpDnbuVc9SaUnJyqP/gT88/sauSKJuFQRNO7WvsqxzmZOejmRT50SSzeaXOERx0RHc0681AK2efdx/wdZd2HxM7U/WduwHSJR7WjELMOJjIhEmEwAmm5WI0MvPytwVXSnVwOhwpmIg260gjyCblVlzXqXr/q3O+r2d+/Cfa+93lmXUh6HLjg2+FLXGRIwYitWghj+zyQav6U/X91K14QfbdSV38vt0nPi8z2TU0dHRudyIi47g0NxfsOGikBo7FqZN869gfiDsy880iTZcFRaunx/L+hEj6nvXABhFxcjZ0WbMjnRe/H1mvcvsK1Ky8pg0f6vTlbHjhEUMfS/d32LViG1Hi0j/+BGeyppHp9P5tC4xewzs74qh9LyvxLvkyM41M335PvIW/ebx2rliVGyaZ6fE7NlKvr5I3ZZP3NHdGqW7K47y6pN1a5WvPDDO2ZdYZAPKA+Pq9Pt1LnESE1HsyapsBqPf3NPaNFYVKJ1aNfXL8SsT10VVko3asYLw8hK6HNiOcpP/A7BXRVx0BKMGqErn23as4JdPfwhYryVfoCulGhIZGYTu1wY5lwCTzUJ41hpnXXxMJMJYEeNeoCp79vW8ykeC1o7YMcP5441/AbCru+cYJilZefy+8QAA6yKi2WM3h9TR0dHRqT9ixwzHuHYt0uTJsHYtJCf7WyT/kJDA+R69q21mQquEqmxj4SgnrPylzkTzN6nb8hlwZCdPZ8wl/eNH2PevUXw4+UEGvu3Z6jkQcChPvp77BtHFJzxaRgk8W0qda9TYJzJeamTnmrnvMzWemmHlCqfLqzflVLCtXLOt25mj9SyhlrgjOwktL/EY4woqfvvem1bW6XG3HVGtJwUgJIltR32rjNMJbLLbxjLthr8A8NqQJFLkKP8IYlPDwMgm7y6uvqT/STXQ+YCjqku8DChlZRyZn+pHqaonbP8eAEZvTw9oryVfoGffa0ikp4PQvjoFYBCCNjEVnVbc0V30W5WsaQOC3m0DNw6IHKRq5HvtWE/5n29n13e/aMxFU7flc+su1WT+T1uXYX16FfRaHtC+xDo6OjoNgoQEva9FtZayXX21M3W8A4fywtvk1hMh5aV+yTZWG1Ky8kjdlu/MLpida2bexsPOcz9w6hwj+7al6/6tTLJnGHSshHYvPMS3/3mU57r8zAf39vfXKXjktflbSba7Ge7I3VpNa3fFVKgz1K5nHC6BAO2ahbB6wpALkvNSI2P/KXrnbSc+bythZRWue47n4lSjprR0cWctadyUoDMVoSdKOvk2o6FtebpTcVbVsxtecpaUrDxNhs2LITxrjbO/MCg2WmxYi6eM0zqXJ5k5BeyI7AjAvsj2/PDzNrq3Dvf5uyJ0324AgnfvhFsSfXpsTxxZ/DtRVGTfE4DFYCSjQx/+5F/RquTKkzkAGBCYbFavGeYvB3SlVEMiMREaNUKcP69xGxCSREdKK9qlpyPbrM6ijLp6G8hpM4vWZAEVD23uj4s1Sqmhp3MYu3Ghs41k9U+aVB0dHR2dy5SEBM4Mu5WIXysCH1eeyLoGdq4qEk2YtYwz//0Y3nu1joW8OLJzzbzw3WbyCkvof2Qn8Xlb+aFDH/IKbuPzVTnY7Cc8wGXb+PT/YRCK2/l2LTzET5uPMqhTZJ1N6C+WlKw8krPyGJ8+k1t2r8UmJLdg3NUpF82hTWnjZdu1U5fx/Ldv88OOdGTgeGgE1/L9ZaGY6rR3C7NnT8KgWBGS7HwGBCCZTOwccjstF37rvLbrOvVn2OYKq4EdjVvT2UeypmTlcf+6CmvFynHzXJ/fViVmNs9dzP2Dn6yTY++3hTiPZRCC/UoIiXXyzToNgfiYSNYYVHWpUbGhCEFmToFvlVIZGXT/+F0AWr3yPAzq5/f5VkbHK7mLimdz2xWdeeuWp3ll1M1+las6whOvhZQvUQDZZPSaYf5yQFdKNSQSEmDZMkofepRGe3ZWDJzkSilD7elEJXvwcAFYkDnQfQCBmowyt2d/WPgNCmCTZQ70HqjZ3n/FAmThsPlCzUwRwGlAdXR0dHQaHs3ffA1laarGatlVmeGK68TW9bPj3R2x+OeAUkpl55r50ydrEahKpzkpEzApNmySzGsnD3Jly46M2fY7Lc6ZuXlvFjICq2ygzGDy+H0ysOTzp3ilXUrAKKVSt+Uz8fcveGL9T14VT9VZuxkiIzVlh0VZZFgQz3/7NmN2pDt/49YlZr5/626YUFgH0qtsOFhIRk4BV3duEVCWdk2y1hBsswBgFTaEJINQsMoGjvxjGp3NZpSF6n1hkyQ6H96t2f/WtFmQ8ZRPJr+p2/K510P8sMoKScf2e9PnAHWjlOpzYp+mX+h/6kCdfK9OwyAuOoI7B3aAFDAqCkFGmfiYyOp3rEvS05GtqnGDZLEGhBGAw9vHYWW4o1UMm6MCdVZbgWxU348SIPk5q6K/0WNKNTQSEiiL7ampWte2B9ltYzVtjl5bsSongOUxcSyL8NUaVO3peEUzl5JETIswzfbW4SGa8pkht/i9g9TR0dHRucxISEBeswapXz+kJk2Qxo5FHj/ea3PX4OiVy8rpM9zx0eo6z1h3oZnwkr5ZjwDmff0C3ye/TJA9ELVBKExOm8685JcZuzmV4XszMdqzDpoUG40tpV5jZ3UvPMSDn7weMMFdR/Ruw0PZCwAvMb+aNUPq0gVp2DDAs4LKIoQzJtXUxTudQd5/2nyUO3as0CgfAa4oMTN18c46kT8718yfPs3gvV/3cM+MtQFzXQEyiyqupgHYZo/9+XbioyyKH6VaCIQ0QpENSMEhhAVXrJtLgCwU0mfM9YmsEZvdE/8oQcFIM2ZwpG1Ht20xhUfq7NhKmTZwusmoT9V0tFzXUw3JMrhDE2Y9Fu975XNiIoo9AZVi9F+wdVdUb5+KfrVN8UlsitBknw9EQja7yG21+iWbYqCg93QNkLMjb9eU+x3d7RY4bUOfa52fJeCm/Rs0GfoCDdu6dYA9Y5HNiqj00Bbc9Wds9q7IIhs4/uT/87GEOjo6Ojo6qAsimzbBmTNq4Pdp0zjfKMxNgVFiCkbq0QOpdWuNS5BjUB17Kpc/Dp9h0vytdaKYys418/g3GzSZ8FKy8hj6XjodJyyi44RFXoOPD30vnUcXfca+aSOJO7YH19C2koe/yts84ZptMFCCu96vHMGkVBET6t57Ye9eSEtDmjEDxUOTbutXMOX1L3k3bTefrszh3s2pfP3d62R8OA6jBzWWBMSOf5rpy/ddtBJpWupO5/Hu3pjKtNS6UXZdLFMX7+S+tK81dX1PqLFUXlv+BZZVq1WF7u/LkN9+C/n3ZbR5Y4KzreOqlW3Z5hN5n0t+x81t0/jhfyEpiS2drnRrfzY8wqmIvJjfMDvXzDpDhOa44QkDve+gc1liCFIVQiO3ryDOHtjbl2S3jWV6vBqp6YXbntcaPviJXd0HIMDZJzcuK2Hgsd2+tyKrJdarrwbUUDsEBQWEgs9f6O57DZBtbbvTzv5ZDZRopcuODbgGTmt23WD4sKKNSbHS5pfv4bE7fSxtzSiOaOF8QRsQlIQ302xP33OSLpXK/u8idXR0dHR0IHT4UMRPP2nqwqzlsGOHWvjsMyxPPkWQqFBzhFrL+PWLp/jqqttJ7driolzcsnPN3P95JmVWhXs3pXLrnjUs7n4Nbxokym0VipKTZ8vpOGERRhmsCgQbZQZ3as6d33/EU1nzqlUw1QRXd0aHMs7y1Ux41v/BXTd/+xN9PdQ73SsffLCiMikJ85uTiczP1Vg/mRQbLy3/H9GFR4ksOa3JuFgZx/kP37WGHmm7CTHJF2X50G/J90xMmw7A9Qc38Q+jAZ68+oK+qy4xfPUFUWe1FguOa2YUCjfMfB/eeEibNCEhgXPjJxJ2ptB5nQYe31PvsqZk5XFX0QnNPW1DwpiUBEBn21m3fQ5JITz0eSYWm+pOdaG/YWZOAS3PqkotCVCoFBNWRwcI3q0qojounge/LfC5+1xmTgG5TVoDsPmKLnTzdUwrD2w7WkQ3KvqVfvl7SJnzGnJSAkQHrueMGDQYgD+uvJaQ118l9jL28tEtpRogS3addH52BEo8ILTubd3auWuOK7vABRLXFh0GKjqba4sOabbH/jofg33gZ1JsxP4635fi6ejo6OjoeGf8eDcLIjq4KJmSkrCFNHKLP9W14BBT0qbT9aeUizp8Zk4BvXK3s/Cr/8eUX6dz/cHNTEmbzpSf3mXe1y+wb9pIcqaNZN+0kex+9w42/Pse9k0bxbp3/0Tb779l3MZFHhVPNc0mWB3Dt6/guTmb6ujbLpyfm3V1rrRXDm7NjBluE78W7a/w+D2DD2+ndYmZIIRHa7HKbpshNgv3bk6l1KLw2vwLt1q/f6tq6eY43n0Z8+vc/fNCGL5rTZXb250+5rF+Z291wua4Vjvaa8NTrD9YyP/9tqdO3RRTt+VTYgzW1J0Jq8hOXd6ylds+UmEhvXK38+TaufQ8uJ1nZmVf0HUvPm+h2fkiwHHfCYgMbEsPHd8TvHwZYFdql5fDN9/49PjxMZEESWpPKRmNAWGNlJC3VdPXyoBsKQ94d7idp1Sl8y/NYxm9SQkol2tfoyulGiDNm1QolyTABoQWn9a0Cdm9w/lZAMJoouWzj/tGwAvAcOp4leWQwlNVlnV0dHR0dPxGQgKsXQvN7Fa+0dFw8KCmSaMxozVl1wH2X9O+uKjDFyxNZ07KBHqdPKBRkIzZkc6AY3swYnePB4IUG00tJRgRNCkvYUradBpbvFtrVI6JVVU7b20jyku47q0X/D4gjz15UOOa6FRIDRsGdksZDY8+qgl+XdkKzJXqrMz+/ttn3Ls5lZ3HimutoJu6eCeJ7y7nSJjWWqFL4SEWzJjHq/O3+vXarh9wo1ud6/2w0YNLHACHtQuSxiOHnOeRnWtm6htfUfbWO0x7Y2adnV/X/VtpWl6iqVOaV0y6TQ/9BQXt/dsrfx+zZ0/kxZXfMmvOq7TduZlJ87fWOlZY2eo1jNq1CqiwlKIgsGPi6PieQou2pz1R7FtrurjoCK6NaQ7A23dd6XcrKYCoO0do+pRLxR1uU34xAAbFhsWqBHwMrPpEV0o1QHq2a+78LFAHmd17ddS0yUtbpWlz+OobAzow+JHgplWWhaLtoIWoq/VbHR0dHR2dOiAhAcxmNTNfJYUUAMnJFIc18ajYaWop4ZGk/3OWs3PNdJ2kxoHq9upixn2ZxdD30ol9PZUHv8xytunz9yV0nLCIkDWrMCk2d2utSlSOC1X5P7grlyojPLRxKmtat0aaMcNuP6T97lv2ZPh9QN5xxRJN2SobYOxYSEvzvENSEsyYQWGbDh6zs1WHqxIrxGZhStp0lnz+FD9vPkrHCYvo+XpqtRY3Uxfv5NOVORwsKGFB2wrljoQ6yP/b0i+ZlZXHfZ9n+k0xZbqyL54idTl++47Bnq9aTJF2AbL7yYO8Nn8r6w4UMOe/35E8+1VeXPktX6dMZP3sRXUia69lP7s9Gy3jKpw6Y8cMpyCyjWZ7Y1sZwTYrBgTB1nL+vfB97t2cymercmp1zUdt/k2TSVqqnD1bRwdYEz8cUOMnlRtMrIy/1ecyRBeoCuO+J3N8fmyvuGSv29etH7uS5wf03Bbgqi4tAbj24KZLIgZWfXJJKKUkSWouSdJQSZJa+FuWSwHbt8nOz44BUmWf9O8addS0ab12OWRk+ES+CyH/9rudg1yLbCD/dm3siTYRWtfDds0a+U44HR0dHR2dOuBA0zZudY5hdlLq5zz+zQZufi+duz5Zy8r/G0fOtJFsmnYnwz/6B3FLf+CRlXM4m76K7q8u5q5P1nJb1kK2v3snL638pkolVFV42+5UqISHV7QdNEjNUFepDYC5bTTk50NSEvKggW7bQ61lNJr5ZTXS1B9TF+/EWKyuWjvk2nn9CDVYfVUkJZHdupsmWH1VOLMrVqp3zUj41XevA1BiUaoMdJ+SlcdXaw4wfvlMls94nNHb093axB3ewdtLptM7d7vflH79VyzwGBzfQfczRz3ul9unIsi3BDQrO8eVS+Zyz4xMWm7IIMRa7lQEBa9eWSeydjlVca2dytVKGTS3/eUZjVyuSECn0/lMSZvOS8tn1uqaV860dyDhpoCfVOv4nvYjhwKwqmN/Hrh/Mp1G3exbATIy6DF3JgDhD44NjPljejqSqFjuUE4V8OaC7X63vq2Oq04dAOC6g5tJmfOaXwLXBwoBr5SSJCkCWAgMApZLktTSXv+xJEmjXNp9KUlShiRJr1VVdznQLXuVpiwBB9Eqba44kafZbgjwNJRFpVbN4LWo1KrZbmqjHciHtIvygVQ6Ojo6Ojp1R/Rpz5NzgKsOb2fpjuPsO3mOjA/H0abEjAyE2soZuzmVKWnTeXnlN8xNfoVeeTuY+PsXTEmbTqhi8RjTqDI1sfBxKqKGDVP/ZsyAoiLV+ksIyMpyWoPlTn4fGxIK6mLSiQ9nVHxRVpZHq62rlv1YAyk8Uzn7WUpWHlf+I40ukxY7rceqwvDVFww4tkejMGl69nRVuzjps2+zW/ZEB54sx842CsfQxrsC8rqDm8ixx/ma+d3rfLXmgFvblKw8Js3fynPLvuKpdfPodDqfwYe3u32fCcHYP1KZmzxezXLnByzWKjIaAnTv7rH6lHDPx/R22nTGp8/kmTWzNZZ8MTs2XJBsrvdNdq6ZiFPa+FaFLdq4KYaa/vVpSuUK2bxlnHwyax55C2ueWbKklzbM/qnrbqrxvjqXD/vM5QBsjOrB+rY92H2s2LcCpKcj2+zPtMUSGPPHxESEJDn72a4FecxMnhgwmV29YVitztllxCURA6s+uRSy7/UFXhBCZNoVVAMkSSoBWgshFgBIkjQGMAghEiRJ+kqSpK5An8p1Qoi9/jsN3xE0+Kr/z96dx0dV3f8ff52ZSQKELSyyEwgocUEroDBqaawr7VeL2Kpfo7b9aqPWfn/dvtpa7fa1VrH7t1WL1VpbpGqrWLUiKhpwSaJGUHaQJYGwh7BDlpnz++POTHIzkwUScieT9/Px4JF7ztx75zOTO2HmM+d8Dqxx/+e8rbCIUXd+O9Y+b9V7sW0Lzv+gSTxE+PQ3/oWP+pVtTn/jX66Vej46IYeh1L/pWzp4DPqvXEREOpOdPbLoc6j+A0bDkTd+4L3/u5aKvoMZdKj+29/GSRA/Yf45+/Ymv3VMVP8o0f01vj3WPvvspqezNTDqzm+zatwpVM17jaxpF5E74xL3DiefDCtXuu4z89B+SsuqmJidxRk/nc/ew3WxGLIy07lq4nC+/7mT4+6rtKyKax4pojZk6Zbm4yvBUfxxUf20kkVrd3HDYyX89cbJTcb7uZKX4/rWDhlDdouPFDb3G8zg/e5als09z9suvZxel07F3Hxzwn381I90z9u4mLQHvwvfcb+vm7dsKxMqVvLl0pdaNdrNj2XaH+9xVrnrQO98sosXwwOZkOC2WKKu0UikqF57d7vazuOAW0uejdt34uYVFPz1A27+zJhW17iZU1LOXXOXYgGfgYK07dzeaOW9yrQeNJ6mMTE7i4OBNGxNXYu1wv77kbu5/pQzmXbakIQraJaWVVG8vpK12/eT8/4azqK+Hmx4l+qjSrxnPqzgagyXrygkb/0HvLD8Unjxdy0f2F7y8gj7/c6AhrS0pPj8WDo0F4aO4/Qta0izYXxAWqiOYPlSGq4+n2zM+edHPocbTCeogXU8JX1Sylq7EMAYMxVntNQ9QAnwsjHmC9bafwF5wDORQ14FzgPOTNDnSkoZYwqAAoCRI499qeVk03fwwLi+nnvcw4eXDx7NpHUfxtovn3Y+lyXxEOHqunCz7VHWmZ5ogDoM4/zVHRWaiIhIu+jjTzxeKZqgGHh4HwMjq3M1pTVT8kI4bwCjI3gaJp6a/ZCdn9/ydLYGcmdcAo2TUVErVhAyvtjKuQADD1bxyvpKvvp4CY/P+iZnbFuDD9jVvQ+3XHk3fzzojBBonJgqXl/J+PIVTClfSvHI8fyxNsyEipX839z7GHRoDx8PGsuVX/41592/gK+ff2JccqC0rIqM6uq4xz7yg9aNLDp0wlAoWwa4n8Naf4D0t5xpZaHP5GFqa7FpaZx4+231o2++/nVsKHG9r+jv/ayyj+Lu88R1S/n+nO8TCLcwCqnh46lseiTe8fLW2p3krS9t8vbq9G50a+L9Z/8xI+Hj+P5E16gvHObVFdt5Y/UOni4ItpiYKi2r4q65S7m98HEuXf0ur4w7h97Vh+KSuZkJq2HBkYzu9Kg57OpL9PoZfGA3b63dxVtrd/G/Ly6nLmw5Z0x//nrjZErLqrjy4XcBmFCxkkvLV8Z+536gnG4k7ztz8Upwxxr8WHKqnNfzp15aw6+/GOA7//xVBwUQZMV/XMP452dT8/yLZCTB58fi9ZWc2KMv0VdgKFLofNgV07wNrCXBIDX+NNaNPgXfzJnkJsFz6ZWkT0oBGGMMcDVQBVwHrAAeAP7bGDMSyAQqIrvvBiY00edirX0EeARg0qRJKVMZ+739hisa9Q0a6/6ub7DP/Z9set/eJLNN2eM4rVF7fIP2kuxTOQWnRkPIH2D/lHM7NkAREZE2OuHL/4l94IGEH24TfRBvTQ2jRGqzcwhsXIe55BJ49VXn/Glp7LwqnwFP/gUfzv+nu6/9KgN7ZzgH3XBDu9e32dN3AP337Iy1e9UeofrBh3n8nZdiU+kABh7eyz9n387cU/L4ff8fxSWlPpjzEv+IjA5LtALehG1rKHzov8j7+p/5wdylAK7E1KyF67i7+mDc8zlyr7vQdlMm7/wktt3w+H0nDGNA5DnzLyx0pmbk5dU/jwUFUFDA3v6D6Lt7R9zxUXvTe/B6Sbkr5nPnPh5XvL6xxo9nT58BdHTFzdwNy7h4bXFcf/T31O1LVzZ57Em330bdS//AV1vTYr2R7qFa3n3oKzx/ymf4csDHdZOzE46qiypeX8nthY9za8mzGJzRV3vSM+P289fVxR8MHJpwFv0W1o8YbPpDhOWJp3/IvHHnMHLPtlgCbNTar+L3wR2Fj/Olj19jQINkczQx5VuypIVHLV3R9Uc2Au4vE658bTb3v3xTs9d8e9qS2Y/xwOIRuUzpkHts3pRQ7KQFAAAgAElEQVSc/lRXHyTNOp9vXzx5Kk+dfTm3D81losexNae0rIqT/AGK+o7iF4vDPDmxKilWM/RCp0hKWWcptduMMfcA3wC+ba3dZoyZDdwLbILY/7M9cWplHUjQ1yXYBsN9LRAyPgZ+42uufU42h5ptJ5sDW7bH3lyFgV1l9d/2lZZV8cr7G7k21mNZtmUfuR0epYiISBvMnIlZsiSWKIKWE08tjXRKNH2s+7SLnY35850itZFkyQlA+NmnCdfUYNLTnfcOx/Gb2wE9M7B76uOzwPnvvMTp29YmHDk0Y0UhQ0rGAOfHbistq+Kep38WK6TdVMHx7P07WPrrL/K3CZ/nwb638siidVx66mDnQ1xREcMaTNuKJUyu+EKrHke3q76IfeCBuP402yChEQw2+Vxm3fSVuOMbPobuNdVxybTRlRU01ngqZuPzrDshm/L1lbz9yS7yxp1wzB9+Ssuq+OPCdezYd4SrzxqZcFpa1IDnno69AU80JdTcdlv8QVHBIIGFhRw+/wK6VR9udhSfBYbs3xWb2vdA9VfZtu8Iv73mzITHTMnpz2nvPe86Z9+ag3H79SZxUmrEfT8mfM581+OJPqZoX3S64dSNi5m6cXFsn4bTD6NJscbHA4zZlbjAvXRtw66Yhv3FPa6+Eft2UP7yAuiApFRpWRXLN1VxCXDT7MU8cXOm54mUiVtWEdpUX1Nv5cDRvD94HMXrKz2PrTnF6yvJ8QXwh0PU1oWTPt7jKekTNcaY7xljbog0+wJ/AXIi7UlAGVCKMz0P4AxgYxN9XcKBXn1c7Vc/lx/3RqhbxaZm28mm59BBsf+0fcCq2vRYMdPi9ZVMiQxt9wGBcCgyh1hERKSTmT8fZs2Ciy/G5OcDzRchb1xEu/Ft0KgQc1qaM+opKhiEO++MJU18byzA97N78L2x4Piv/HXtta44AQYeqCTRI4o+hlMXvuTqn7VwHYMOVCXct3G7Z+0Rbi15lvznH2Zj5SH+uGg933pqMTe/8ifX6nAAdYG01k9VnDmTMCYu6rSe8SNvmjr+iK9xBPV6hqp55U+38uCbaznxB/9m1Pf/zY6Mni2etvHEs747tnD1I8X8/o1P+NIf321yVb/mlJZVcdWsd3ltxXY+2ryXH8xdyv0vr2xyf/+O+tFmjZOnxudrubBvMMiuKVPjztFYw5FxN73/PHcUPs7zS7Y0ufrW6m37Y6MqEp03+rvM/OoNJBQM4ps1CxNZht74/ZhZszAnnug63iT4B04R9JsbJaQaO7E6uVcOE48sdX/GiV5XV7/5VIfcffH6SoZWOQsCnLxplWerejZUMXcextaXdjmxspy0gI8pOf09jKplU3L6U+fzkxau6xTxHk9Jn5TCmV53vTFmEc4XDg8B50faXwd+CTwf2efXwFXAv5vo6xLOK37V1c5dvyJunz4H9zbbTjYjyla72lPXfRD7Izglpz/V6c70Agv4rGXY2OEdHaKIiEj7KChwklOzZ2POPjs2EiRRAqquwf9/JNjHpKXBu+/CLbc4/xYubD7Z1DBJdbzNnMnhQLqra9iByrgEUUMruw2IJUHmlJTz+srtrpXQmnqeGiYEvvzBi7zz4Jd56snvUf7vBWTviE/O1Jx4dOOt/fn1Cbboffe4/butPj4jHEqYXIzGPG73Jj5dOJfayOeuPd17tXhO2yjRddLOMiZUrOTrRc/wqc0rufv5pUe9ZHrx+kpCYbhmyTyeePqHXLNkHn9ctD7heUrLqljvS5yYsz4fJiOjVYV9S754I+FGfc0latPDIW4teZZnn/gOsxauS7jP2n+9GndOqB91BbB/8HCYObPpOyoogHfegZ//HN56y2mvWUPI3/xEFIPzASzRh7CGSapefVv+HUsX9NhjCbtPW/dxq1YabasLqtZx5fI3APjrU3dzQVXi11hHKho5nrCpf0Vl20M8f6Yv6UcdTczOwk+YM3es4/+yjyR9vMdT0k/fs9ZWARc16o4ro2+MyYvs94C1dm9TfV3BsKqtzbYBMi44H5580t1OYoOiNS0iLlxbwqiqdcBYAHK3O8slG5w3OlR6n7UXERFps5ISuO46zNy51B05gj8cdn0gT//WN2HMGHj2WbjySvjtb2Glk7QxAH/4Q7NTx7x2ML0b3etqmry98VS8wXt38swHmxjZP5MfzF3Kr178JT1DNXHHNK4v1VCPUA2ZByoZeqCSp+d8n/LeJzDgkPttYuZnjrI25ezZzv3MnQu9e8NPf+okKVrJl52NLStz/W5jI4oi23e9/ig/fP0RMkK1La6uCFAx4RyyP3CWHDdAGmGenX17JHFmmDV5BsUXj2vxg9C3nlpM4ZqdjOrXg817DnNHpBYTOFPTLln9Lt/p9ysW3uF+L1m8vpLh1fHlIczUqXDppe76Ws0YfdmF1H4zgD/snkrX0tTWCdvW8KmH7qf0M3+Ke4znvftyk8nP6PN9qG8/Wqy4muC1FXhrEfacc1o6skmx3+Fllx3zOSR1rfb14qQE/f2q93PeY7+EG/9xVOeLrgA5Jad/q5Iiuas/JBx2UrrdbIjc1R8CTSxo0UFGX3YhpQ+czOTIFL6JK97Dd90VsKADRvy2warn5nPSoX30PbSP0bdew6p+L8SvVNtFdIaRUq1ira2y1j5jrd3WXF9XsHv6F11vSnZP/2L8TqeeGts0jdrJ6ITbCghHh0jjLG3sm/03AN7/+7+5MFJE0wJ1/kCXXlJTRERSzOzZcPAggVAI8+67mKlTMcOHY+64wxnJER1ZVVAAK1bEpv8xa9ZRJUa80CPsnkLVVH2dqOz9O7jr6fv47eur+c0LDzBjRWFcLShffj6cfHJsalVjDVe3C4RDZO/Z5hppFjY+9xTH1or8nti69eif940bMdnZznMQCFDbPX6EUc9QNZmhWgLEJ2Nco+N8PsysWVT+81/u/shPZ5SO5daSZxn93JM055t//5Buf3mM3z3+fS6e/Vu+9exvuCUy7Sz6L2/jYq5+7kG+9dRi17Frt+/n7M31dV5iseTnH9VovInZWfht/LimkImfMhkVfaxf+vg1nv1wc9zt/crrR3c0NQU2feQxjroPBjGBQNzoxbhRjE0cHuvv2/fY7l9S2u8mTk84EhTg2o9eOapzlZZVkf9oMb96dTX5jxa3buRkXh7W73OSwunpSfGZa+KWVUyqWBVr+2wYampanh7ssap5r8VGTqaF6qia95rXIXkmZZJSUu+dU8+LbYeMz9WOycuD7t3B73d+JsEflGYFg3x8qnt9h027nW/fRr/8LIEGb1ZKT5mS1FlxERGRYxYMOlPwNm1qempRwyRVksu8cjoQnxSItsMNEkvRrf9YuYivvDiLK1YuivtgHwYnObRiBYTDHOyT1WIiIIB1TdtafdrZ3ryP2LgRrIXaWtIXvNZsvbDGibjotgH4n/+BggImZmdRnZbe7LTAMS8+3WxIvf72F+6b/yBTNy7m1pJnuXbJvIQfHm587/lYDaf7X15J3i/eZNdrhZxwYLfrPg0c02j2tJ6ZriQPwLIh8eNFGv9+Bxzex6rn5rs+bJeWVdG/wWp3rtganL/fT+4+6jhjHnzQlfxseH011vhxxfZL9vfm4on/MJVNJjT9oUSTUuNFX6Mz562kujZM2EJNpNB2i4JBVp57CbU+f/KMRCosxNfgCw4LkCQJs+ZkTbvI+SIECPl8ZE1rPDms61BSKgUFy5e6/uNLWPQ7GHT+kNxzT/L8QWlBdaS+Q/SxdR/QD4ChWza49ss80GVmaoqIiHRus2dj8vMTfmAPdevBrjPOirst3Ya5pcEKZtCwDtAwV3/Pm7/mur2xRKv8ZW9a04rAj7NgkANZA2PNRB9CGyY7LGCGD4fo6LmIcN9+ccc0tCG9T5OjI+aUlPONhX9zjYpq6oNDug3x+NM/5DtPL+GPi9azsfIQ1731jGt/C4QCxzia/dZb3Ume/HxO2t/8RIjo/n/7+w9iH7ZLy6r40sPvsqLX4GaPDUHb3hsXFLhHLFqL7913sYG0hNdi3MiX7t07xXtz6XhnvTG3ydu2Z7Y8uu7+l1fGXqPvbax/7Yct7D9c26oYdvToS00gndKhSbLWeV6eq6ZUyPjY+MN7k/41lDvEmSBsgIDPF2t3RUpKpaBhV0yDbt0I+3z4MjKcdiIdWcy0HQzZtNZVP2BYpPh5L+uuMdC4LSIiIkls9mzC6fW1I6Mf0AO/+w2DHvqta8SQafSTRu2D1/+X+4aZM6mcHleKtNlC2f7MVq6ad5z1vv9nse2m6idFH8fWyVMTjp6Lrh7X1OPNqK1ucnTEvGVbyTqyv8U4o3HlbVxM/6Wl3FH4OG/M+hrnbVgcF3N51rBje985c6aTcBs71vk5ezY9Lv+PhLs2fqw9QrWsfm4+F/6qkOsfK+GqJfOYVL48bt+G24Fe7VBkvPGIxWAQ36KFhHr2ihsVZfr1c1/b//3fbb9/SUkb0+tXWW88mnJE1TYoKmr2+FeWb3MtVGAhtgDCe3//d4urcpaWVbFp535Cxtf6KX/HWzDIhmFjXV1b11d4FEzrVcydV//lQl0dFXPneR2SZ5K+0Lkcg2AQ3xtvOPNoW1lEsjNInzQBPng79sc3fdIEANb0HUo2y2P9a/oOZZQXAYqIiMgxCfz+/7A33xxrm/z82If57aNzGbyhvl5Ik/WUjEn4RdyAuc9wIK0bPeuqmzxHw/N0+1Ebpm21p4ICam+5lTQbjqu11TCBYYFh9kjic8yciVmyBPvqqwlvztu4mLnPzYfzx8bdNrFiJYEGU2KaE43j0X/8mKzqQ01OV6sZE38/rTZzpjvpNns2B5avoueSUlccieL65ux7KRr1KcbuKmdygzpXrpFmDc9x663HHmdzgkECr87HnnseNlJ6IlYb7nvfg+eegxkzml/1T7q08KXTYMkiwD0t1ADGhqmYO49hzXz2u6N8EdPmPwg4CxWM3LONr73/PIFwiFpfgPtG9IXJNzV5fPH6SnqFw9T5/NRGpvx5vWpcaVkVn/TLZuxmZ5Rrnc/fKabCFY0czwwMFkutP0DRyPEkqATdJSgplaqSeKWdYxXu5XwzYHCGVUfb0T9A0T/M0baIiIh0EgUFTjIguopgg3pYQy7Jw/5xVZOHAoR9fvxvv9X0e5/0NGiQlGpqZb5Qtx4EkqgWV7pxyky1aOjQpm+bPx+Tloatq4ubrmiByW//G7gt/pQv/vOop1T0jSSkGos+hHFfveooz9i8Xos/YON9v2HIT39AenV9Yq7xyLKcPVvJWeKsRp2omP6RUTl0PzforHZ5vJNCwSDmnbfjvzxunHQTSWByb0uYxMl5A6wOZTAs/rCYqW+9ANS//vMXzyMtknxOC9dxxWtPws+bTkpNyenPasKEfT7SAj6m5PQ/9gfTTorXV3Kw75BY+w/nXMP5E8/2MKLWGX3ZhZTfPYje1Qf5zWe/wvTLLvQ6JM9o+p50GiX7nT+/0aWeo+3utdWu/XrUVSMiIiKdTFMF2m+4ocmi39E+/8MPNftlXM9JE5o8vuG5A7/7zdFGfXxNmuRqJiqKbcCZ0tacq69ucvTSxWvejevLf6SI85e/3WJ4zeXLEtXrOpYi5y0Zdee3yThyGHP22RAIYLKzaVzuuWFdrEQxdr/0YqdA/tq1HZMY6mQlNCSJ5OVhffEf4aOv70MVTddaKy2rYllltet1kBFy15FqOCo1kYnZWZxsD9Cttobnz/R5PkoKnETZads+ibW/UfQUG1583cOIWmfillWM3LedrCP7+ekbjzJxS/PPfSpTUko6jcz9e4D6kVKZ+/dQWlZFeY9+rj+uBwc39/2AiIiIdCrBIL5Zs4DENYAaTvVr0v33u6ZqRY8zt9yCmToVc/bZmFmzkm/FwpISTCDgXkHQGPdUs4svbjm5MXs25OcT9vnjEklZh+IXiPnafbcx4PDeuBXpGv6MWy2O+KRPw32t3398V8MqKYHaWti4kdr0bk2OhhPp1IJBln3+GiD+72EYw8sDxjV56IYXX2dCxUpXX20g3dU2PVqoqVdUxOkfv0PPmkPkXndFizWsOkJm6XtcsrY+jrS6usQLfSWbwkKMdVZ/9dXWOKMnuyglpaTT6DvCGZZpAT8QyurHzHkrGbJvp2u/rOGDOj44EREROX4KCjCzZsWNvjH5+U7CpSXBILz7rpOAGj7cqeMzezY8/DAsXOgkNJItIRX1ne+4k1C33w75+dCvn/Nz/vzWnWf2bNb+499xo4j8wKrn6s8xp6Scc8o+arp2V2R7d/ZYNlw6vcXkj8FZ8nz5567qsJFB3b50JdD8SC7X7TfccDzDEWlXA3LHxKbwNaz65sdy3bYlTR/3wbukWfdfgB7VB4H618LSL321+TsvLMQXjtS5q0mORErVvNdc85zDPh/7p5zrYUStlJeHNT7nuU9PP75J+ySnmlLSadgPPwTqh6dWvV3CRR8uZ8R+d1KqX87Ijg9OREREjq+CAhg/Hh54ALZsgRtvPLpEUjDoJKA6m+h0snYogp074xIOjz2Jbp+sqV/1Cfjgnt9xcOLZTMzOYt6yrXwpQTqnNpBG+ne+DX374svLo38wSH9g1cBR5O4qA3CNrGq47QN6Bc865riP2uzZ1Mx5inTrLtTeOC4Ak52taXTSqQy7Yhrh3/+ScE0NvnAYsLHX8mklC5o8rvSgn7xGfdERKgYIGR9Dz51Es/LynBXew2FMkiRSsqZdRPix3+KPvN7vPf9GBmaNIdfjuFoUDLJsRC4n7N7Gqz/5Azd04b9DGiklncbew+45z/0PVnHFkvrVZPRtl4iISIoLBmHu3OQe2XQ8zJzZbvWOut/+3dh29L3TNUte4b2//xtwVt3zJ6iuXpvV37n/RrWQRu3e3Oz9RZNAo8o7diGaxhMVE009NIMHw8aNHRiVSDsIBvG9sQDfz+7h3cmXuK7phad9usnDPrUsvn6c61Viw/QqfqfF+1578iT2ZvaBBQuSIqGbO6Q3vgZDNT8ZmpMUBdhbcv/LK9mW0Zuq7r350c7e3P/yypYPSlFKSkmnURno7mpfuLaYbjXuJZAPBTKS4o+jiIiISFIqKKDW5wfqi3/7sfR6eg5zSsqpWfBmwgRO5lcTf+ln/ck58SJwVvyIj7pAGmb69PoaYlu3ehCZSDuIFMs/dFNB7DUaMj4yrryiyUOyd22OGwPZcDKfD2f1vpbszcikskdfSocmx1ikirnzIFz/SG7vsSspCrC35JXl26j1+fFHYn9ledNF6lOdklLSaUwu+yi27byBgm51Ne6lfX0qZykiIiLSHF+CkVB5n7zHD+YuZXf3Xq4PCIcD6U4NriZGaa0dflKz9+XZSPaSEmr7D3B9CN9z1XVdc6SdpKwBzz1Vn1y2YQY891TcPnNKyrn+sRJCaY2KmuN8nooKGUO/w/uavb/Ssir27D9MDYb8R4spLatq82Noq6KR4wk3WJFwnenhYTStd+mpg+l95CADDlYxoWIll5462OuQPKOklHQa/caOiuszjfL94cyeHRSNiIiISOd0aNjIuBETww5U8vjTP+Te+Q+6vvDb16NPs9MG00J1LRYUXzM4x5OR7OkvvoBNTydsDDY9nYHf+FqHxyByPG2qOtxse05JOf/8wzOM/+tDdD+4v9nVKMPGxz96jmn2/orXV+KzYcLGR21dmOL1lccaers5bWhvTINE++f/dJ9r8YZkNf1IOcGyj8g6sp+///1Oph8p9zokzygpJZ1G1k/ujnvT0/gC7v2Z8zoqHBEREZFOqfczc3DKIzuiH1TzNi6Oe281sNEqx431HDWinaNrR8EgvsJCfPfei6+wUCUeJOWkTZoI1L+Wo+2otf96lafm3Mn/LPorQ/ftaP5c4RChjz9mTknTyZEpOf0J2DAhn4+0gC8pajf1Kn4HX4NVBQOhOmdFviRX+5cnCESK1KeH6qj9yxNeh+SZ5JwELpJIMMiGE7IZs6Ms7iYLhDH477ij4+MSERER6UyCQfZm9iXr4B5Xd6JRFKFAmmuKT2Mj7v8JoU+/gQnVxaYRNTa8hcTWcRUMKhklKetzm5fEVpW0kXZD164qJD1cB8S/NhONcLz6o9e4+oXP8YO5S/H7oHuanwtPHsRvrzkTgInZWXyY7sNXE+DJm6YkRe2mopHjudznJz3srL4X8vnJmnaRx1G1bHj1Xle7777dHkXiPY2Ukk7FDB8W961e1MqxZ+hNh4iIiEgr7Pl0nqvd1AfW9O98u/kTBYP431qE75ZbMGlpYBoXV4C63r3bEKmINOXAhvJm2702NL3qZaIE8unb13Lf87/gnQe/zJN/+x4nrV/G80u28K2nFsf26XNoPyccqGLillVtir29jL7sQmYFv9Sgp6UJxUnCuv9Wrty6NylqdHlBSSnpVHJu/rKr3fCPaU1dqGODEREREemkcqae3eJHt/3dMputJxUTDMLDD8PChXDvvWy/5f+5Vu6r+n/fbWO0IpLIqpMnNdveuTO+cLlt9DPK4CyCMGNFIUMPVDJ583KeefJ7TKhYSeGayGjHoiJGl69iYNV2uOACKCpqnwfSBhOzswiG65M5aeFQp5gKt7mbO1m/o0dWUtTo8oKSUtK5FBSwe+DQhG+i+hzYm6BXREREROLk5YHP12xiqqb7Ua5iFVmmfsjDv6Ps57+mfNJ5lP3814y6s4XRViJyTIaMGORKMn1QVRe7bU5JOWv6DEl4XMMpf4k0XNHvFy/9mryTBjo3FBZirFMHiZoaKCxs+4NoB4dC7keyY98RjyJpvbSvfJlan1NNyQL7MnqQ1SO9+YNSlJJS0ul8lH0qEP9HtGfNoY4PRkRERKQzCgbxPfxwwg+lsQ+5Q4Yd8+lH3fltst9/SwkpkeNo/5RzqfGnxdoDN63nol8VArDkmZeZvqIw4XGm0c/m5OzZSv4f7nIaeXnY6BTd9HQnuZ0E5uScG9uu9QX4c86nPYymdXJnXMK7Uy4BnN/DrSXP0v0vj3kblEeUlJJOZ8iOzUD8H9G+dcmfERcRERFJGgUFVGfEj4aKvscaWHOgY+MRkaOyIGsMC0c5RcgNMGNFITP+8QcALnh/fsIP+61JRDXed+yHbzsbwSCbBmWz7YThsGBB0tTzzcrqFdv2hesY1DvDw2hab0RlBVD/PI94c553wXhISSnpdPy1Na529Nu8jCu+0PHBiIiIiHRitWec4Rot1bAWFDNmdHxAItJqU3L6c07ZR0B9YuOGxf8GYOBBd9Hs6O2u13gr7Rkysr4RClNrYdXW+HpVXrm7sH6EkR+459U/ehfMUTBDBgP1v48yfyb3v7zSu4A8oqSUdDqZJhzXV5XRA2bP9iAaERERkc6r929/hY3UlrJACKgZPBRzxx2tK3IuIp6ZmJ1FhnUv9pQecupK1Qw4ocnj9kdGSIZN68ZNDfbVArDqufmM2LmJ4Ts3k3315ax6bv6xhN3uMis2uRJtmRVlnsVyNEK798TqewEMOLSX55dUeBmSJ5SUkk4nfOJJcX2ZjUZPiYiIiEgrBIP43n4bc8stmFtuIfDuu2RsrVBCSqSTqOzR19Xek5EJwO6T6uvwNh4ZtaWXU7jcZ21sn+YcrHUSX1XzXsNg8QFpoTqq5r3WltDbz2WXuetkXXaZh8G03toRJwL1z3/PIwepqYsfgJHqlJSSTqfkizcmWML0aAehioiIiAjg1IV5+GHnX5LUiBGRVurVy9Xsf2gff/3V3zlQ/D6QuIZUdKRUotsS9dVO+zwAWdMuwmIIA7X+AFnTLjr2uNvT7NmQnw/9+jk/O8kMmj2B+t+DASZsW8MPn7nP05i8oKSUdDqjL7uQg2nd3PUPMjM9i0dERERERMQLQ86urwvnJJQs2154hd57K2P7NE40Da/adlT34d/v1I/KnXEJ2/sOZOOQHMqefoHcGZcca9jtb/ZsqKzsNAkpgKIR4+N+N9OXFybNtMiOoqSUdDoTs7M4cGMB0KDI+a23eBeQiIiIiIiIF+64g+iEr2h9op7VB9mVmRXbpfGcksGHqkikqQpT2/dVx7ZDgTQqR49LroRUJ1V91mRXO/r8r/j7Cx0fjIcCXgcgciyGPPw76N0NnnvOWRlGdQ9ERERERKSrCQbZNjqXYRtWYXASUJ9f8RY96o4AR7/SXiK9gmfFtk0oxL6aEKVlVUzMzmrmKGnJV15wrxIY/V29OfgUutLapxopJZ3XzJmwdq0SUiIiIiIi0mWVDRjhao/cv4MBh50pdw1HP0VHUrnX62tZ5rKlAJSWVUEoxO4jYfIfLXbacszGvfFiwqThqbvLOzwWLykpJSIiIiIiItJJjTJH4vqixbMb9zF9Olv6Dj6q82f940koKqJ4fSX+cIiQz0dtXZji9ZUtHyxNqsse5WpHf1+fe+/lDo/FS0pKiYiIiIiIiHRSNdOvwEKjgucO10icjAxWXX8LO7v1bvZ8DY8xgC8cgsJCpuT0x2/DhI2PtICPKTn92yP8LmvQxXkJ+3uaox3L1rkpKSUiIiIiIiLSSX3Qazg2kopKVKy8xh+An/8c3nyTv5mhnFi5qclzRRNS0eLpIQzVxs+qcROYmJ1FRl0tE/eU8/yZPtWUaqslS5r4faV1eCheUlJKREREREREpJMKli+FWFoqXrU/He68E4JBhq/+iJ61h5s9X9mkT1Py+XwAVg0cxT0Xfo0FWWOgqIhe1Qc5qWwFudddAUVF7ftAuporrwSIjXKLJgRtXp5HAXlDSSkRERERERGRTmqzv0eTCSmAtHBdbPvy3WtctzUeGRU2hrTz8zDnnQtA7s6N/PD1P3FB1TooLAQio7FqamJtOUYFBTBrFvuHjwKc5zUMbDfdvIyqwykpJSIiIiIiItJJla0pj1vFrWHb170+yTHsimkQCLhrUOXnQ7fuhH1+TEY3hl0xjdyKtQD4sWTYELmrP4TICB6LgfT0WFvaoKCAf5x/DeD8PnxA6YGulabpWuaHr9wAACAASURBVI9WREREREREJIUcyOyTsLh59GfGrbfU3xgM4lu0CDN9OubsszGzZsHs2fjeWIDvZ/fge2MBBIOsO3kC4K4pRTBIrc9P+akTYYGzn7TdmbvWA/X1wKLtriLgdQAiIiIiIiIicmzGfvh23PS9Qz16kTl0EMyYATNnum8MBmHu3Pi+BkmmtwePYyKwMWsoj02ezrCsMeTiJE4qTp1AthJS7aY27B7nlrF7l0eReEMjpUREREREREQ6qTG1e+Om7716w7dh7dr4hFQrnX94CwCjqyrqa0oB/nCYrQdrKS2rakvI0sCHeZcTatA+qfStLlVEXkkpERERERERkU5q2He/Edd33r5NbTpn1pL3ASdhkFZXS6/idyjdUIkPS/meavIfLVZiqp2cf9LAWGLGAL5QHRVz53kZUodSUkpERERERESksyoooHLsya6uI5sr2nTKteFusWLofiyrQxkUf7IDgJDPR21dmOL1lW26D3Hkrv4wtu0854aikeO9C6iDKSklIiIiIiIi0olt6HmCq71tX3WbzjfOXwM4I3fCxjDOX81Zw/sAcNam5Zy1bTVTcvq36T4kIi8PG0iLNcPGx2lDe3sYUMdSUkpERERERESkExvUO6PZ9tHaP+VcAMJAjT+N/VPO5YxNKwD49MYlzHnqbiZuWdWm+5CIYJB1n7kUiEzfC4c48vob3sbUgZSUEhEREREREenERp6S4yp2PvKUnDadb0HWGPZkZLK9Zz/uufBrLMgag1m0EAAfFl9tDRQWtuk+pN57fUcC9dMlSw90nVRN13mkIiIiIiIiIqnohhswGRlgjPPzhhvadLoLqtbRp/oggw7sjq2+Vzt5CgDWGEhPh7y8dghcAMbvcWqAmUj7zF0bvAumgykpJSIiIiIiItKZBYPw5ptw773Oz2CwTafrVfyOM5UMSAvV0av4HWpPPxOATed8FhYsaPN9SL2qsDs1s+vAEY8i6XhKSomIiIiIiIh0dsEg3HlnuySLikaOx+LUlAr5fBSNHE8oVAfAojETKR2a2+b7kHqHqva62vsr91JaVuVRNB1LSSkRERERERERiXFWfzOR6WSG04b2ZkXZbgBWbD9E/qPFXSZp0hFOLV/pak/d8CHPfbjZo2g6lpJSIiIiIiIiIhLjTN+zGMAfDtGr+B2WllcCUGd81NaFKV5f6W2QKeTjYbmuQvUDDu8j84k/exZPR1JSSkRERERERERiikaOJ2wMFqj1BygaOZ5TB/UEIOTzkxbwMSWnv7dBppDTw/ti29Fi59e9OYc5JeXeBNSBlJQSERERERERkZiasyazYuBoDqZ146cXfI2asyZzYv8eAJw2Mosnb5rCxOwsj6NMHdl7tsb19T+4hz+/k/qr8CkpJSIiIiIiIiIx6e+XcPKODWTWHuGnr88i/f0SwpFC56eN7KeEVHvLz4/r6hGq4eQNyzwIpmMpKSUiIiIiIiIiMZ8pmoc/UlMqPVTHZ4rmEap1klJDFr0GRUXeBphqZs7kUFpGrK5UdArf/7z5F48C6jhKSomIiIiIiIhIzMDeGXHt9CWLARg2/wW44AIlptrZocHD4/oGVKz3IJKOpaSUiIiIiIiIiMSsumg6YePDAjX+NFZdNJ2MxaUAGGuhuhoKCz2NMdUMvPsOANcqfEcGDvImmA6kpJSIiIiIiIiIxCzIGsPcU/MIGR/51/6cBVljqMt0Vt+zgA2Hob9W32tXBQVsOGWiq+uTnNM8CqbjKCklIiIiIiIiIjFTcvpT5w8QsGECWKbk9Gfv1h2AU+8ohKHik83eBpmCVo0+BagfLVUZ6OZdMB1ESSkRERERERERicksfY8vfvw6AE/M+QGZpe+xfOBoAELGUBtIo2jkeC9DTElD168G6gudj176gXfBdBAlpUREREREREQkpvYvT+C3YcBZfa/2L0/Q4wwnCfXP8Rfy1evuY/RlF3oZYkr6ZNhYV3vs5jWsem6+R9F0DCWlRERERERERCRmUKPV9wb1zmB4rzQA9sy4itt/8lUmZmd5EVpKO72XiW0bwB8OUfbcy94F1AGUlBIRERERERGRmBNuKyDsDwBg09I44bYCbF0IgPNOHqKE1HFy0qBesW2Lk5janp7pWTwdQUkpEREREREREakXDLLgqpsBeOXbP4dgkHCoDoBF66ooLavyMrrUdcMNhI0zWio6ZmrQJyu9i6cDKCklIiIiIiIiIjFzSsp5uqYfAA9tT2NOSTkVuw4AMH/VDvIfLVZi6ngIBtkwJMfVNaRig0fBdAwlpUREREREREQkZt6yrYyo2gbA+K1rmbdsKxWVTlLqimVvcFrZcorXV3oZYsrKNGFXe2D1Po8i6RgBrwMQERERERERkeRxvd3CZxb+BYB7XnuY0gnDsVVOEuq6xS9z1cevUTZ9PDC26ZPIMdk8cCSDKzbEpu9tHjiSIZ5GdHxppJSIiIiIiIiIxFy8cxVpkRpSfhtm8q9+xJhl70Xalm42RO7qD70MMWXVjnESfbZRO1UpKSUiIiIiIiIi9fLywO+kCwxAKARhJ01ifX5Merqzj7S7AZ+sAOoLnUfbqUpJKRERERERERGpFwyy944fABDGUJeWTuWZZwGwp+AWWLAAgkEvI0xZB/r0iyWkou1U1imSUsaYfsaYi4wxA7yORURERERERCTVvfSpiwBY238Ed+fdyJKAkxzZ/9UCJaSOo8HV+2NT96LtVJb0SSljTBbwEnA28KYxZmCkf5AxZnGD/R4zxhQZY+5urk9EREREREREmrf5LaeG1NjKTfx4wZ+oXu5MI/uk8rCXYaW8LaNzXe01Q8Z4FEnHSPqkFHA68B1r7b3AfGBCpP+XQHcAY8wMwG+tDQI5xpgTE/V5ELuIiIiIiIhIp3PpwXIA/FjS6moZVLEBgJ/OW01pWZWXoaW0ISMGxUZKWaB0Tziln++kT0pZaxdaa4uNMVNxRksVGWM+CxwEtkV2ywOeiWy/CpzXRJ+LMabAGPOBMeaDnTt3Hr8HISIiIiIiItKJ9B09AnASI34s3WqOADB2yycUr6/0MLLUtn/KudT60wAIGx+7uvVM6ec76ZNSAMYYA1wNVOEUof8h8P0Gu2QCFZHt3cCgJvpcrLWPWGsnWWsnDRw48DhFLyIiIiIiItK5bCvbisX5AB4CPl32EQAP/msmF1St8zK0lLYgawyPTbocAJ+1/Oj1P6X0890pklLWcRvwMfAt4CFr7Z4GuxwgMpUP6InzuBL1iYiIiIiIiEgLsj53MQBhAOPD2DAA6eEQuas/9C6wFDclpz/dCWMBH5YMm9rPd9Inaowx3zPG3BBp9gUuBW4zxhQCnzLGPAqUUj897wxgYxN9IiIiIiIiItJKBggbg/X5nXZ6GuTleRpTKpuYnUXwjpupy+iG9fvxpaen9PMd8DqAVngEeMYYcxOwDDjHWmsBjDGF1tqbjDG9gbeMMUOBacAUnKmvjftEREREREREpAVV814DnKSUz1q2DBnFiC3rOXzPz+kRDHobXIrLnXEJvPkGFBY6CakUfr5NJL/T6RljsoCLgEXW2m1N9TVl0qRJ9oMPPjj+gYqIiIiIiIgkuVXPzeekKy8FoM7nxw/4wyFs9+6YBQtSOlEi7csYU2qtnZTotqSfvtda1toqa+0zDZNPifpEREREREREpHWiI6V84ZDTUVPjjOARaQcpk5QSERERERERkfZRNe81DE5SChsmbAwAR4yfVeMmeBmapBAlpURERERERETEZUjOMMAp1uwHPhySC8D119zLgqwx3gUmKUVJKRERERERERFxGcURwBkpZX0+6gJphIyPZaNOZUpOf2+Dk5ShpJSIiIiIiIiIuOXlETY+LEB6BoHsEYSMjydvmsLE7Cyvo5MUoaSUiIiIiIiIiLiUDs2laOR4dnfvzbXX/Iz9fQcQ8vmVkJJ2paSUiIiIiIiIiLgUr6+k1h/AHw5TFwpjNm/CZ0Osem6+16FJCgl4HYCIiIiIiIiIJJcLqtYxdsNi/DbMk3PuJBAO47Nhsq++nFVPv0DujEu8DlFSgEZKiYiIiIiIiIhLr+J38NkwBgiEQrHttFAdVfNe8zo8SRFKSomIiIiIiIiIS9HI8bFC53V+f2y71h8ga9pFXocnKUJJKRERERERERFxqTlrMm+N+hRhDD++8GbeOyXIwfTulGnqnrQjJaVERERERERExCX9/RLOK/sIP5YfL/gTfQ7twxofuUN6ex2apBAlpURERERERETEJVi+FH84BEBaXQ25G5fRs/ogXHABFBV5HJ2kCiWlRERERERERMRl2NjhmMi2HzDWYgBbUwOFhd4FJilFSSkRERERERERcausjG1aTOQfHDF+Vo2b4F1cklKUlBIRERERERERl1XjJlDrCwBQE0hj6eAx7O7em+v/814WZI3xODpJFUpKiYiIiIiIiIjLgqwx/OuUqQD87pyr2dL7BHZmZrEs+1Sm5PT3ODpJFUpKiYiIiIiIiIjLBVXr+MKKRQB8852nGF53ABPw8+RNU5iYneVxdJIqlJQSEREREREREZdexe/EVt8LhENkHdyLLxBQQkralZJSIiIiIiIiIuJSNHI8dX4/ACGfn6r0HtRYQ2lZlceRSSpRUkpEREREREREXEZfdiEzP3sTAIWjJ1BXG6LaQv6jxUpMSbtRUkpEREREREREXCZmZ3HuKYMBuPCT9zh92xqG7d3OaWXLKV5f6XF0kiqUlBIRERERERGROH0+WQOAH4sPOOHgHv7297u4oGqdt4FJylBSSkRERERERETi7D1jIgDhSNsA3WyI3NUfehaTpBYlpUREREREREQkTtnY0wAo7zsYC1jApKdDXp6XYUkKUVJKREREREREROJkb98IwIg92wHY0WcgLFgAwaCHUUkqUVJKREREREREROL0XrYEcGpKGeBQWgalQ3O9DUpSipJSIiIiIiIiIhLnhLEjAWfaHsAhk0b+o8WUllV5F5SkFCWlRERERERERCRO4MB+wClwDhCwIWrrwhSvr/QuKEkpSkqJiIiIiIiISJzV4e6xAucAvY8c4Kxtq5mS09/LsCSFKCklIiIiIiIiInH6HXGPlBp8YDdznrqbiVtWeReUpBQlpUREREREREQkzienTAIgHGkbwFdbA4WFXoUkKUZJKRERERERERGJc9rQ3kD9SCkLhP0ByMvzKiRJMUpKiYiIiIiIiEicI6+/AdQnpQBqQyFWbd3nTUCScpSUEhEREREREZE4/+p7Ihbjmr7nD4epmveal2FJClFSSkRERERERETinPiFi9nVozfV/jTAqS1V6w+QNe0ibwOTlBHwOgARERERERERST7XfvQK9tDeWHtH/yHseeRxcmdc4mFUkko0UkpERERERERE4uz83cNAfU2ptOojHJx4tncBScpRUkpERERERERE4mxM7+Nq7wt0I//RYkrLqjyKSFKNklIiIiIiIiIiEid86aWudnmfQdTWhSleX+lRRJJqlJQSERERERERkTg55Wti2wYYt6uMs7atZkpOf++CkpSipJSIiIiIiIiIxNm2/4irPehgFXOeupuJW1Z5FJGkGiWlRERERERERCTOoVNPd7UNYGproLDQk3gk9SgpJSIiIiIiIiJxwrt2YWNr70EYOGL8rBo3wbugJKUoKSUiIiIiIiIicbKmXUStPxBrb+k1kJ9e8DUWZI3xMCpJJUpKiYiIiIiIiEic3BmX8Icrvx1rD92/kx8v+BMXVK3zMCpJJUpKiYiIiIiIiEhCo0fUr7TnA9JDdeSu/tC7gCSlKCklIiIiIiIiIgllV9SPirKRf6opJe1FSSkRERERERERSajfjgp3h7Us27LPm2Ak5SgpJSIiIiIiIiIJ9VzxcWzbAH4swfKl3gUkKUVJKRERERERERFJ6P2JebFtC4R8foZdMc2zeCS1KCklIiIiIiIiIgl9NCEvth0G5nz5DggGPYtHUouSUiIiIiIiIiKS0OkL/hXb9gH9Vy/3LhhJOUpKiYiIiIiIiEhCh2pCzbZF2kJJKRERERERERFJaMn5l8e2LcbVFmkrJaVEREREREREJKHbS56ObRusqy3SVkpKiYiIiIiIiEhCfd8vwjZqi7QXJaVEREREREREJLFPfxoT2TSRtkh7UVJKRERERERERBKbPx8uvhi6d3d+zp/vdUSSQgJeByAiIiIiIiIiSUyJKDlONFJKREREREREREQ6nJJSIiIiIiIiIiLS4ZSUEhERERERERGRDqeklIiIiIiIiIiIdDglpUREREREREREpMMpKSUiIiIiIiIiIh1OSSkREREREREREelwSkqJiIiIiIiIiEiH6xRJKWNMP2PMRcaYAV7HIiIiIiIiIiIibZf0SSljTBbwEnA28KYxJtsYM88Y86oxZq4xJj2y32PGmCJjzN0Njo3rExERERERERER7yV9Ugo4HfiOtfZeYD4wHfi1tfZiYBtwqTFmBuC31gaBHGPMiYn6vHoAIiIiIiIiIiLiFvA6gJZYaxcCGGOm4oyW+l9r7b7IzQOBHcC1wDORvleB84AzE/StbXhuY0wBUAAwcuTI4/cgRERERERERETEpTOMlMIYY4CrgSqgNtIXBLKstcVAJlAR2X03MKiJPhdr7SPW2knW2kkDBw48vg9CRERERERERERiOkVSyjpuAz4GLjfG9AN+D/xXZJcDQPfIdk+cx5WoT0REREREREREkkDSJ2qMMd8zxtwQafYF9gD/AO601pZF+ktxpucBnAFsbKJPRERERERERESSQNLXlAIeAZ4xxtwELANygAnAXcaYu4CHgeeBt4wxQ4FpwBTAJugTEREREREREZEkkPRJKWttFXBRo+6HG+9njMmL7PeAtXZvU30iIiIiIiIiIuK9pE9KtVYkefVMS30iIiIiIiIiIuK9pK8pJSIiIiIiIiIiqUdJKRERERERERER6XBKSomIiIiIiIiISIcz1lqvY0gKxpidQJnXcbSTAcAur4MQ6SC63qUr0fUuXYmud+lKdL1LV6FrvWvKttYOTHSDklIpyBjzgbV2ktdxiHQEXe/Sleh6l65E17t0JbrepavQtS6NafqeiIiIiIiIiIh0OCWlRERERERERESkwykplZoe8ToAkQ6k6126El3v0pXoepeuRNe7dBW61sVFNaVERERERERERKTDaaSUiIiIiIiIiIh0OCWlRERERERERESkwykplWKMMY8ZY4qMMXd7HYtIWxhj+hhj5hljXjXGzDXGpCe6vlvbJ9IZGGMGGWMWR7Z1vUtKM8Y8ZIy5LLKt611SkjEmyxjzsjHmA2PMrEifrndJOZH3MG81aB/zda5rv2tRUiqFGGNmAH5rbRDIMcac6HVMIm2QD/zaWnsxsA24hkbXd6JrXq8D6eR+CXRv7bWt6106K2PMp4HB1toXdb1LirseeNJaOwnoZYy5A13vkmKMMVnAE0BmpH3Mf9d17Xc9Skqlljzgmcj2q8B53oUi0jbW2oesta9FmgOB64i/vvNa2SeS9IwxnwUO4iRh89D1LinKGJMG/AnYaIz5ArreJbVVAqcZY/oCI4DR6HqX1BMCrgb2Rdp5HPt1nqhPUpiSUqklE6iIbO8GBnkYi0i7MMYEgSxgE/HXd6JrXq8D6XSMMenAD4HvR7pae23repfO6AZgBfAAcDZwG7reJXW9DWQD/w9YCaSj611SjLV2n7V2b4OutryP0bXfxSgplVoOAN0j2z3R71c6OWNMP+D3wH+R+PpubZ9Isvs+8JC1dk+kretdUtmZwCPW2m3AbGARut4ldf0YuMVa+7/AKuBadL1L6mvL+xhd+12MfsGppZT64Y1nABu9C0WkbSIjR/4B3GmtLSPx9d3aPpFkdyFwmzGmEPgUcBm63iV1fQLkRLYnAaPQ9S6pKwsYb4zxA5OB+9H1LqmvLe/bde13MQGvA5B29TzwljFmKDANmOJxPCJtcSMwAbjLGHMX8DhwfaPr2xJ/zSfqE0lq1tqp0e1IYupyWndt63qXzugx4M/GmGuANJz6IS/oepcUdR/Oe5hsoAj4Dfr7Lqkv0efS1l7nuva7GGOt9ToGaUeRlQ8uAhZFhsWLpIxE13dr+0Q6G13v0pXoepeuRNe7dAVtuc517XctSkqJiIiIiIiIiEiHU00pERERERERERHpcEpKiYiIiIiIiIhIh1NSSkRERFKWMeZSY8wXjTGnN7PPUGPMncaYuPdFxpjpxpj/NcaMaMeYxhhj/hD512RcqcIYk2mM+akxZqzXsYiIiEhyUU0pERERSVnGmOXAKcBMa+33E9zeD9gMdAeuttY+0+j2d4BzgG3AGGvtoXaIaTJQHGleYq19ta3nTGbGmFuBhyLN31prv+1lPCIiIpI8NFJKREREUtn+yM/DiW601u4GXoo0XUkrY8wpOAkpgDvbIyEVcaTBdsK4kokxxt+GY3sAdzXomt/2iERERCRVKCklIiIiqawu8rO55M8vIj/PNMac3aD/1sjPZcAT7RhTw6RUXZN7JY9vGWPmGWPMMRx7FzCsQfuXxpju7RSXiIiIdHJKSomIiEgqiyZ9aprawVr7PvAm8C+gFsAY0xv4SmSXe2371juobnj37XjedheZ3ng3sOJon4PINMXvRZqvAHuAU4E/tWuQIiIi0mkFvA5AREREpKMZYzKB6UAlTrLku9QnpE4Dvgj0BKqANcaYs4AMIB0IWWsXehG3B34MhIGfHc1BxpgsYA7gB8qB/wSm4iT+8o0x6621P2rnWEVERKSTUVJKREREuqIsYHYr9ytt1FcBDG/YYYzpC2QDh3BGZYWaOefgBtsDjTHDm9jP4LxXSwe6ATustVtbEXO7MMaciDOF8XZrbdVRHOcHngJycJ6HfGvtHuAFY8yvcBKAPzTGVFtr7z0OoYuIiEgnodX3REREJCUYY/KBP+NMj4v+G4AzwmkPzkioHsCTwI9wCpzvi/Q3rO30WZzV+JbgJKCi/JFzHbbWfr7Rff8H8GK7Pyi3O6219x/n+4gxxswFTgNOsdbWtvIYH079rev+f3t3H6tlWQdw/PuDA9gQsxm4ArTNlZvaUhs6Mik2W5kvLVlZOIwazDlTmzkth7GVWRsSzZw1UbOXWdl6mRuVTWvVzFLLqM22MsO3RKUXJkdA4Pz647oeuTmcl+ccnvMgj9/P9uy57+u+7uu+bvjn7Pf8rutXm67OzGsa1/uAeyhZUwCrgSsyc6BjE5ckSQcMM6UkSVKvCEpW0VRgxqBrhzaOJ2fmM8C8IQeJ2EDJelqdme1kU0HZG2oHewbEBv/y1wccPsz9G9k7u2oSJRA2lRIk69oviRGxgLK88ZwxBKSmALewOyB1YzMgBZCZOyPiDOCnwNspWVPHRcT5mflsx15AkiQdEMyUkiRJPaFWdZtOWUK3gxIcubVevoyywfbBwM7M3DTCOBsoQaklYwhKtTO/ZXUOA+wuNrONsjRvUWb+sFPP2he1yt79lIywBaP1r/fMBr4PzK9N3wbOz8yMiA8DF9X2pZn5SN3Tax3wjtr+HHBxZn6vU+8hSZJe/qy+J0mSekJmbs3MTZn5Qs3uefeel3NLZm4cKSA1wS6s33c22u6q30u7O5URnQe8lZLFNKqIWAI8xO6A1O3ARxvV+qYDp9TPZIDM7Afey+5/i5nAdyPi3ohY2ImXkCRJL38GpSRJUs+pm22ftr/n0RIR7wJOpGRJ3dC4dAdlWd7pEXHE/phbU0QcBFwL3J6ZD4zSd15E/Br4JiWoNABclZnnZWZzj67NjeNtrYMaPHwfcClluSPA24BfRMRDEXFRRMza97eSJEkvVwalJElSL3oPcFizoe551DyfHREnRsSciDh4uIEiYnJEzIiIWRExd/A4bVpZv38A/KPR/ijwc8p+UyvGMW6nXUYJMF01XIeIODUi7qYs8Tu1Nm8Gzs7MLwxxS3/jeK+qhJl5PXAy8HCj+XhK8O6SMc1ekiQdUAxKSZKkXrR80Pkc4IGI+FCj7SzgD8ATwPMRkRGRlP2kAL5Vz3dSqvQ9AzwOHDuWiUTEByhL1xL43BBd1tTvpRFx9FjG7qSalfQpYE1mPj5C1+3ACY3zHwNvzsx1w/Tf1jjeKygFkJnrgbcAF1D+P6D836wcqr8kSeoNBqUkSVJPiYi5wBmDmj9ICXrcHBHH1LZdlGDT08CTwGP10wqcbGq0PUUJSvUzhip4NQNrdT39Tmb+ZXCfzLwL+A0wBbitLj3cHz4LbAW+OFKnzLwfOIeS8XVmZr4/M58Y4ZaB5u0jjLszM28C3gh8Arg0M4cMYkmSpN5g9T1JktRTImItsAx4FtgAnARcDSyiLAv7E3ByZr44zP0b6FD1vYj4OmUT863A0Zn5RES8Afhn7TI/M38XEScB91F+MLwmM6/el+eOY57HAH8GPp6ZX2vznkmZOdBGv3cCv6ynr8vMjeOeqCRJ6ilmSkmSpJ4REUexu5LdlyjBIChL8JZTsnaOpwv7N0XE4sZcPjNSNlHNPmot41sRERdM8PQGuw74G7C23RvaCUhJkiSNxKCUJEnqJV+hbBq+kT2r3JGZDwJfpQRe1ux9a+dExHzglnr6W0qAbDQrgD/W4xsj4uKJmNtgtTLg6cDlLpeTJEndZFBKkiT1hIhYSgmuAKzMzP4hul1C2Ux7ckRMnaB5zAPWAQcBzwHntpNVlJnbgLMpe1xNAq6PiC+Ps9pfu3OdRMmSujszfzJRz5EkSRqKQSlJktQrltTvB4Gbh+pQg0PTKcGi7RGxPSI2RcRjEbGh7ic1p3Zf02qrn6ci4r8RsTUibhhq/Jp1dA/wGkrVuaXAjoh49UhBsIiYGhGHADuAcyn7YQFcCvxqAqvyfQw4Drh8gsaXJEkalkEpSZLUK5YDm4FlY9jvaCpwGHAEZXPzI4FW9bvXNtqOBF4PHErJgOprDhIRkyLi08DPgBmUCn6LgTdRQq98owAAAj1JREFUlhL+jxIES3Zvcg5wX23bXuf+DPARYCHQ2oNqPrA+IlZFxOFtvteoImI6peLebZm5vlPjSpIktcuglCRJ6gmZ+Sgwr40ASz8wF5gFHAJMy8xofYDHar8lg9onAVPqPVe2BouIY4F7gWtrn53A4sz80RDP3lU/w5233uVhStXA39emacBZdPZvtysp79LVSn+SJEktBqUkSVLPyMy/t9EnM/PJzHwuM5/PzBfbHDszc2e9Z3Pj0gAlewpKtb9FmXlHPV8LzKRkT/VlZh/QXIq3oLb11T4zgU/W520EFgCrKFlUZ2bm0+3MdTQRMbs+Z1Vm/qsTY0qSJI2VQSlJktTLWkvxJuxvnsz8K3Aapcrewsy8s3GtPzM3ZeaWRmW75sblfbXfrtpnUzPglZkvZuYVwFGZ+UgHp/15ypLC6zo45nAmN477hu0lSZJecfzDQJIk9bJpg77HItrtmJn/Bk5ps3tzw/O2KuvV8TsiIk6gbAq/bJgKhZ3WDEpNWCVBSZJ04DFTSpIk9bKpg77HYvLoXcZlyjDH3bIFuAn4Rpee1/wR1KCUJEl6iZlSkiSpl+1LptR47mnHXsv3uqnuu3VhFx/5qsaxQSlJkvQSM6UkSVIv+w/wFPDCOO6d3uG5tOzvTKluawalxpOxJkmSelRk5v6egyRJkiRJkl5hzJSSJEmSJElS1xmUkiRJkiRJUtcZlJIkSZIkSVLXGZSSJEmSJElS1xmUkiRJkiRJUtcZlJIkSZIkSVLX/R9z6FzYFNqyWgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 1440x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(20,10))\n",
    "plt.rcParams['font.sans-serif']=['SimHei']\n",
    "plt.rcParams['axes.unicode_minus']=False\n",
    "plt.xlabel('样本 /个',fontdict={ 'size'   : 30})\n",
    "plt.ylabel('推力值 /N',fontdict={ 'size'   : 30})\n",
    "plt.plot(trainY_1[200:11000],marker='.',label='true')\n",
    "plt.plot(predict_1[200:11000],'r',marker='.',label='predicted')                  #sample的时刻是一致的\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
