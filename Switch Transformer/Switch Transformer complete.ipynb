{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "import math\n",
    "import warnings\n",
    "from typing import Optional, Tuple, Union\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.nn import CrossEntropyLoss\n",
    "from torch.utils.checkpoint import checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SwitchTransformersTop1Router(nn.Module):\n",
    "    \"\"\"\n",
    "    Router using tokens choose top-1 experts assignment.\n",
    "    This router uses the same mechanism as in Switch Transformer (https://arxiv.org/abs/2101.03961) and V-MoE\n",
    "    (https://arxiv.org/abs/2106.05974): tokens choose their top experts. Items are sorted by router_probs and then\n",
    "    routed to their choice of expert until the expert's expert_capacity is reached. **There is no guarantee that each\n",
    "    token is processed by an expert**, or that each expert receives at least one token.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, hidden_size, num_experts, experts_capacity, router_bias, router_jitter_noise, router_ignore_padding_tokens, router_dtype):\n",
    "        super().__init__()\n",
    "        self.num_experts = num_experts\n",
    "        self.expert_capacity = experts_capacity\n",
    "        self.classifier = nn.Linear(hidden_size, num_experts, bias=router_bias)\n",
    "        self.jitter_noise = router_jitter_noise\n",
    "        self.ignore_padding_tokens = router_ignore_padding_tokens\n",
    "        self.dtype = getattr(torch, router_dtype)\n",
    "\n",
    "    def _compute_router_probabilities(self, hidden_states: torch.Tensor) -> Tuple[torch.Tensor, torch.Tensor]:\n",
    "        r\"\"\"\n",
    "        Computes router probabilities from input hidden states.\n",
    "        Args:\n",
    "            hidden_states (`torch.Tensor`):\n",
    "                (batch_size, sequence_length, hidden_dim) from which router probabilities are computed.\n",
    "        Returns:\n",
    "            router_probabilities (`torch.Tensor`):\n",
    "                Tensor of shape (batch_size, sequence_length, num_experts) corresponding to the probabilities for each\n",
    "                token and expert. Used for routing tokens to experts.\n",
    "            router_logits (`torch.Tensor`):\n",
    "                Logits tensor of shape (batch_size, sequence_length, num_experts) corresponding to raw router logits.\n",
    "                This is used later for computing router z-loss.\n",
    "        \"\"\"\n",
    "        # float32 is used to ensure stability. See the discussion of \"selective precision\" in\n",
    "        # https://arxiv.org/abs/2101.03961.\n",
    "        # We also store the previous dtype to cast back the output to the previous dtype\n",
    "        self.input_dtype = hidden_states.dtype\n",
    "        hidden_states = hidden_states.to(self.dtype)\n",
    "\n",
    "        if self.jitter_noise > 0:\n",
    "            # Get the lower and upper bound of the uniform distribution\n",
    "            # Adapted from: https://stackoverflow.com/questions/44328530/how-to-get-a-uniform-distribution-in-a-range-r1-r2-in-pytorch\n",
    "            distrib_lower_bound = 1.0 - self.jitter_noise\n",
    "            distrib_upper_bound = 1.0 + self.jitter_noise\n",
    "\n",
    "            uniform_distrib = torch.rand(hidden_states.shape, device=hidden_states.device, dtype=self.dtype)\n",
    "            uniform_distrib = uniform_distrib * (distrib_lower_bound - distrib_upper_bound)\n",
    "\n",
    "            uniform_distrib = uniform_distrib + distrib_upper_bound\n",
    "            # Multiply the token inputs by the uniform distribution - adding some noise\n",
    "            hidden_states *= uniform_distrib\n",
    "\n",
    "        # Shape: [num_groups, tokens_per_group, num_experts]\n",
    "        self._cast_classifier()\n",
    "        router_logits = self.classifier(hidden_states)\n",
    "\n",
    "        # Apply Softmax and cast back to the original `dtype`\n",
    "        router_probabilities = nn.functional.softmax(router_logits, dim=-1, dtype=self.dtype).to(self.input_dtype)\n",
    "        return router_probabilities, router_logits\n",
    "\n",
    "    def _cast_classifier(self):\n",
    "        r\"\"\"\n",
    "        `bitsandbytes` `Linear8bitLt` layers does not support manual casting Therefore we need to check if they are an\n",
    "        instance of the `Linear8bitLt` class by checking special attributes.\n",
    "        \"\"\"\n",
    "        if not (hasattr(self.classifier, \"SCB\") or hasattr(self.classifier, \"CB\")):\n",
    "            self.classifier = self.classifier.to(self.dtype)\n",
    "\n",
    "    def forward(self, hidden_states: torch.Tensor) -> Tuple:\n",
    "        r\"\"\"\n",
    "        Generic forward function for every Router class. Each Router expects to have the same input hidden states\n",
    "        (`hidden_states`) corresponding to the hidden states for each token, the `expert_capacity` corresponding to the\n",
    "        number of tokens the Router will send to each expert, some Routers can send up to few tokens to each expert.\n",
    "        Each Router works as the following: it expects the hidden states for each token, gets the `router_probs` and\n",
    "        `router_logits` from the `router_weights`. This will assign for each token, the raw probability to be assigned\n",
    "        to an expert. Then each Router class will have to define its own `_compute_routing_instructions`.\n",
    "        Args:\n",
    "            hidden_states (`torch.Tensor`) :\n",
    "                [num_groups, tokens_per_group, hidden_dim] inputs to send to experts.\n",
    "        Returns:\n",
    "            Tuple[`torch.Tensor`, `torch.Tensor`, `torch.Tensor`] Tuple containing the expert index, the router probs\n",
    "            and the router logits. The router probabilities and logits are required to compute the loss.\n",
    "        \"\"\"\n",
    "        router_probs, router_logits = self._compute_router_probabilities(hidden_states)\n",
    "\n",
    "        expert_index = torch.argmax(router_probs, dim=-1)\n",
    "        expert_index = torch.nn.functional.one_hot(expert_index, num_classes=self.num_experts)\n",
    "\n",
    "        # Mask tokens outside expert capacity. Sum over each sequence\n",
    "        token_priority = torch.cumsum(expert_index, dim=-2)\n",
    "        # mask if the token routed to to the expert will overflow\n",
    "        expert_capacity_mask = token_priority <= self.expert_capacity\n",
    "        expert_index = expert_index * expert_capacity_mask\n",
    "\n",
    "        router_probs = torch.max(router_probs, dim=-1).values.unsqueeze(-1)\n",
    "        return expert_index, router_probs, router_logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SwitchTransformersLayerNorm(nn.Module):\n",
    "    def __init__(self, hidden_size, eps=1e-6):\n",
    "        \"\"\"\n",
    "        Construct a layernorm module in the SwitchTransformers style. No bias and no subtraction of mean.\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.weight = nn.Parameter(torch.ones(hidden_size))\n",
    "        self.variance_epsilon = eps\n",
    "\n",
    "    def forward(self, hidden_states):\n",
    "        # SwitchTransformers uses a layer_norm which only scales and doesn't shift, which is also known as Root Mean\n",
    "        # Square Layer Normalization https://arxiv.org/abs/1910.07467 thus varience is calculated\n",
    "        # w/o mean and there is no bias. Additionally we want to make sure that the accumulation for\n",
    "        # half-precision inputs is done in fp32\n",
    "\n",
    "        variance = hidden_states.to(torch.float32).pow(2).mean(-1, keepdim=True)\n",
    "        hidden_states = hidden_states * torch.rsqrt(variance + self.variance_epsilon)\n",
    "\n",
    "        # convert into half-precision if necessary\n",
    "        if self.weight.dtype in [torch.float16, torch.bfloat16]:\n",
    "            hidden_states = hidden_states.to(self.weight.dtype)\n",
    "\n",
    "        return self.weight * hidden_states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SwitchTransformersDenseActDense(nn.Module):\n",
    "    def __init__(self, d_model, d_ff, dropout_rate, dense_act_fn):\n",
    "        super().__init__()\n",
    "        self.wi = nn.Linear(d_model, d_ff, bias=False)\n",
    "        self.wo = nn.Linear(d_ff, d_model, bias=False)\n",
    "        self.dropout = nn.Dropout(dropout_rate)\n",
    "        if dense_act_fn == \"gelu\":\n",
    "            self.act = nn.GELU()\n",
    "\n",
    "    def forward(self, hidden_states):\n",
    "        hidden_states = self.wi(hidden_states)\n",
    "        hidden_states = self.act(hidden_states)\n",
    "        hidden_states = self.dropout(hidden_states)\n",
    "        if (\n",
    "            isinstance(self.wo.weight, torch.Tensor)\n",
    "            and hidden_states.dtype != self.wo.weight.dtype\n",
    "            and self.wo.weight.dtype != torch.int8\n",
    "        ):\n",
    "            hidden_states = hidden_states.to(self.wo.weight.dtype)\n",
    "        hidden_states = self.wo(hidden_states)\n",
    "        return hidden_states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SwitchTransformersDenseGatedActDense(nn.Module):\n",
    "    def __init__(self, d_model, d_ff, dropout_rate, dense_act_fn):\n",
    "        super().__init__()\n",
    "        self.wi_0 = nn.Linear(d_model, d_ff, bias=False)\n",
    "        self.wi_1 = nn.Linear(d_model, d_ff, bias=False)\n",
    "        self.wo = nn.Linear(d_ff, d_model, bias=False)\n",
    "        self.dropout = nn.Dropout(dropout_rate)\n",
    "        if dense_act_fn == \"gelu\":\n",
    "            self.act = nn.GELU()\n",
    "\n",
    "    def forward(self, hidden_states):\n",
    "        hidden_gelu = self.act(self.wi_0(hidden_states))\n",
    "        hidden_linear = self.wi_1(hidden_states)\n",
    "        hidden_states = hidden_gelu * hidden_linear\n",
    "        hidden_states = self.dropout(hidden_states)\n",
    "        hidden_states = self.wo(hidden_states)\n",
    "        return hidden_states\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SwitchTransformersSparseMLP(nn.Module):\n",
    "    r\"\"\"\n",
    "    Implementation of the Switch Transformers Sparse MLP module.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, hidden_size, num_experts, experts_capacity, router_bias, router_jitter_noise, router_ignore_padding_tokens, \n",
    "                 router_dtype, d_model, d_ff, dropout_rate, dense_act_fn, expert_class: nn.Module = SwitchTransformersDenseActDense):        \n",
    "        super().__init__()\n",
    "        # Step 1: Get the correct router according to its class\n",
    "        self.router = SwitchTransformersTop1Router(hidden_size, num_experts, experts_capacity, router_bias, router_jitter_noise, \n",
    "                                                   router_ignore_padding_tokens, router_dtype)\n",
    "\n",
    "        # Step 2: Get the experts\n",
    "        self.experts = nn.ModuleDict()\n",
    "        for idx in range(num_experts):\n",
    "            self.experts[f\"expert_{idx}\"] = expert_class(d_model, d_ff, dropout_rate, dense_act_fn)\n",
    "\n",
    "    def forward(self, hidden_states):\n",
    "        r\"\"\"\n",
    "        Hold on, this will be slightly tricky to understand In the correct order, a MoE layer does the following:\n",
    "        1- Gets the `router_mask` from the router. The shape of the mask is `(batch_size, sequence_length, num_expert)`\n",
    "        and corresponds to the argmax of the `router_probs`. The probabilities are needed in the computation of the\n",
    "        hidden states : they are broadcasted to the hidden states values (can be interpreted as a scaling factor).\n",
    "        2- Dispatch the tokens to its associated experts. We do a classic for loop over the experts and assign for each\n",
    "        expert the corresponding hidden states.\n",
    "        \"\"\"\n",
    "        # Step 1: Get the router_mask from the router as wel as the probabilities\n",
    "        router_mask, router_probs, router_logits = self.router(hidden_states)\n",
    "        expert_index = torch.argmax(router_mask, dim=-1)\n",
    "\n",
    "        # The routers introduced might not always map all the tokens, to a router, which means that some hidden states\n",
    "        # can be unchanged from one layer to another. That is why the hidden states are cloned before updating only the seleced ones.\n",
    "\n",
    "        next_states = hidden_states.clone()\n",
    "        for idx, expert in enumerate(self.experts.values()):\n",
    "            token_indices = router_mask[:, :, idx].bool()\n",
    "            next_states[token_indices] = expert(hidden_states[token_indices])\n",
    "\n",
    "        hidden_states = router_probs * next_states\n",
    "        return hidden_states, (router_logits, expert_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SwitchTransformersLayerFF(nn.Module):\n",
    "    r\"\"\"\n",
    "    Switch Transformers Feed Forward layer module. This is a wrapper around the Mixture of Experts module.\n",
    "    Parameters:\n",
    "        config : ([`SwitchTransformersConfig`]): Model configuration class with all the parameters of the model.\n",
    "            Initializing with a config file does not load the weights associated with the model, only the\n",
    "            configuration. Check out the [`~PreTrainedModel.from_pretrained`] method to load the model weights.\n",
    "        is_sparse (`bool`):\n",
    "            Whether the MLP layer is a `Sparse` layer (contains a Mixture of Experts) or not\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, hidden_size, num_experts, experts_capacity, router_bias, router_jitter_noise, router_ignore_padding_tokens, \n",
    "                 router_dtype, d_model, d_ff, dropout_rate, dense_act_fn, layer_norm_epsilon, is_sparse=False):\n",
    "        super().__init__()\n",
    "        self.is_sparse = is_sparse\n",
    "\n",
    "        # Check if it is a sparse layer, if not then it is a dense layer\n",
    "        if not self.is_sparse:\n",
    "            self.mlp = SwitchTransformersDenseActDense(d_model, d_ff, dropout_rate, dense_act_fn)\n",
    "        else:\n",
    "            self.mlp = SwitchTransformersSparseMLP(hidden_size, num_experts, experts_capacity, router_bias, router_jitter_noise, \n",
    "                 router_ignore_padding_tokens, router_dtype, d_model, d_ff, dropout_rate, dense_act_fn)\n",
    "\n",
    "        self.layer_norm = SwitchTransformersLayerNorm(d_model, eps=layer_norm_epsilon)\n",
    "        self.dropout = nn.Dropout(dropout_rate)\n",
    "\n",
    "    def forward(self, hidden_states, output_router_logits):\n",
    "        forwarded_states = self.layer_norm(hidden_states)\n",
    "        forwarded_states = self.mlp(forwarded_states)\n",
    "\n",
    "        if isinstance(forwarded_states, tuple):\n",
    "            forwarded_states, router_tuple = forwarded_states\n",
    "        else:\n",
    "            router_tuple = None\n",
    "\n",
    "        output = hidden_states + self.dropout(forwarded_states)\n",
    "\n",
    "        if output_router_logits and router_tuple is not None:\n",
    "            output = (output, router_tuple)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SwitchTransformersAttention(nn.Module):\n",
    "    def __init__(self, d_model, num_heads, dropout_rate, d_kv, relative_attention_num_buckets, relative_attention_max_distance, \n",
    "                 is_decoder=False, has_relative_attention_bias=False):\n",
    "        super().__init__()\n",
    "        self.is_decoder = is_decoder\n",
    "        self.has_relative_attention_bias = has_relative_attention_bias\n",
    "        self.relative_attention_num_buckets = relative_attention_num_buckets\n",
    "        self.relative_attention_max_distance = relative_attention_max_distance\n",
    "        self.d_model = d_model\n",
    "        self.key_value_proj_dim = d_kv\n",
    "        self.n_heads = num_heads\n",
    "        self.dropout = dropout_rate\n",
    "        self.inner_dim = self.n_heads * self.key_value_proj_dim\n",
    "\n",
    "        # Mesh TensorFlow initialization to avoid scaling before softmax\n",
    "        self.q = nn.Linear(self.d_model, self.inner_dim, bias=False)\n",
    "        self.k = nn.Linear(self.d_model, self.inner_dim, bias=False)\n",
    "        self.v = nn.Linear(self.d_model, self.inner_dim, bias=False)\n",
    "        self.o = nn.Linear(self.inner_dim, self.d_model, bias=False)\n",
    "\n",
    "        if self.has_relative_attention_bias:\n",
    "            self.relative_attention_bias = nn.Embedding(self.relative_attention_num_buckets, self.n_heads)\n",
    "        self.pruned_heads = set()\n",
    "        self.gradient_checkpointing = False\n",
    "\n",
    "    def prune_heads(self, heads):\n",
    "        if len(heads) == 0:\n",
    "            return\n",
    "        heads, index = find_pruneable_heads_and_indices(\n",
    "            heads, self.n_heads, self.key_value_proj_dim, self.pruned_heads\n",
    "        )\n",
    "        # Prune linear layers\n",
    "        self.q = prune_linear_layer(self.q, index)\n",
    "        self.k = prune_linear_layer(self.k, index)\n",
    "        self.v = prune_linear_layer(self.v, index)\n",
    "        self.o = prune_linear_layer(self.o, index, dim=1)\n",
    "        # Update hyper params\n",
    "        self.n_heads = self.n_heads - len(heads)\n",
    "        self.inner_dim = self.key_value_proj_dim * self.n_heads\n",
    "        self.pruned_heads = self.pruned_heads.union(heads)\n",
    "\n",
    "    @staticmethod\n",
    "    def _relative_position_bucket(relative_position, bidirectional=True, num_buckets=32, max_distance=128):\n",
    "        \"\"\"\n",
    "        Adapted from Mesh Tensorflow:\n",
    "        https://github.com/tensorflow/mesh/blob/0cb87fe07da627bf0b7e60475d59f95ed6b5be3d/mesh_tensorflow/transformer/transformer_layers.py#L593\n",
    "        Translate relative position to a bucket number for relative attention. The relative position is defined as\n",
    "        memory_position - query_position, i.e. the distance in tokens from the attending position to the attended-to\n",
    "        position. If bidirectional=False, then positive relative positions are invalid. We use smaller buckets for\n",
    "        small absolute relative_position and larger buckets for larger absolute relative_positions. All relative\n",
    "        positions >=max_distance map to the same bucket. All relative positions <=-max_distance map to the same bucket.\n",
    "        This should allow for more graceful generalization to longer sequences than the model has been trained on\n",
    "        Args:\n",
    "            relative_position: an int32 Tensor\n",
    "            bidirectional: a boolean - whether the attention is bidirectional\n",
    "            num_buckets: an integer\n",
    "            max_distance: an integer\n",
    "        Returns:\n",
    "            a Tensor with the same shape as relative_position, containing int32 values in the range [0, num_buckets)\n",
    "        \"\"\"\n",
    "        relative_buckets = 0\n",
    "        if bidirectional:\n",
    "            num_buckets //= 2\n",
    "            relative_buckets += (relative_position > 0).to(torch.long) * num_buckets\n",
    "            relative_position = torch.abs(relative_position)\n",
    "        else:\n",
    "            relative_position = -torch.min(relative_position, torch.zeros_like(relative_position))\n",
    "        # now relative_position is in the range [0, inf)\n",
    "\n",
    "        # half of the buckets are for exact increments in positions\n",
    "        max_exact = num_buckets // 2\n",
    "        is_small = relative_position < max_exact\n",
    "\n",
    "        # The other half of the buckets are for logarithmically bigger bins in positions up to max_distance\n",
    "        relative_position_if_large = max_exact + (\n",
    "            torch.log(relative_position.float() / max_exact)\n",
    "            / math.log(max_distance / max_exact)\n",
    "            * (num_buckets - max_exact)\n",
    "        ).to(torch.long)\n",
    "        relative_position_if_large = torch.min(\n",
    "            relative_position_if_large, torch.full_like(relative_position_if_large, num_buckets - 1)\n",
    "        )\n",
    "\n",
    "        relative_buckets += torch.where(is_small, relative_position, relative_position_if_large)\n",
    "        return relative_buckets\n",
    "\n",
    "    def compute_bias(self, query_length, key_length, device=None):\n",
    "        \"\"\"Compute binned relative position bias\"\"\"\n",
    "        if device is None:\n",
    "            device = self.relative_attention_bias.weight.device\n",
    "        context_position = torch.arange(query_length, dtype=torch.long, device=device)[:, None]\n",
    "        memory_position = torch.arange(key_length, dtype=torch.long, device=device)[None, :]\n",
    "        relative_position = memory_position - context_position  # shape (query_length, key_length)\n",
    "        relative_position_bucket = self._relative_position_bucket(\n",
    "            relative_position,  # shape (query_length, key_length)\n",
    "            bidirectional=(not self.is_decoder),\n",
    "            num_buckets=self.relative_attention_num_buckets,\n",
    "            max_distance=self.relative_attention_max_distance,\n",
    "        )\n",
    "        values = self.relative_attention_bias(relative_position_bucket)  # shape (query_length, key_length, num_heads)\n",
    "        values = values.permute([2, 0, 1]).unsqueeze(0)  # shape (1, num_heads, query_length, key_length)\n",
    "        return values\n",
    "\n",
    "    def forward(\n",
    "        self,\n",
    "        hidden_states,\n",
    "        mask=None,\n",
    "        key_value_states=None,\n",
    "        position_bias=None,\n",
    "        past_key_value=None,\n",
    "        layer_head_mask=None,\n",
    "        query_length=None,\n",
    "        use_cache=False,\n",
    "        output_attentions=False,\n",
    "    ):\n",
    "        \"\"\"\n",
    "        Self-attention (if key_value_states is None) or attention over source sentence (provided by key_value_states).\n",
    "        \"\"\"\n",
    "        # Input is (batch_size, seq_length, dim)\n",
    "        # Mask is (batch_size, key_length) (non-causal) or (batch_size, key_length, key_length)\n",
    "        # past_key_value[0] is (batch_size, n_heads, q_len - 1, dim_per_head)\n",
    "        batch_size, seq_length = hidden_states.shape[:2]\n",
    "\n",
    "        real_seq_length = seq_length\n",
    "\n",
    "        if past_key_value is not None:\n",
    "            assert (\n",
    "                len(past_key_value) == 2\n",
    "            ), f\"past_key_value should have 2 past states: keys and values. Got { len(past_key_value)} past states\"\n",
    "            real_seq_length += past_key_value[0].shape[2] if query_length is None else query_length\n",
    "\n",
    "        key_length = real_seq_length if key_value_states is None else key_value_states.shape[1]\n",
    "\n",
    "        def shape(states):\n",
    "            \"\"\"projection\"\"\"\n",
    "            return states.view(batch_size, -1, self.n_heads, self.key_value_proj_dim).transpose(1, 2)\n",
    "\n",
    "        def unshape(states):\n",
    "            \"\"\"reshape\"\"\"\n",
    "            return states.transpose(1, 2).contiguous().view(batch_size, -1, self.inner_dim)\n",
    "\n",
    "        def project(hidden_states, proj_layer, key_value_states, past_key_value):\n",
    "            \"\"\"projects hidden states correctly to key/query states\"\"\"\n",
    "            if key_value_states is None:\n",
    "                # self-attn\n",
    "                # (batch_size, n_heads, seq_length, dim_per_head)\n",
    "                hidden_states = shape(proj_layer(hidden_states))\n",
    "            elif past_key_value is None:\n",
    "                # cross-attn\n",
    "                # (batch_size, n_heads, seq_length, dim_per_head)\n",
    "                hidden_states = shape(proj_layer(key_value_states))\n",
    "            if past_key_value is not None:\n",
    "                if key_value_states is None:\n",
    "                    # self-attn\n",
    "                    # (batch_size, n_heads, key_length, dim_per_head)\n",
    "                    hidden_states = torch.cat([past_key_value, hidden_states], dim=2)\n",
    "                elif past_key_value.shape[2] != key_value_states.shape[1]:\n",
    "                    # checking that the `sequence_length` of the `past_key_value` is the same as\n",
    "                    # the provided `key_value_states` to support prefix tuning\n",
    "                    # cross-attn\n",
    "                    # (batch_size, n_heads, seq_length, dim_per_head)\n",
    "                    hidden_states = shape(proj_layer(key_value_states))\n",
    "                else:\n",
    "                    # cross-attn\n",
    "                    hidden_states = past_key_value\n",
    "            return hidden_states\n",
    "\n",
    "        # get query states\n",
    "        query_states = shape(self.q(hidden_states))  # (batch_size, n_heads, seq_length, dim_per_head)\n",
    "\n",
    "        # get key/value states\n",
    "        key_states = project(\n",
    "            hidden_states, self.k, key_value_states, past_key_value[0] if past_key_value is not None else None\n",
    "        )\n",
    "        value_states = project(\n",
    "            hidden_states, self.v, key_value_states, past_key_value[1] if past_key_value is not None else None\n",
    "        )\n",
    "\n",
    "        # compute scores\n",
    "        scores = torch.matmul(\n",
    "            query_states, key_states.transpose(3, 2)\n",
    "        )  # equivalent of torch.einsum(\"bnqd,bnkd->bnqk\", query_states, key_states), compatible with onnx op>9\n",
    "\n",
    "        if position_bias is None:\n",
    "            if not self.has_relative_attention_bias:\n",
    "                position_bias = torch.zeros(\n",
    "                    (1, self.n_heads, real_seq_length, key_length), device=scores.device, dtype=scores.dtype\n",
    "                )\n",
    "                if self.gradient_checkpointing and self.training:\n",
    "                    position_bias.requires_grad = True\n",
    "            else:\n",
    "                position_bias = self.compute_bias(real_seq_length, key_length, device=scores.device)\n",
    "\n",
    "            # if key and values are already calculated\n",
    "            # we want only the last query position bias\n",
    "            if past_key_value is not None:\n",
    "                position_bias = position_bias[:, :, -hidden_states.size(1) :, :]\n",
    "\n",
    "            if mask is not None:\n",
    "                position_bias = position_bias + mask  # (batch_size, n_heads, seq_length, key_length)\n",
    "\n",
    "        if self.pruned_heads:\n",
    "            mask = torch.ones(position_bias.shape[1])\n",
    "            mask[list(self.pruned_heads)] = 0\n",
    "            position_bias_masked = position_bias[:, mask.bool()]\n",
    "        else:\n",
    "            position_bias_masked = position_bias\n",
    "\n",
    "        scores += position_bias_masked\n",
    "        attn_weights = nn.functional.softmax(scores.float(), dim=-1).type_as(\n",
    "            scores\n",
    "        )  # (batch_size, n_heads, seq_length, key_length)\n",
    "        attn_weights = nn.functional.dropout(\n",
    "            attn_weights, p=self.dropout, training=self.training\n",
    "        )  # (batch_size, n_heads, seq_length, key_length)\n",
    "\n",
    "        # Mask heads if we want to\n",
    "        if layer_head_mask is not None:\n",
    "            attn_weights = attn_weights * layer_head_mask\n",
    "\n",
    "        attn_output = unshape(torch.matmul(attn_weights, value_states))  # (batch_size, seq_length, dim)\n",
    "        attn_output = self.o(attn_output)\n",
    "\n",
    "        present_key_value_state = (key_states, value_states) if (self.is_decoder and use_cache) else None\n",
    "        outputs = (attn_output,) + (present_key_value_state,) + (position_bias,)\n",
    "\n",
    "        if output_attentions:\n",
    "            outputs = outputs + (attn_weights,)\n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SwitchTransformersLayerSelfAttention(nn.Module):\n",
    "    def __init__(self, d_model, num_heads, dropout_rate, d_kv, relative_attention_num_buckets, relative_attention_max_distance, \n",
    "                 layer_norm_epsilon=1e-6, is_decoder=False, has_relative_attention_bias=False):\n",
    "        super().__init__()\n",
    "        self.SelfAttention = SwitchTransformersAttention(\n",
    "            d_model=d_model, num_heads=num_heads, dropout_rate=dropout_rate, d_kv=d_kv, \n",
    "            relative_attention_num_buckets=relative_attention_num_buckets, relative_attention_max_distance=relative_attention_max_distance, \n",
    "            is_decoder=is_decoder, has_relative_attention_bias=has_relative_attention_bias\n",
    "        )\n",
    "        self.layer_norm = SwitchTransformersLayerNorm(d_model, layer_norm_epsilon)\n",
    "        self.dropout = nn.Dropout(dropout_rate)\n",
    "\n",
    "    def forward(\n",
    "        self,\n",
    "        hidden_states,\n",
    "        attention_mask=None,\n",
    "        position_bias=None,\n",
    "        layer_head_mask=None,\n",
    "        past_key_value=None,\n",
    "        use_cache=False,\n",
    "        output_attentions=False,\n",
    "    ):\n",
    "        normed_hidden_states = self.layer_norm(hidden_states)\n",
    "        attention_output = self.SelfAttention(\n",
    "            normed_hidden_states,\n",
    "            mask=attention_mask,\n",
    "            position_bias=position_bias,\n",
    "            layer_head_mask=layer_head_mask,\n",
    "            past_key_value=past_key_value,\n",
    "            use_cache=use_cache,\n",
    "            output_attentions=output_attentions,\n",
    "        )\n",
    "        hidden_states = hidden_states + self.dropout(attention_output[0])\n",
    "        outputs = (hidden_states,) + attention_output[1:]  # add attentions if we output them\n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SwitchTransformersLayerCrossAttention(nn.Module):\n",
    "    def __init__(self, d_model, num_heads, dropout_rate, d_kv, relative_attention_num_buckets, relative_attention_max_distance, \n",
    "                 layer_norm_epsilon, is_decoder=False, has_relative_attention_bias=False):\n",
    "        super().__init__()\n",
    "        self.EncDecAttention = SwitchTransformersAttention(d_model, num_heads, dropout_rate, d_kv, relative_attention_num_buckets, \n",
    "                 relative_attention_max_distance, is_decoder, has_relative_attention_bias)\n",
    "        self.layer_norm = SwitchTransformersLayerNorm(d_model, eps=layer_norm_epsilon)\n",
    "        self.dropout = nn.Dropout(dropout_rate)\n",
    "\n",
    "    def forward(\n",
    "        self,\n",
    "        hidden_states,\n",
    "        key_value_states,\n",
    "        attention_mask=None,\n",
    "        position_bias=None,\n",
    "        layer_head_mask=None,\n",
    "        past_key_value=None,\n",
    "        use_cache=False,\n",
    "        query_length=None,\n",
    "        output_attentions=False,\n",
    "    ):\n",
    "        normed_hidden_states = self.layer_norm(hidden_states)\n",
    "        attention_output = self.EncDecAttention(\n",
    "            normed_hidden_states,\n",
    "            mask=attention_mask,\n",
    "            key_value_states=key_value_states,\n",
    "            position_bias=position_bias,\n",
    "            layer_head_mask=layer_head_mask,\n",
    "            past_key_value=past_key_value,\n",
    "            use_cache=use_cache,\n",
    "            query_length=query_length,\n",
    "            output_attentions=output_attentions,\n",
    "        )\n",
    "        layer_output = hidden_states + self.dropout(attention_output[0])\n",
    "        outputs = (layer_output,) + attention_output[1:]  # add attentions if we output them\n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SwitchTransformersBlock(nn.Module):\n",
    "    def __init__(self, d_model, num_heads, dropout_rate, d_kv, relative_attention_num_buckets, relative_attention_max_distance, \n",
    "                 hidden_size, num_experts, experts_capacity, router_bias, router_jitter_noise, router_ignore_padding_tokens, \n",
    "                 router_dtype, d_ff, dense_act_fn, layer_norm_epsilon, is_decoder=False, has_relative_attention_bias=False, is_sparse=False):\n",
    "        super().__init__()\n",
    "        self.is_decoder = is_decoder\n",
    "        self.is_sparse = is_sparse\n",
    "        self.layer = nn.ModuleList()\n",
    "        self.layer.append(\n",
    "            SwitchTransformersLayerSelfAttention(d_model, num_heads, dropout_rate, d_kv, relative_attention_num_buckets, \n",
    "                 relative_attention_max_distance, layer_norm_epsilon, is_decoder, has_relative_attention_bias)\n",
    "        )\n",
    "        if self.is_decoder:\n",
    "            self.layer.append(SwitchTransformersLayerCrossAttention(d_model, num_heads, dropout_rate, d_kv, relative_attention_num_buckets, \n",
    "                 relative_attention_max_distance, layer_norm_epsilon, is_decoder, has_relative_attention_bias))\n",
    "\n",
    "        self.layer.append(SwitchTransformersLayerFF(hidden_size, num_experts, experts_capacity, router_bias, router_jitter_noise, \n",
    "                 router_ignore_padding_tokens, router_dtype, d_model, d_ff, dropout_rate, dense_act_fn, layer_norm_epsilon, self.is_sparse))\n",
    "\n",
    "    def forward(\n",
    "        self,\n",
    "        hidden_states,\n",
    "        attention_mask=None,\n",
    "        position_bias=None,\n",
    "        encoder_hidden_states=None,\n",
    "        encoder_attention_mask=None,\n",
    "        encoder_decoder_position_bias=None,\n",
    "        layer_head_mask=None,\n",
    "        cross_attn_layer_head_mask=None,\n",
    "        past_key_value=None,\n",
    "        use_cache=False,\n",
    "        output_attentions=False,\n",
    "        output_router_logits=True,\n",
    "        return_dict=True,\n",
    "    ):\n",
    "        if past_key_value is not None:\n",
    "            if not self.is_decoder:\n",
    "                logger.warning(\"`past_key_values` is passed to the encoder. Please make sure this is intended.\")\n",
    "            expected_num_past_key_values = 2 if encoder_hidden_states is None else 4\n",
    "\n",
    "            if len(past_key_value) != expected_num_past_key_values:\n",
    "                raise ValueError(\n",
    "                    f\"There should be {expected_num_past_key_values} past states. \"\n",
    "                    f\"{'2 (past / key) for cross attention. ' if expected_num_past_key_values == 4 else ''}\"\n",
    "                    f\"Got {len(past_key_value)} past key / value states\"\n",
    "                )\n",
    "\n",
    "            self_attn_past_key_value = past_key_value[:2]\n",
    "            cross_attn_past_key_value = past_key_value[2:]\n",
    "        else:\n",
    "            self_attn_past_key_value, cross_attn_past_key_value = None, None\n",
    "\n",
    "        self_attention_outputs = self.layer[0](\n",
    "            hidden_states,\n",
    "            attention_mask=attention_mask,\n",
    "            position_bias=position_bias,\n",
    "            layer_head_mask=layer_head_mask,\n",
    "            past_key_value=self_attn_past_key_value,\n",
    "            use_cache=use_cache,\n",
    "            output_attentions=output_attentions,\n",
    "        )\n",
    "        hidden_states, present_key_value_state = self_attention_outputs[:2]\n",
    "        attention_outputs = self_attention_outputs[2:]  # Keep self-attention outputs and relative position weights\n",
    "\n",
    "        # clamp inf values to enable fp16 training\n",
    "        if hidden_states.dtype == torch.float16 and torch.isinf(hidden_states).any():\n",
    "            clamp_value = torch.finfo(hidden_states.dtype).max - 1000\n",
    "            hidden_states = torch.clamp(hidden_states, min=-clamp_value, max=clamp_value)\n",
    "\n",
    "        do_cross_attention = self.is_decoder and encoder_hidden_states is not None\n",
    "        if do_cross_attention:\n",
    "            # the actual query length is unknown for cross attention\n",
    "            # if using past key value states. Need to inject it here\n",
    "            if present_key_value_state is not None:\n",
    "                query_length = present_key_value_state[0].shape[2]\n",
    "            else:\n",
    "                query_length = None\n",
    "\n",
    "            cross_attention_outputs = self.layer[1](\n",
    "                hidden_states,\n",
    "                key_value_states=encoder_hidden_states,\n",
    "                attention_mask=encoder_attention_mask,\n",
    "                position_bias=encoder_decoder_position_bias,\n",
    "                layer_head_mask=cross_attn_layer_head_mask,\n",
    "                past_key_value=cross_attn_past_key_value,\n",
    "                query_length=query_length,\n",
    "                use_cache=use_cache,\n",
    "                output_attentions=output_attentions,\n",
    "            )\n",
    "            hidden_states = cross_attention_outputs[0]\n",
    "\n",
    "            # clamp inf values to enable fp16 training\n",
    "            if hidden_states.dtype == torch.float16 and torch.isinf(hidden_states).any():\n",
    "                clamp_value = torch.finfo(hidden_states.dtype).max - 1000\n",
    "                hidden_states = torch.clamp(hidden_states, min=-clamp_value, max=clamp_value)\n",
    "\n",
    "            # Combine self attn and cross attn key value states\n",
    "            if present_key_value_state is not None:\n",
    "                present_key_value_state = present_key_value_state + cross_attention_outputs[1]\n",
    "\n",
    "            # Keep cross-attention outputs and relative position weights\n",
    "            attention_outputs = attention_outputs + cross_attention_outputs[2:]\n",
    "\n",
    "        # Apply Feed Forward layer\n",
    "        hidden_states = self.layer[-1](hidden_states, output_router_logits)\n",
    "\n",
    "        if isinstance(hidden_states, tuple):\n",
    "            hidden_states, router_tuple = hidden_states\n",
    "        else:\n",
    "            router_tuple = (None,)\n",
    "\n",
    "        # clamp inf values to enable fp16 training\n",
    "        if hidden_states.dtype == torch.float16 and torch.isinf(hidden_states).any():\n",
    "            clamp_value = torch.finfo(hidden_states.dtype).max - 1000\n",
    "            hidden_states = torch.clamp(hidden_states, min=-clamp_value, max=clamp_value)\n",
    "\n",
    "        outputs = (hidden_states,)\n",
    "\n",
    "        if use_cache:\n",
    "            outputs = outputs + (present_key_value_state,) + attention_outputs + (router_tuple,)           \n",
    "        else:\n",
    "            outputs = outputs + attention_outputs + (router_tuple,)\n",
    "\n",
    "        return outputs  # hidden-states, present_key_value_states, (self-attention position bias), (self-attention weights), (cross-attention position bias), (cross-attention weights), (router_tuple)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SwitchTransformersStack(nn.Module):\n",
    "    def __init__(self, d_model, vocab_size, num_heads, dropout_rate, d_kv, relative_attention_num_buckets, relative_attention_max_distance, \n",
    "                 hidden_size, num_experts, experts_capacity, router_bias, router_jitter_noise, router_ignore_padding_tokens, \n",
    "                 router_dtype, d_ff, dense_act_fn, layer_norm_epsilon, decoder_sparse_step, encoder_sparse_step, num_decoder_layers,\n",
    "                 num_layers, output_attentions, use_cache, output_hidden_states, is_decoder=False, has_relative_attention_bias=False, is_sparse=False, embed_tokens=None):\n",
    "        super().__init__()\n",
    "\n",
    "        self.embed_tokens = nn.Embedding(vocab_size, d_model)\n",
    "\n",
    "        if embed_tokens is not None:\n",
    "            self.embed_tokens.weight = embed_tokens.weight\n",
    "\n",
    "        self.is_decoder = is_decoder\n",
    "\n",
    "        sparse_step = decoder_sparse_step if self.is_decoder else encoder_sparse_step\n",
    "        num_layers = num_decoder_layers if self.is_decoder else num_layers\n",
    "        self.block = nn.ModuleList()\n",
    "        for i in range(num_layers):\n",
    "            is_sparse = True\n",
    "            #is_sparse = (i % sparse_step == 1) if sparse_step > 0 else False\n",
    "\n",
    "            self.block.append(\n",
    "                SwitchTransformersBlock(d_model, num_heads, dropout_rate, d_kv, relative_attention_num_buckets, \n",
    "                 relative_attention_max_distance, hidden_size, num_experts, experts_capacity, router_bias, router_jitter_noise, \n",
    "                 router_ignore_padding_tokens, router_dtype, d_ff, dense_act_fn, layer_norm_epsilon, is_decoder, \n",
    "                 has_relative_attention_bias=bool(i == 0), is_sparse=is_sparse)\n",
    "            )\n",
    "\n",
    "        self.final_layer_norm = SwitchTransformersLayerNorm(d_model, eps=layer_norm_epsilon)\n",
    "        self.dropout = nn.Dropout(dropout_rate)\n",
    "\n",
    "        # Initialize weights and apply final processing\n",
    "\n",
    "        self.device_map = None\n",
    "        self.gradient_checkpointing = False\n",
    "        self.use_cache = use_cache\n",
    "        self.output_attentions = output_attentions\n",
    "        self.output_hidden_states = output_hidden_states\n",
    "        \n",
    "\n",
    "    def get_input_embeddings(self):\n",
    "        return self.embed_tokens\n",
    "\n",
    "    def set_input_embeddings(self, new_embeddings):\n",
    "        self.embed_tokens = new_embeddings\n",
    "\n",
    "    def forward(\n",
    "        self,\n",
    "        input_ids=None,\n",
    "        attention_mask=None,\n",
    "        encoder_hidden_states=None,\n",
    "        encoder_attention_mask=None,\n",
    "        inputs_embeds=None,\n",
    "        head_mask=None,\n",
    "        cross_attn_head_mask=None,\n",
    "        past_key_values=None,\n",
    "        use_cache=None,\n",
    "        output_attentions=None,\n",
    "        output_hidden_states=None,\n",
    "        output_router_logits=True,\n",
    "        return_dict=None,\n",
    "    ):\n",
    "        use_cache = use_cache if use_cache is not None else self.use_cache\n",
    "           \n",
    "        output_attentions = output_attentions if output_attentions is not None else self.output_attentions\n",
    "        output_hidden_states = (\n",
    "            output_hidden_states if output_hidden_states is not None else self.output_hidden_states\n",
    "        )\n",
    "        return_dict = return_dict if return_dict is not None else self.config.use_return_dict\n",
    "\n",
    "        if input_ids is not None and inputs_embeds is not None:\n",
    "            err_msg_prefix = \"decoder_\" if self.is_decoder else \"\"\n",
    "            raise ValueError(\n",
    "                f\"You cannot specify both {err_msg_prefix}input_ids and {err_msg_prefix}inputs_embeds at the same time\"\n",
    "            )\n",
    "        elif input_ids is not None:\n",
    "            input_shape = input_ids.size(0), input_ids.size(1)\n",
    "            input_ids = input_ids.view(input_shape[0], input_shape[1], -1)\n",
    "        elif inputs_embeds is not None:\n",
    "            input_shape = inputs_embeds.size()[:-1]\n",
    "        else:\n",
    "            err_msg_prefix = \"decoder_\" if self.is_decoder else \"\"\n",
    "            raise ValueError(f\"You have to specify either {err_msg_prefix}input_ids or {err_msg_prefix}inputs_embeds\")\n",
    "\n",
    "        if inputs_embeds is None:\n",
    "            if self.embed_tokens is None:\n",
    "                raise ValueError(\"You have to initialize the model with valid token embeddings\")\n",
    "            inputs_embeds = input_ids\n",
    "\n",
    "        batch_size, seq_length = input_shape\n",
    "\n",
    "        # required mask seq length can be calculated via length of past\n",
    "        mask_seq_length = past_key_values[0][0].shape[2] + seq_length if past_key_values is not None else seq_length\n",
    "\n",
    "        if use_cache is True:\n",
    "            if not self.is_decoder:\n",
    "                raise ValueError(f\"`use_cache` can only be set to `True` if {self} is used as a decoder\")\n",
    "\n",
    "        if attention_mask is None:\n",
    "            attention_mask = torch.ones(batch_size, mask_seq_length, device=inputs_embeds.device)\n",
    "        if self.is_decoder and encoder_attention_mask is None and encoder_hidden_states is not None:\n",
    "            encoder_seq_length = encoder_hidden_states.shape[1]\n",
    "            encoder_attention_mask = torch.ones(\n",
    "                batch_size, encoder_seq_length, device=inputs_embeds.device, dtype=torch.long\n",
    "            )\n",
    "\n",
    "        # initialize past_key_values with `None` if past does not exist\n",
    "        if past_key_values is None:\n",
    "            past_key_values = [None] * len(self.block)\n",
    "\n",
    "        # We can provide a self-attention mask of dimensions [batch_size, from_seq_length, to_seq_length]\n",
    "        # ourselves in which case we just need to make it broadcastable to all heads.\n",
    "        extended_attention_mask = None\n",
    "        #extended_attention_mask = self.get_extended_attention_mask(attention_mask, input_shape)\n",
    "\n",
    "        # If a 2D or 3D attention mask is provided for the cross-attention\n",
    "        # we need to make broadcastable to [batch_size, num_heads, seq_length, seq_length]\n",
    "        if self.is_decoder and encoder_hidden_states is not None:\n",
    "            encoder_batch_size, encoder_sequence_length, _ = encoder_hidden_states.size()\n",
    "            encoder_hidden_shape = (encoder_batch_size, encoder_sequence_length)\n",
    "            if encoder_attention_mask is None:\n",
    "                encoder_attention_mask = torch.ones(encoder_hidden_shape, device=inputs_embeds.device)\n",
    "            encoder_extended_attention_mask = None\n",
    "            #encoder_extended_attention_mask = self.invert_attention_mask(encoder_attention_mask)\n",
    "        else:\n",
    "            encoder_extended_attention_mask = None\n",
    "\n",
    "        if self.gradient_checkpointing and self.training:\n",
    "            if use_cache:\n",
    "                logger.warning_once(\n",
    "                    \"`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\"\n",
    "                )\n",
    "                use_cache = False\n",
    "\n",
    "        # Prepare head mask if needed\n",
    "        head_mask=None\n",
    "        #head_mask = self.get_head_mask(head_mask, self.config.num_layers)\n",
    "        cross_attn_head_mask=None\n",
    "        #cross_attn_head_mask = self.get_head_mask(cross_attn_head_mask, self.config.num_layers)\n",
    "        present_key_value_states = () if use_cache else None\n",
    "        all_hidden_states = () if output_hidden_states else None\n",
    "        all_attentions = () if output_attentions else None\n",
    "        all_router_probs = () if output_router_logits else None\n",
    "        all_cross_attentions = () if (output_attentions and self.is_decoder) else None\n",
    "        position_bias = None\n",
    "        encoder_decoder_position_bias = None\n",
    "\n",
    "        hidden_states = self.dropout(inputs_embeds)\n",
    "\n",
    "        for i, (layer_module, past_key_value) in enumerate(zip(self.block, past_key_values)):\n",
    "            layer_head_mask = None\n",
    "            #layer_head_mask = head_mask[i]\n",
    "            cross_attn_layer_head_mask = None\n",
    "            #cross_attn_layer_head_mask = cross_attn_head_mask[i]\n",
    "\n",
    "            if output_hidden_states:\n",
    "                all_hidden_states = all_hidden_states + (hidden_states,)\n",
    "\n",
    "            if self.gradient_checkpointing and self.training:\n",
    "\n",
    "                def create_custom_forward(module):\n",
    "                    def custom_forward(*inputs):\n",
    "                        return tuple(module(*inputs, use_cache, output_attentions))\n",
    "\n",
    "                    return custom_forward\n",
    "\n",
    "                layer_outputs = checkpoint(\n",
    "                    create_custom_forward(layer_module),\n",
    "                    hidden_states,\n",
    "                    extended_attention_mask,\n",
    "                    position_bias,\n",
    "                    encoder_hidden_states,\n",
    "                    encoder_extended_attention_mask,\n",
    "                    encoder_decoder_position_bias,\n",
    "                    layer_head_mask,\n",
    "                    cross_attn_layer_head_mask,\n",
    "                    None,  # past_key_value is always None with gradient checkpointing\n",
    "                )\n",
    "            else:\n",
    "                layer_outputs = layer_module(\n",
    "                    hidden_states,\n",
    "                    attention_mask=extended_attention_mask,\n",
    "                    position_bias=position_bias,\n",
    "                    encoder_hidden_states=encoder_hidden_states,\n",
    "                    encoder_attention_mask=encoder_extended_attention_mask,\n",
    "                    encoder_decoder_position_bias=encoder_decoder_position_bias,\n",
    "                    layer_head_mask=layer_head_mask,\n",
    "                    cross_attn_layer_head_mask=cross_attn_layer_head_mask,\n",
    "                    past_key_value=past_key_value,\n",
    "                    use_cache=use_cache,\n",
    "                    output_attentions=output_attentions,\n",
    "                    output_router_logits=output_router_logits,\n",
    "                )\n",
    "\n",
    "            router_probs = layer_outputs[-1]           \n",
    "            layer_outputs = layer_outputs[:-1]\n",
    "\n",
    "            # layer_outputs is a tuple with:\n",
    "            # hidden-states, key-value-states, (self-attention position bias), (self-attention weights), (cross-attention position bias), (cross-attention weights)\n",
    "            if use_cache is False:\n",
    "                layer_outputs = layer_outputs[:1] + (None,) + layer_outputs[1:]\n",
    "\n",
    "            hidden_states, present_key_value_state = layer_outputs[:2]\n",
    "\n",
    "            # We share the position biases between the layers - the first layer store them\n",
    "            # layer_outputs = hidden-states, key-value-states (self-attention position bias), (self-attention weights),\n",
    "            # (cross-attention position bias), (cross-attention weights)\n",
    "            position_bias = layer_outputs[2]\n",
    "            if self.is_decoder and encoder_hidden_states is not None:\n",
    "                encoder_decoder_position_bias = layer_outputs[4 if output_attentions else 3]\n",
    "            # append next layer key value states\n",
    "            if use_cache:\n",
    "                present_key_value_states = present_key_value_states + (present_key_value_state,)\n",
    "\n",
    "            if output_attentions:\n",
    "                all_attentions = all_attentions + (layer_outputs[3],)\n",
    "                if self.is_decoder:\n",
    "                    all_cross_attentions = all_cross_attentions + (layer_outputs[5],)\n",
    "\n",
    "            if output_router_logits:\n",
    "                all_router_probs = all_router_probs + (router_probs,)\n",
    "\n",
    "        hidden_states = self.final_layer_norm(hidden_states)\n",
    "        hidden_states = self.dropout(hidden_states)\n",
    "        \n",
    "        # Add last layer\n",
    "        if output_hidden_states:\n",
    "            all_hidden_states = all_hidden_states + (hidden_states,)\n",
    "\n",
    "        if not return_dict:           \n",
    "            return tuple(\n",
    "                v\n",
    "                for v in [\n",
    "                    hidden_states,\n",
    "                    present_key_value_states,\n",
    "                    all_hidden_states,\n",
    "                    all_attentions,\n",
    "                    all_cross_attentions,\n",
    "                    all_router_probs,\n",
    "                ]\n",
    "                if v is not None\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SwitchTransformersModel(nn.Module):\n",
    "    def __init__(self, d_model, vocab_size, num_heads, dropout_rate, d_kv, relative_attention_num_buckets, \n",
    "                 relative_attention_max_distance, hidden_size, num_experts, experts_capacity, router_bias, router_jitter_noise, \n",
    "                 router_ignore_padding_tokens, router_dtype, d_ff, dense_act_fn, layer_norm_epsilon, decoder_sparse_step, \n",
    "                 encoder_sparse_step, num_decoder_layers, num_layers, num_sparse_encoder_layers):\n",
    "        super().__init__()\n",
    "        self.shared = nn.Embedding(vocab_size, d_model)\n",
    "\n",
    "        self.encoder = SwitchTransformersStack(d_model, vocab_size, num_heads, dropout_rate, d_kv, relative_attention_num_buckets, \n",
    "                 relative_attention_max_distance, hidden_size, num_experts, experts_capacity, router_bias, router_jitter_noise, \n",
    "                 router_ignore_padding_tokens, router_dtype, d_ff, dense_act_fn, layer_norm_epsilon, decoder_sparse_step, \n",
    "                 encoder_sparse_step, num_decoder_layers, num_layers, output_attentions=True, use_cache=False, output_hidden_states=True, \n",
    "                 is_decoder=False, has_relative_attention_bias=True, is_sparse=True, embed_tokens=self.shared)\n",
    "\n",
    "        self.decoder = SwitchTransformersStack(d_model, vocab_size, num_heads, dropout_rate, d_kv, relative_attention_num_buckets, \n",
    "                 relative_attention_max_distance, hidden_size, num_experts, experts_capacity, router_bias, router_jitter_noise, \n",
    "                 router_ignore_padding_tokens, router_dtype, d_ff, dense_act_fn, layer_norm_epsilon, decoder_sparse_step, \n",
    "                 encoder_sparse_step, num_decoder_layers, num_layers, output_attentions=True, use_cache=True, output_hidden_states=True, \n",
    "                 is_decoder=True, has_relative_attention_bias=True, is_sparse=True, embed_tokens=self.shared)\n",
    "\n",
    "        # Initialize weights and apply final processing\n",
    "\n",
    "        # Model parallel\n",
    "        self.device_map = None\n",
    "        self.use_cache = True\n",
    "        self.use_return_dict = False\n",
    "        self.num_sparse_encoder_layers = num_sparse_encoder_layers\n",
    "        \n",
    "        self.flatten = nn.Flatten()\n",
    "        self.final_layer = nn.Linear(d_model, 1)\n",
    "        \n",
    "\n",
    "    def get_input_embeddings(self):\n",
    "        return self.shared\n",
    "\n",
    "    def set_input_embeddings(self, new_embeddings):\n",
    "        self.shared = new_embeddings\n",
    "        self.encoder.set_input_embeddings(new_embeddings)\n",
    "        self.decoder.set_input_embeddings(new_embeddings)\n",
    "\n",
    "    def get_encoder(self):\n",
    "        return self.encoder\n",
    "\n",
    "    def get_decoder(self):\n",
    "        return self.decoder\n",
    "\n",
    "    def _prune_heads(self, heads_to_prune):\n",
    "        \"\"\"\n",
    "        Prunes heads of the model. heads_to_prune: dict of {layer_num: list of heads to prune in this layer} See base\n",
    "        class PreTrainedModel\n",
    "        \"\"\"\n",
    "        for layer, heads in heads_to_prune.items():\n",
    "            self.encoder.layer[layer].attention.prune_heads(heads)\n",
    "\n",
    "    def forward(\n",
    "        self,\n",
    "        input_ids: Optional[torch.LongTensor] = None,\n",
    "        attention_mask: Optional[torch.FloatTensor] = None,\n",
    "        decoder_input_ids: Optional[torch.LongTensor] = None,\n",
    "        decoder_attention_mask: Optional[torch.BoolTensor] = None,\n",
    "        head_mask: Optional[torch.FloatTensor] = None,\n",
    "        decoder_head_mask: Optional[torch.FloatTensor] = None,\n",
    "        cross_attn_head_mask: Optional[torch.Tensor] = None,\n",
    "        encoder_outputs: Optional[Tuple[Tuple[torch.FloatTensor]]] = None,\n",
    "        past_key_values: Optional[Tuple[Tuple[torch.FloatTensor]]] = None,\n",
    "        inputs_embeds: Optional[torch.Tensor] = None,\n",
    "        decoder_inputs_embeds: Optional[torch.Tensor] = None,\n",
    "        use_cache: Optional[bool] = None,\n",
    "        output_attentions: Optional[bool] = None,\n",
    "        output_hidden_states: Optional[bool] = None,\n",
    "        output_router_logits: Optional[bool] = None,\n",
    "        return_dict: Optional[bool] = None,\n",
    "    ) -> Union[Tuple[torch.FloatTensor]]:\n",
    "        r\"\"\"\n",
    "        Returns:\n",
    "        Example:\n",
    "        ```python\n",
    "        >>> from transformers import AutoTokenizer, SwitchTransformersModel\n",
    "        >>> tokenizer = AutoTokenizer.from_pretrained(\"google/switch-base-8\")\n",
    "        >>> model = SwitchTransformersModel.from_pretrained(\"google/switch-base-8\")\n",
    "        >>> input_ids = tokenizer(\n",
    "        ...     \"Studies have been shown that owning a dog is good for you\", return_tensors=\"pt\"\n",
    "        ... ).input_ids  # Batch size 1\n",
    "        >>> decoder_input_ids = tokenizer(\"Studies show that\", return_tensors=\"pt\").input_ids  # Batch size 1\n",
    "        >>> # preprocess: Prepend decoder_input_ids with start token which is pad token for SwitchTransformersModel.\n",
    "        >>> # This is not needed for torch's SwitchTransformersForConditionalGeneration as it does this internally using labels arg.\n",
    "        >>> decoder_input_ids = model._shift_right(decoder_input_ids)\n",
    "        >>> # forward pass\n",
    "        >>> outputs = model(input_ids=input_ids, decoder_input_ids=decoder_input_ids)\n",
    "        >>> last_hidden_states = outputs.last_hidden_state\n",
    "        ```\"\"\"\n",
    "        use_cache = use_cache if use_cache is not None else self.use_cache\n",
    "        return_dict = return_dict if return_dict is not None else self.use_return_dict\n",
    "\n",
    "        # FutureWarning: head_mask was separated into two input args - head_mask, decoder_head_mask\n",
    "        if head_mask is not None and decoder_head_mask is None:\n",
    "            if self.config.num_layers == self.config.num_decoder_layers:\n",
    "                warnings.warn(__HEAD_MASK_WARNING_MSG, FutureWarning)\n",
    "                decoder_head_mask = head_mask\n",
    "\n",
    "        if (\n",
    "            output_router_logits\n",
    "            and self.num_sparse_encoder_layers == 0\n",
    "            and self.num_sparse_encoder_layers == 0\n",
    "        ):\n",
    "            raise ValueError(\n",
    "                \"You asked to return `output_router_logits` but the transformer in dense, and does                    \"\n",
    "                \"           not contain any sparse MLP Layers. Set `output_router_logits = False` and restart\"\n",
    "            )\n",
    "        # Encode if needed (training, first prediction pass)\n",
    "        if encoder_outputs is None:\n",
    "            encoder_outputs = self.encoder(\n",
    "                input_ids=input_ids,\n",
    "                attention_mask=attention_mask,\n",
    "                inputs_embeds=inputs_embeds,\n",
    "                head_mask=head_mask,\n",
    "                output_attentions=output_attentions,\n",
    "                output_hidden_states=output_hidden_states,\n",
    "                output_router_logits=output_router_logits,\n",
    "                return_dict=return_dict,\n",
    "            )\n",
    "        elif return_dict and not isinstance(encoder_outputs, MoEModelOutput):\n",
    "            encoder_outputs = MoEModelOutput(\n",
    "                last_hidden_state=encoder_outputs[0],\n",
    "                hidden_states=encoder_outputs[1] if len(encoder_outputs) > 1 else None,\n",
    "                attentions=encoder_outputs[2] if len(encoder_outputs) > 2 else None,\n",
    "                router_probs=encoder_outputs[3] if len(encoder_outputs) > 3 else None,\n",
    "            )\n",
    "\n",
    "        hidden_states = encoder_outputs[0]\n",
    "\n",
    "        # Decode\n",
    "        decoder_outputs = self.decoder(\n",
    "            input_ids=decoder_input_ids,\n",
    "            attention_mask=decoder_attention_mask,\n",
    "            inputs_embeds=decoder_inputs_embeds,\n",
    "            past_key_values=past_key_values,\n",
    "            encoder_hidden_states=hidden_states,\n",
    "            encoder_attention_mask=attention_mask,\n",
    "            head_mask=decoder_head_mask,\n",
    "            cross_attn_head_mask=cross_attn_head_mask,\n",
    "            use_cache=use_cache,\n",
    "            output_attentions=output_attentions,\n",
    "            output_hidden_states=output_hidden_states,\n",
    "            output_router_logits=output_router_logits,\n",
    "            return_dict=return_dict,\n",
    "        )\n",
    "        output = decoder_outputs[0]\n",
    "        output = F.relu(self.flatten(output))\n",
    "        output = self.final_layer(output)\n",
    "        \n",
    "        new_output = (output,) + decoder_outputs[1:]\n",
    "\n",
    "        if not return_dict:\n",
    "            return new_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_layers = 2\n",
    "num_decoder_layers = 2\n",
    "vocab_size = 50\n",
    "num_heads = 2\n",
    "d_model = 20\n",
    "d_ff = 64\n",
    "dropout_rate = 0\n",
    "d_kv = 32\n",
    "relative_attention_num_buckets = 32\n",
    "relative_attention_max_distance = 128\n",
    "hidden_size = 20\n",
    "num_experts = 4\n",
    "experts_capacity = 10\n",
    "router_bias = True\n",
    "router_jitter_noise = 0.01\n",
    "router_ignore_padding_tokens = True\n",
    "router_dtype = 'float32'\n",
    "dense_act_fn = 'gelu'\n",
    "layer_norm_epsilon = 1e-6\n",
    "decoder_sparse_step = 2\n",
    "encoder_sparse_step = 2\n",
    "num_sparse_encoder_layers = 2\n",
    "\n",
    "input_ids = torch.rand(5, 21, 20)\n",
    "target_ids = torch.rand(5, 1, 20)\n",
    "\n",
    "model=SwitchTransformersModel(\n",
    "        d_model, vocab_size, num_heads, dropout_rate, d_kv, relative_attention_num_buckets, \n",
    "        relative_attention_max_distance, hidden_size, num_experts, experts_capacity, router_bias, router_jitter_noise, \n",
    "        router_ignore_padding_tokens, router_dtype, d_ff, dense_act_fn, layer_norm_epsilon, decoder_sparse_step, \n",
    "        encoder_sparse_step, num_decoder_layers, num_layers, num_sparse_encoder_layers\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5, 1])\n",
      "tensor([[ 0.2873],\n",
      "        [-0.0507],\n",
      "        [ 0.3121],\n",
      "        [ 0.1668],\n",
      "        [-0.0302]], grad_fn=<AddmmBackward0>)\n"
     ]
    }
   ],
   "source": [
    "hidden_states, present_key_value_states, all_hidden_states, all_attentions, all_cross_attentions, all_router_probs = model(input_ids=input_ids, decoder_input_ids=target_ids, output_router_logits=True)\n",
    "print(hidden_states.shape)\n",
    "print(hidden_states)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import seaborn as sns\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>AOAL</th>\n",
       "      <th>AOAR</th>\n",
       "      <th>PITCH</th>\n",
       "      <th>W</th>\n",
       "      <th>MACH</th>\n",
       "      <th>AIRSPD</th>\n",
       "      <th>TEFLAPL</th>\n",
       "      <th>XIDA</th>\n",
       "      <th>T</th>\n",
       "      <th>...</th>\n",
       "      <th>OPR</th>\n",
       "      <th>OTL</th>\n",
       "      <th>OTR</th>\n",
       "      <th>VIBN1L</th>\n",
       "      <th>VIBN1R</th>\n",
       "      <th>VIBN2L</th>\n",
       "      <th>VIBN2R</th>\n",
       "      <th>FE</th>\n",
       "      <th>TMAX</th>\n",
       "      <th>FS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>-10.55</td>\n",
       "      <td>-4.22</td>\n",
       "      <td>-0.53</td>\n",
       "      <td>63901.05853</td>\n",
       "      <td>0.084</td>\n",
       "      <td>56.3</td>\n",
       "      <td>5</td>\n",
       "      <td>6.855</td>\n",
       "      <td>20.50</td>\n",
       "      <td>...</td>\n",
       "      <td>24</td>\n",
       "      <td>110</td>\n",
       "      <td>110</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.05</td>\n",
       "      <td>23995.070700</td>\n",
       "      <td>24572.967483</td>\n",
       "      <td>577.896783</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>-9.84</td>\n",
       "      <td>-3.87</td>\n",
       "      <td>-0.53</td>\n",
       "      <td>63900.67347</td>\n",
       "      <td>0.087</td>\n",
       "      <td>58.2</td>\n",
       "      <td>5</td>\n",
       "      <td>6.325</td>\n",
       "      <td>20.50</td>\n",
       "      <td>...</td>\n",
       "      <td>26</td>\n",
       "      <td>110</td>\n",
       "      <td>110</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.05</td>\n",
       "      <td>23453.775200</td>\n",
       "      <td>24572.967483</td>\n",
       "      <td>1119.192283</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>-9.14</td>\n",
       "      <td>-3.34</td>\n",
       "      <td>-0.53</td>\n",
       "      <td>63900.23197</td>\n",
       "      <td>0.090</td>\n",
       "      <td>60.1</td>\n",
       "      <td>5</td>\n",
       "      <td>5.710</td>\n",
       "      <td>20.50</td>\n",
       "      <td>...</td>\n",
       "      <td>26</td>\n",
       "      <td>110</td>\n",
       "      <td>110</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.05</td>\n",
       "      <td>22821.215600</td>\n",
       "      <td>24572.967483</td>\n",
       "      <td>1751.751883</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>-8.09</td>\n",
       "      <td>-3.87</td>\n",
       "      <td>-0.35</td>\n",
       "      <td>63899.73805</td>\n",
       "      <td>0.093</td>\n",
       "      <td>62.0</td>\n",
       "      <td>5</td>\n",
       "      <td>5.630</td>\n",
       "      <td>20.50</td>\n",
       "      <td>...</td>\n",
       "      <td>26</td>\n",
       "      <td>110</td>\n",
       "      <td>110</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.05</td>\n",
       "      <td>22738.950900</td>\n",
       "      <td>24572.967483</td>\n",
       "      <td>1834.016583</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>-7.56</td>\n",
       "      <td>-3.87</td>\n",
       "      <td>-0.35</td>\n",
       "      <td>63899.14333</td>\n",
       "      <td>0.096</td>\n",
       "      <td>63.9</td>\n",
       "      <td>5</td>\n",
       "      <td>5.365</td>\n",
       "      <td>20.50</td>\n",
       "      <td>...</td>\n",
       "      <td>26</td>\n",
       "      <td>110</td>\n",
       "      <td>110</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.05</td>\n",
       "      <td>22464.769900</td>\n",
       "      <td>24572.967483</td>\n",
       "      <td>2108.197583</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11519</th>\n",
       "      <td>11544</td>\n",
       "      <td>-2.81</td>\n",
       "      <td>-3.69</td>\n",
       "      <td>-0.70</td>\n",
       "      <td>56378.87869</td>\n",
       "      <td>0.150</td>\n",
       "      <td>56.0</td>\n",
       "      <td>30</td>\n",
       "      <td>3.950</td>\n",
       "      <td>23.75</td>\n",
       "      <td>...</td>\n",
       "      <td>43</td>\n",
       "      <td>98</td>\n",
       "      <td>98</td>\n",
       "      <td>0.09</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.05</td>\n",
       "      <td>7668.487126</td>\n",
       "      <td>18764.344514</td>\n",
       "      <td>11095.857388</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11520</th>\n",
       "      <td>11545</td>\n",
       "      <td>-2.99</td>\n",
       "      <td>-3.69</td>\n",
       "      <td>-0.88</td>\n",
       "      <td>56378.72144</td>\n",
       "      <td>0.150</td>\n",
       "      <td>52.0</td>\n",
       "      <td>30</td>\n",
       "      <td>4.220</td>\n",
       "      <td>23.75</td>\n",
       "      <td>...</td>\n",
       "      <td>31</td>\n",
       "      <td>98</td>\n",
       "      <td>98</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.07</td>\n",
       "      <td>7393.237132</td>\n",
       "      <td>18764.344514</td>\n",
       "      <td>11371.107383</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11521</th>\n",
       "      <td>11546</td>\n",
       "      <td>-2.81</td>\n",
       "      <td>-3.69</td>\n",
       "      <td>-0.88</td>\n",
       "      <td>56378.57427</td>\n",
       "      <td>0.150</td>\n",
       "      <td>49.0</td>\n",
       "      <td>30</td>\n",
       "      <td>4.130</td>\n",
       "      <td>23.75</td>\n",
       "      <td>...</td>\n",
       "      <td>31</td>\n",
       "      <td>98</td>\n",
       "      <td>98</td>\n",
       "      <td>0.13</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.09</td>\n",
       "      <td>7484.958267</td>\n",
       "      <td>18764.344514</td>\n",
       "      <td>11279.386247</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11522</th>\n",
       "      <td>11547</td>\n",
       "      <td>-2.81</td>\n",
       "      <td>-3.69</td>\n",
       "      <td>-0.70</td>\n",
       "      <td>56378.43517</td>\n",
       "      <td>0.150</td>\n",
       "      <td>46.0</td>\n",
       "      <td>30</td>\n",
       "      <td>3.950</td>\n",
       "      <td>24.00</td>\n",
       "      <td>...</td>\n",
       "      <td>31</td>\n",
       "      <td>97</td>\n",
       "      <td>97</td>\n",
       "      <td>0.13</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.18</td>\n",
       "      <td>0.09</td>\n",
       "      <td>7652.561590</td>\n",
       "      <td>18764.344514</td>\n",
       "      <td>11111.782924</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11523</th>\n",
       "      <td>11548</td>\n",
       "      <td>-3.16</td>\n",
       "      <td>-3.69</td>\n",
       "      <td>-0.70</td>\n",
       "      <td>56378.30816</td>\n",
       "      <td>0.150</td>\n",
       "      <td>45.0</td>\n",
       "      <td>30</td>\n",
       "      <td>4.125</td>\n",
       "      <td>24.00</td>\n",
       "      <td>...</td>\n",
       "      <td>31</td>\n",
       "      <td>97</td>\n",
       "      <td>97</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.09</td>\n",
       "      <td>7474.749119</td>\n",
       "      <td>18764.344514</td>\n",
       "      <td>11289.595395</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>11524 rows  28 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        date   AOAL  AOAR  PITCH            W   MACH  AIRSPD  TEFLAPL   XIDA  \\\n",
       "0          0 -10.55 -4.22  -0.53  63901.05853  0.084    56.3        5  6.855   \n",
       "1          1  -9.84 -3.87  -0.53  63900.67347  0.087    58.2        5  6.325   \n",
       "2          2  -9.14 -3.34  -0.53  63900.23197  0.090    60.1        5  5.710   \n",
       "3          3  -8.09 -3.87  -0.35  63899.73805  0.093    62.0        5  5.630   \n",
       "4          4  -7.56 -3.87  -0.35  63899.14333  0.096    63.9        5  5.365   \n",
       "...      ...    ...   ...    ...          ...    ...     ...      ...    ...   \n",
       "11519  11544  -2.81 -3.69  -0.70  56378.87869  0.150    56.0       30  3.950   \n",
       "11520  11545  -2.99 -3.69  -0.88  56378.72144  0.150    52.0       30  4.220   \n",
       "11521  11546  -2.81 -3.69  -0.88  56378.57427  0.150    49.0       30  4.130   \n",
       "11522  11547  -2.81 -3.69  -0.70  56378.43517  0.150    46.0       30  3.950   \n",
       "11523  11548  -3.16 -3.69  -0.70  56378.30816  0.150    45.0       30  4.125   \n",
       "\n",
       "           T  ...  OPR  OTL  OTR  VIBN1L  VIBN1R  VIBN2L  VIBN2R  \\\n",
       "0      20.50  ...   24  110  110    0.03    0.05    0.05    0.05   \n",
       "1      20.50  ...   26  110  110    0.03    0.05    0.07    0.05   \n",
       "2      20.50  ...   26  110  110    0.03    0.06    0.08    0.05   \n",
       "3      20.50  ...   26  110  110    0.03    0.06    0.08    0.05   \n",
       "4      20.50  ...   26  110  110    0.03    0.06    0.08    0.05   \n",
       "...      ...  ...  ...  ...  ...     ...     ...     ...     ...   \n",
       "11519  23.75  ...   43   98   98    0.09    0.10    0.10    0.05   \n",
       "11520  23.75  ...   31   98   98    0.10    0.10    0.12    0.07   \n",
       "11521  23.75  ...   31   98   98    0.13    0.12    0.12    0.09   \n",
       "11522  24.00  ...   31   97   97    0.13    0.15    0.18    0.09   \n",
       "11523  24.00  ...   31   97   97    0.14    0.15    0.25    0.09   \n",
       "\n",
       "                 FE          TMAX            FS  \n",
       "0      23995.070700  24572.967483    577.896783  \n",
       "1      23453.775200  24572.967483   1119.192283  \n",
       "2      22821.215600  24572.967483   1751.751883  \n",
       "3      22738.950900  24572.967483   1834.016583  \n",
       "4      22464.769900  24572.967483   2108.197583  \n",
       "...             ...           ...           ...  \n",
       "11519   7668.487126  18764.344514  11095.857388  \n",
       "11520   7393.237132  18764.344514  11371.107383  \n",
       "11521   7484.958267  18764.344514  11279.386247  \n",
       "11522   7652.561590  18764.344514  11111.782924  \n",
       "11523   7474.749119  18764.344514  11289.595395  \n",
       "\n",
       "[11524 rows x 28 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "column_names = ['date','AOAL','AOAR','PITCH','W','MACH','AIRSPD','TEFLAPL','XIDA',\n",
    "               'T','ALTSTD','N1L','N1R','N2L','N2R','EGTL','EGTR','OPL','OPR','OTL',\n",
    "               'OTR','VIBN1L','VIBN1R','VIBN2L','VIBN2R','FE','TMAX','FS']\n",
    "\n",
    "input=pd.read_excel('D:\\\\\\\\practice\\\\QAR_xunlian.xlsx',names=column_names)\n",
    "input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_names = ['W','MACH','AIRSPD','TEFLAPL','XIDA',\n",
    "               'T','ALTSTD','N1L','N1R','N2L','N2R','EGTL','EGTR','OPL','OPR','OTL',\n",
    "               'OTR','VIBN1L','VIBN1R','VIBN2L','VIBN2R','FE']\n",
    "\n",
    "df=input[feature_names]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_for_training=df[feature_names].astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11524, 22)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_for_training.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler=StandardScaler()\n",
    "scaler=scaler.fit(df_for_training)\n",
    "df_for_training_scaled=scaler.transform(df_for_training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainX=[]\n",
    "trainY=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_future=1\n",
    "n_past=20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(n_past,len(df_for_training_scaled)-n_future+1):\n",
    "    trainX.append(df_for_training_scaled[i-n_past:i,0:df_for_training.shape[1]])\n",
    "    trainY.append(df_for_training_scaled[i:i+n_future,21])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainX shape==(11504, 20, 22).\n",
      "trainY shape==(11504, 1).\n"
     ]
    }
   ],
   "source": [
    "trainX,trainY=np.array(trainX),np.array(trainY)\n",
    "print('trainX shape=={}.'.format(trainX.shape))\n",
    "print('trainY shape=={}.'.format(trainY.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainX0=np.zeros((trainX.shape[0],22,20))\n",
    "for i in range(0,trainX.shape[0]):\n",
    "    trainX0[i]=trainX[i].T\n",
    "trainX1=np.zeros((trainX.shape[0],21,20))\n",
    "for i in range(0,trainX.shape[0]):\n",
    "    trainX1[i]=trainX0[i][0:21,:]\n",
    "trainX2=np.zeros((trainX.shape[0],1,20))\n",
    "for i in range(0,trainX.shape[0]):\n",
    "    trainX2[i]=trainX0[i][21,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainX1_copy,trainX2_copy,trainY_copy=trainX1.copy(),trainX2.copy(),trainY.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_shuffle(data1,data2,label):\n",
    "    randnum = np.random.randint(0, len(label))\n",
    "    np.random.seed(randnum)\n",
    "    np.random.shuffle(data1)\n",
    "    np.random.seed(randnum)\n",
    "    np.random.shuffle(data2)\n",
    "    np.random.seed(randnum)\n",
    "    np.random.shuffle(label)\n",
    "    return data1,data2,label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "data1,data2,label=random_shuffle(trainX1,trainX2,trainY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a DataLoader for the training data\n",
    "data1 = torch.from_numpy(data1).float()\n",
    "data2 = torch.from_numpy(data2).float()\n",
    "label = torch.from_numpy(label).float()\n",
    "train_dataset = TensorDataset(data1, data2, label)\n",
    "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(model.parameters(), lr=3e-4, weight_decay=1e-5)\n",
    "min_val_acc=1000000000000000\n",
    "scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=50, eta_min=0 )\n",
    "criterion = nn.L1Loss()\n",
    "device = torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda3\\lib\\site-packages\\torch\\optim\\lr_scheduler.py:156: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n",
      "  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 Loss: 0.8093079328536987\n",
      "Epoch: 1 Loss: 1.148249864578247\n",
      "Epoch: 2 Loss: 0.06433305144309998\n",
      "Epoch: 3 Loss: 0.6730219721794128\n",
      "Epoch: 4 Loss: 0.41886866092681885\n",
      "Epoch: 5 Loss: 0.8018103241920471\n",
      "Epoch: 6 Loss: 0.15394283831119537\n",
      "Epoch: 7 Loss: 0.10315534472465515\n",
      "Epoch: 8 Loss: 0.14083260297775269\n",
      "Epoch: 9 Loss: 0.5030076503753662\n",
      "Epoch: 10 Loss: 0.20733943581581116\n",
      "Epoch: 11 Loss: 0.13448265194892883\n",
      "Epoch: 12 Loss: 0.11839621514081955\n",
      "Epoch: 13 Loss: 0.6104989051818848\n",
      "Epoch: 14 Loss: 0.3892529308795929\n",
      "Epoch: 15 Loss: 0.055139172822237015\n",
      "Epoch: 16 Loss: 0.32503217458724976\n",
      "Epoch: 17 Loss: 0.1308736503124237\n",
      "Epoch: 18 Loss: 1.9695549011230469\n",
      "Epoch: 19 Loss: 0.16541334986686707\n",
      "Epoch: 20 Loss: 0.7598134875297546\n",
      "Epoch: 21 Loss: 0.4582280218601227\n",
      "Epoch: 22 Loss: 0.6607184410095215\n",
      "Epoch: 23 Loss: 0.20870348811149597\n",
      "Epoch: 24 Loss: 0.11154915392398834\n",
      "Epoch: 25 Loss: 0.45063135027885437\n",
      "Epoch: 26 Loss: 0.14380186796188354\n",
      "Epoch: 27 Loss: 1.4951159954071045\n",
      "Epoch: 28 Loss: 0.7797967791557312\n",
      "Epoch: 29 Loss: 0.9386739134788513\n",
      "Epoch: 30 Loss: 0.8170890212059021\n",
      "Epoch: 31 Loss: 0.23417547345161438\n",
      "Epoch: 32 Loss: 0.9759657979011536\n",
      "Epoch: 33 Loss: 0.2720736861228943\n",
      "Epoch: 34 Loss: 0.6693447828292847\n",
      "Epoch: 35 Loss: 0.09267540276050568\n",
      "Epoch: 36 Loss: 0.17077578604221344\n",
      "Epoch: 37 Loss: 0.186850443482399\n",
      "Epoch: 38 Loss: 0.14386680722236633\n",
      "Epoch: 39 Loss: 0.7299927473068237\n",
      "Epoch: 40 Loss: 0.08970410376787186\n",
      "Epoch: 41 Loss: 0.10074041783809662\n",
      "Epoch: 42 Loss: 0.17802304029464722\n",
      "Epoch: 43 Loss: 0.0894332304596901\n",
      "Epoch: 44 Loss: 0.17068617045879364\n",
      "Epoch: 45 Loss: 0.2690330743789673\n",
      "Epoch: 46 Loss: 0.6583874821662903\n",
      "Epoch: 47 Loss: 0.11353085935115814\n",
      "Epoch: 48 Loss: 0.08531539887189865\n",
      "Epoch: 49 Loss: 0.11294514685869217\n",
      "Epoch: 50 Loss: 0.14910727739334106\n",
      "Epoch: 51 Loss: 0.2878545820713043\n",
      "Epoch: 52 Loss: 0.20555874705314636\n",
      "Epoch: 53 Loss: 0.3380374312400818\n",
      "Epoch: 54 Loss: 0.13204188644886017\n",
      "Epoch: 55 Loss: 0.1403656154870987\n",
      "Epoch: 56 Loss: 0.21356789767742157\n",
      "Epoch: 57 Loss: 0.27101874351501465\n",
      "Epoch: 58 Loss: 0.17571954429149628\n",
      "Epoch: 59 Loss: 0.0953129306435585\n",
      "Epoch: 60 Loss: 0.37953969836235046\n",
      "Epoch: 61 Loss: 0.09748417884111404\n",
      "Epoch: 62 Loss: 0.07860753685235977\n",
      "Epoch: 63 Loss: 0.4198274314403534\n",
      "Epoch: 64 Loss: 0.2177095264196396\n",
      "Epoch: 65 Loss: 0.4848341941833496\n",
      "Epoch: 66 Loss: 0.19050011038780212\n",
      "Epoch: 67 Loss: 0.053370822221040726\n",
      "Epoch: 68 Loss: 0.1811520755290985\n",
      "Epoch: 69 Loss: 0.10248377919197083\n",
      "Epoch: 70 Loss: 0.09413722157478333\n",
      "Epoch: 71 Loss: 0.0818655788898468\n",
      "Epoch: 72 Loss: 0.19192703068256378\n",
      "Epoch: 73 Loss: 0.1560019999742508\n",
      "Epoch: 74 Loss: 0.07574958354234695\n",
      "Epoch: 75 Loss: 0.8930414319038391\n",
      "Epoch: 76 Loss: 0.11390936374664307\n",
      "Epoch: 77 Loss: 0.06326469779014587\n",
      "Epoch: 78 Loss: 0.19893425703048706\n",
      "Epoch: 79 Loss: 0.30802467465400696\n",
      "Epoch: 80 Loss: 0.03843557462096214\n",
      "Epoch: 81 Loss: 0.24711883068084717\n",
      "Epoch: 82 Loss: 0.2041819840669632\n",
      "Epoch: 83 Loss: 0.09299628436565399\n",
      "Epoch: 84 Loss: 0.4502671957015991\n",
      "Epoch: 85 Loss: 0.23242570459842682\n",
      "Epoch: 86 Loss: 0.07566115260124207\n",
      "Epoch: 87 Loss: 0.15304352343082428\n",
      "Epoch: 88 Loss: 0.06108403205871582\n",
      "Epoch: 89 Loss: 0.2901698052883148\n",
      "Epoch: 90 Loss: 0.2070898413658142\n",
      "Epoch: 91 Loss: 0.22588959336280823\n",
      "Epoch: 92 Loss: 0.09279686212539673\n",
      "Epoch: 93 Loss: 0.38553935289382935\n",
      "Epoch: 94 Loss: 0.1513195037841797\n",
      "Epoch: 95 Loss: 0.30061936378479004\n",
      "Epoch: 96 Loss: 0.09491223096847534\n",
      "Epoch: 97 Loss: 0.32178252935409546\n",
      "Epoch: 98 Loss: 0.1350807249546051\n",
      "Epoch: 99 Loss: 0.16759851574897766\n",
      "Epoch: 100 Loss: 0.05791962146759033\n",
      "Epoch: 101 Loss: 0.0701860785484314\n",
      "Epoch: 102 Loss: 0.07578591257333755\n",
      "Epoch: 103 Loss: 0.16760237514972687\n",
      "Epoch: 104 Loss: 0.07963963598012924\n",
      "Epoch: 105 Loss: 0.4176707863807678\n",
      "Epoch: 106 Loss: 0.10086376965045929\n",
      "Epoch: 107 Loss: 0.18488234281539917\n",
      "Epoch: 108 Loss: 0.23759202659130096\n",
      "Epoch: 109 Loss: 0.038214124739170074\n",
      "Epoch: 110 Loss: 0.17159152030944824\n",
      "Epoch: 111 Loss: 0.18360085785388947\n",
      "Epoch: 112 Loss: 0.21675044298171997\n",
      "Epoch: 113 Loss: 0.19501851499080658\n",
      "Epoch: 114 Loss: 0.1619454324245453\n",
      "Epoch: 115 Loss: 0.18341629207134247\n",
      "Epoch: 116 Loss: 0.13305950164794922\n",
      "Epoch: 117 Loss: 0.1518910825252533\n",
      "Epoch: 118 Loss: 0.2564811706542969\n",
      "Epoch: 119 Loss: 0.12724918127059937\n",
      "Epoch: 120 Loss: 0.07429268211126328\n",
      "Epoch: 121 Loss: 0.12228213995695114\n",
      "Epoch: 122 Loss: 0.234770268201828\n",
      "Epoch: 123 Loss: 0.10168018937110901\n",
      "Epoch: 124 Loss: 0.20055851340293884\n",
      "Epoch: 125 Loss: 0.13065683841705322\n",
      "Epoch: 126 Loss: 0.05271700769662857\n",
      "Epoch: 127 Loss: 0.08186358213424683\n",
      "Epoch: 128 Loss: 0.07859107851982117\n",
      "Epoch: 129 Loss: 0.12636373937129974\n",
      "Epoch: 130 Loss: 0.24094939231872559\n",
      "Epoch: 131 Loss: 0.07970310747623444\n",
      "Epoch: 132 Loss: 0.14586764574050903\n",
      "Epoch: 133 Loss: 0.15575449168682098\n",
      "Epoch: 134 Loss: 0.27268242835998535\n",
      "Epoch: 135 Loss: 0.26154980063438416\n",
      "Epoch: 136 Loss: 0.0786379724740982\n",
      "Epoch: 137 Loss: 0.12416678667068481\n",
      "Epoch: 138 Loss: 0.2975838780403137\n",
      "Epoch: 139 Loss: 0.03118942305445671\n",
      "Epoch: 140 Loss: 0.05720698833465576\n",
      "Epoch: 141 Loss: 0.11313006281852722\n",
      "Epoch: 142 Loss: 0.058204229921102524\n",
      "Epoch: 143 Loss: 0.09772486984729767\n",
      "Epoch: 144 Loss: 0.15359614789485931\n",
      "Epoch: 145 Loss: 0.12171953916549683\n",
      "Epoch: 146 Loss: 0.10402734577655792\n",
      "Epoch: 147 Loss: 0.10709411650896072\n",
      "Epoch: 148 Loss: 0.16661879420280457\n",
      "Epoch: 149 Loss: 0.16114899516105652\n",
      "Epoch: 150 Loss: 0.047251276671886444\n",
      "Epoch: 151 Loss: 0.09260519593954086\n",
      "Epoch: 152 Loss: 0.048509374260902405\n",
      "Epoch: 153 Loss: 0.05050740763545036\n",
      "Epoch: 154 Loss: 0.060972925275564194\n",
      "Epoch: 155 Loss: 0.05469953268766403\n",
      "Epoch: 156 Loss: 0.23164571821689606\n",
      "Epoch: 157 Loss: 0.14563696086406708\n",
      "Epoch: 158 Loss: 0.1559469848871231\n",
      "Epoch: 159 Loss: 0.1408163160085678\n",
      "Epoch: 160 Loss: 0.0589849017560482\n",
      "Epoch: 161 Loss: 0.6730748414993286\n",
      "Epoch: 162 Loss: 0.04512111097574234\n",
      "Epoch: 163 Loss: 0.05739738792181015\n",
      "Epoch: 164 Loss: 0.05183599516749382\n",
      "Epoch: 165 Loss: 0.0924018919467926\n",
      "Epoch: 166 Loss: 0.11811095476150513\n",
      "Epoch: 167 Loss: 0.16159860789775848\n",
      "Epoch: 168 Loss: 0.06608149409294128\n",
      "Epoch: 169 Loss: 0.16949684917926788\n",
      "Epoch: 170 Loss: 0.10574471950531006\n",
      "Epoch: 171 Loss: 0.1283470094203949\n",
      "Epoch: 172 Loss: 0.08572465181350708\n",
      "Epoch: 173 Loss: 0.11890723556280136\n",
      "Epoch: 174 Loss: 0.18577368557453156\n",
      "Epoch: 175 Loss: 0.06711189448833466\n",
      "Epoch: 176 Loss: 0.09623023867607117\n",
      "Epoch: 177 Loss: 0.1757422685623169\n",
      "Epoch: 178 Loss: 0.22003842890262604\n",
      "Epoch: 179 Loss: 0.12092147767543793\n",
      "Epoch: 180 Loss: 0.060348693281412125\n",
      "Epoch: 181 Loss: 0.1162770465016365\n",
      "Epoch: 182 Loss: 0.07778409123420715\n",
      "Epoch: 183 Loss: 0.07272833585739136\n",
      "Epoch: 184 Loss: 0.03425559774041176\n",
      "Epoch: 185 Loss: 0.09661471843719482\n",
      "Epoch: 186 Loss: 0.1281743049621582\n",
      "Epoch: 187 Loss: 0.10029717534780502\n",
      "Epoch: 188 Loss: 0.18401718139648438\n",
      "Epoch: 189 Loss: 0.12279722094535828\n",
      "Epoch: 190 Loss: 0.1000794842839241\n",
      "Epoch: 191 Loss: 0.16098923981189728\n",
      "Epoch: 192 Loss: 0.032596856355667114\n",
      "Epoch: 193 Loss: 0.08698199689388275\n",
      "Epoch: 194 Loss: 0.1108308956027031\n",
      "Epoch: 195 Loss: 0.056555140763521194\n",
      "Epoch: 196 Loss: 0.09373609721660614\n",
      "Epoch: 197 Loss: 0.11078935861587524\n",
      "Epoch: 198 Loss: 0.04085827246308327\n",
      "Epoch: 199 Loss: 0.14904551208019257\n",
      "Epoch: 200 Loss: 0.1256573647260666\n",
      "Epoch: 201 Loss: 0.04856986552476883\n",
      "Epoch: 202 Loss: 0.06253062188625336\n",
      "Epoch: 203 Loss: 0.05001867562532425\n",
      "Epoch: 204 Loss: 0.10229817777872086\n",
      "Epoch: 205 Loss: 0.3162345588207245\n",
      "Epoch: 206 Loss: 0.04805801063776016\n",
      "Epoch: 207 Loss: 0.19204813241958618\n",
      "Epoch: 208 Loss: 0.049155861139297485\n",
      "Epoch: 209 Loss: 0.05299573391675949\n",
      "Epoch: 210 Loss: 0.05267079919576645\n",
      "Epoch: 211 Loss: 0.041514843702316284\n",
      "Epoch: 212 Loss: 0.12659429013729095\n",
      "Epoch: 213 Loss: 0.19969865679740906\n",
      "Epoch: 214 Loss: 0.14364555478096008\n",
      "Epoch: 215 Loss: 0.10210980474948883\n",
      "Epoch: 216 Loss: 0.1523033082485199\n",
      "Epoch: 217 Loss: 0.1919059306383133\n",
      "Epoch: 218 Loss: 0.08498241007328033\n",
      "Epoch: 219 Loss: 0.09984421730041504\n",
      "Epoch: 220 Loss: 0.15868611633777618\n",
      "Epoch: 221 Loss: 0.18580226600170135\n",
      "Epoch: 222 Loss: 0.08006638288497925\n",
      "Epoch: 223 Loss: 0.09193004667758942\n",
      "Epoch: 224 Loss: 0.05798228457570076\n",
      "Epoch: 225 Loss: 0.06698140501976013\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 226 Loss: 0.13676238059997559\n",
      "Epoch: 227 Loss: 0.11783357709646225\n",
      "Epoch: 228 Loss: 0.03944813832640648\n",
      "Epoch: 229 Loss: 0.192428857088089\n",
      "Epoch: 230 Loss: 0.1074574887752533\n",
      "Epoch: 231 Loss: 0.05099894478917122\n",
      "Epoch: 232 Loss: 0.09389285743236542\n",
      "Epoch: 233 Loss: 0.6232318878173828\n",
      "Epoch: 234 Loss: 0.09459133446216583\n",
      "Epoch: 235 Loss: 0.14363297820091248\n",
      "Epoch: 236 Loss: 0.17403213679790497\n",
      "Epoch: 237 Loss: 0.05845581740140915\n",
      "Epoch: 238 Loss: 0.11127065122127533\n",
      "Epoch: 239 Loss: 0.1620534360408783\n",
      "Epoch: 240 Loss: 0.21655209362506866\n",
      "Epoch: 241 Loss: 0.1674947887659073\n",
      "Epoch: 242 Loss: 0.153672993183136\n",
      "Epoch: 243 Loss: 0.1897723376750946\n",
      "Epoch: 244 Loss: 0.2039402574300766\n",
      "Epoch: 245 Loss: 0.05051174759864807\n",
      "Epoch: 246 Loss: 0.24966804683208466\n",
      "Epoch: 247 Loss: 0.06366603076457977\n",
      "Epoch: 248 Loss: 0.08280974626541138\n",
      "Epoch: 249 Loss: 0.07633322477340698\n",
      "Epoch: 250 Loss: 0.06088804081082344\n",
      "Epoch: 251 Loss: 0.06532908976078033\n",
      "Epoch: 252 Loss: 0.10466240346431732\n",
      "Epoch: 253 Loss: 0.1394762545824051\n",
      "Epoch: 254 Loss: 0.09974446147680283\n",
      "Epoch: 255 Loss: 0.09495964646339417\n",
      "Epoch: 256 Loss: 0.08318303525447845\n",
      "Epoch: 257 Loss: 0.10538362711668015\n",
      "Epoch: 258 Loss: 0.04205431416630745\n",
      "Epoch: 259 Loss: 0.1242646872997284\n",
      "Epoch: 260 Loss: 0.0822795182466507\n",
      "Epoch: 261 Loss: 0.1427704095840454\n",
      "Epoch: 262 Loss: 0.0996621772646904\n",
      "Epoch: 263 Loss: 0.0822652131319046\n",
      "Epoch: 264 Loss: 0.04638632759451866\n",
      "Epoch: 265 Loss: 0.2803618013858795\n",
      "Epoch: 266 Loss: 0.1676671802997589\n",
      "Epoch: 267 Loss: 0.04892490431666374\n",
      "Epoch: 268 Loss: 0.16705499589443207\n",
      "Epoch: 269 Loss: 0.06166182458400726\n",
      "Epoch: 270 Loss: 0.11971231549978256\n",
      "Epoch: 271 Loss: 0.22743524610996246\n",
      "Epoch: 272 Loss: 0.07437662035226822\n",
      "Epoch: 273 Loss: 0.08270540088415146\n",
      "Epoch: 274 Loss: 0.06675256788730621\n",
      "Epoch: 275 Loss: 0.06487934291362762\n",
      "Epoch: 276 Loss: 0.044210754334926605\n",
      "Epoch: 277 Loss: 0.18460319936275482\n",
      "Epoch: 278 Loss: 0.09311269968748093\n",
      "Epoch: 279 Loss: 0.06681834161281586\n",
      "Epoch: 280 Loss: 0.555980920791626\n",
      "Epoch: 281 Loss: 0.07620236277580261\n",
      "Epoch: 282 Loss: 0.1279626190662384\n",
      "Epoch: 283 Loss: 0.05382636934518814\n",
      "Epoch: 284 Loss: 0.08912642300128937\n",
      "Epoch: 285 Loss: 0.4910720884799957\n",
      "Epoch: 286 Loss: 0.21574266254901886\n",
      "Epoch: 287 Loss: 0.04466646909713745\n",
      "Epoch: 288 Loss: 0.12615996599197388\n",
      "Epoch: 289 Loss: 0.19882449507713318\n",
      "Epoch: 290 Loss: 0.1552860140800476\n",
      "Epoch: 291 Loss: 0.4088892340660095\n",
      "Epoch: 292 Loss: 0.06892161071300507\n",
      "Epoch: 293 Loss: 0.050920359790325165\n",
      "Epoch: 294 Loss: 0.10971575975418091\n",
      "Epoch: 295 Loss: 0.03505615517497063\n",
      "Epoch: 296 Loss: 0.02996218204498291\n",
      "Epoch: 297 Loss: 0.10310550034046173\n",
      "Epoch: 298 Loss: 0.12696951627731323\n",
      "Epoch: 299 Loss: 0.1795419305562973\n",
      "Epoch: 300 Loss: 0.05641299858689308\n",
      "Epoch: 301 Loss: 0.16685998439788818\n",
      "Epoch: 302 Loss: 0.09200657904148102\n",
      "Epoch: 303 Loss: 0.046177878975868225\n",
      "Epoch: 304 Loss: 0.2667698860168457\n",
      "Epoch: 305 Loss: 0.07729519158601761\n",
      "Epoch: 306 Loss: 0.11813309788703918\n",
      "Epoch: 307 Loss: 0.09179740399122238\n",
      "Epoch: 308 Loss: 0.16796982288360596\n",
      "Epoch: 309 Loss: 0.06254179775714874\n",
      "Epoch: 310 Loss: 0.05036121606826782\n",
      "Epoch: 311 Loss: 0.07492120563983917\n",
      "Epoch: 312 Loss: 0.11730634421110153\n",
      "Epoch: 313 Loss: 0.09811022132635117\n",
      "Epoch: 314 Loss: 0.06485288590192795\n",
      "Epoch: 315 Loss: 0.10210536420345306\n",
      "Epoch: 316 Loss: 0.04609619826078415\n",
      "Epoch: 317 Loss: 0.09466394037008286\n",
      "Epoch: 318 Loss: 0.06944561749696732\n",
      "Epoch: 319 Loss: 0.044293370097875595\n",
      "Epoch: 320 Loss: 0.06061449646949768\n",
      "Epoch: 321 Loss: 0.07673667371273041\n",
      "Epoch: 322 Loss: 0.06408432126045227\n",
      "Epoch: 323 Loss: 0.13387982547283173\n",
      "Epoch: 324 Loss: 0.06892582774162292\n",
      "Epoch: 325 Loss: 0.04779239743947983\n",
      "Epoch: 326 Loss: 0.09635354578495026\n",
      "Epoch: 327 Loss: 0.19509276747703552\n",
      "Epoch: 328 Loss: 0.10453693568706512\n",
      "Epoch: 329 Loss: 0.0796961858868599\n",
      "Epoch: 330 Loss: 0.09118682146072388\n",
      "Epoch: 331 Loss: 0.04566284269094467\n",
      "Epoch: 332 Loss: 0.0546921081840992\n",
      "Epoch: 333 Loss: 0.1642780601978302\n",
      "Epoch: 334 Loss: 0.06681652367115021\n",
      "Epoch: 335 Loss: 0.0997924879193306\n",
      "Epoch: 336 Loss: 0.5095087289810181\n",
      "Epoch: 337 Loss: 0.09230031818151474\n",
      "Epoch: 338 Loss: 0.07611654698848724\n",
      "Epoch: 339 Loss: 0.04246926307678223\n",
      "Epoch: 340 Loss: 0.059319768100976944\n",
      "Epoch: 341 Loss: 0.0563022643327713\n",
      "Epoch: 342 Loss: 0.12292366474866867\n",
      "Epoch: 343 Loss: 0.15441855788230896\n",
      "Epoch: 344 Loss: 0.050327423959970474\n",
      "Epoch: 345 Loss: 0.1128307357430458\n",
      "Epoch: 346 Loss: 0.05543367564678192\n",
      "Epoch: 347 Loss: 0.07852678000926971\n",
      "Epoch: 348 Loss: 0.0420125275850296\n",
      "Epoch: 349 Loss: 0.09639208018779755\n",
      "Epoch: 350 Loss: 0.1535530835390091\n",
      "Epoch: 351 Loss: 0.060560502111911774\n",
      "Epoch: 352 Loss: 0.0682026818394661\n",
      "Epoch: 353 Loss: 0.1162770688533783\n",
      "Epoch: 354 Loss: 0.0756302997469902\n",
      "Epoch: 355 Loss: 0.04155649244785309\n",
      "Epoch: 356 Loss: 0.1227434054017067\n",
      "Epoch: 357 Loss: 0.07031680643558502\n",
      "Epoch: 358 Loss: 0.09190639853477478\n",
      "Epoch: 359 Loss: 0.06175171211361885\n",
      "Epoch: 360 Loss: 0.07987309247255325\n",
      "Epoch: 361 Loss: 0.044719841331243515\n",
      "Epoch: 362 Loss: 0.24448230862617493\n",
      "Epoch: 363 Loss: 0.10644086450338364\n",
      "Epoch: 364 Loss: 0.089642733335495\n",
      "Epoch: 365 Loss: 0.08342771232128143\n",
      "Epoch: 366 Loss: 0.16220992803573608\n",
      "Epoch: 367 Loss: 0.07482777535915375\n",
      "Epoch: 368 Loss: 0.05396835505962372\n",
      "Epoch: 369 Loss: 0.23991146683692932\n",
      "Epoch: 370 Loss: 0.14805087447166443\n",
      "Epoch: 371 Loss: 0.13197766244411469\n",
      "Epoch: 372 Loss: 0.1233135536313057\n",
      "Epoch: 373 Loss: 0.0598021037876606\n",
      "Epoch: 374 Loss: 0.05054633691906929\n",
      "Epoch: 375 Loss: 0.24956656992435455\n",
      "Epoch: 376 Loss: 0.16592851281166077\n",
      "Epoch: 377 Loss: 0.04194963723421097\n",
      "Epoch: 378 Loss: 0.0672178566455841\n",
      "Epoch: 379 Loss: 0.057969219982624054\n",
      "Epoch: 380 Loss: 0.06205128878355026\n",
      "Epoch: 381 Loss: 0.10332516580820084\n",
      "Epoch: 382 Loss: 0.20312583446502686\n",
      "Epoch: 383 Loss: 0.26408204436302185\n",
      "Epoch: 384 Loss: 0.058112967759370804\n",
      "Epoch: 385 Loss: 0.12857866287231445\n",
      "Epoch: 386 Loss: 0.0455210879445076\n",
      "Epoch: 387 Loss: 0.1592317819595337\n",
      "Epoch: 388 Loss: 0.08226701617240906\n",
      "Epoch: 389 Loss: 0.060365743935108185\n",
      "Epoch: 390 Loss: 0.044351570308208466\n",
      "Epoch: 391 Loss: 0.050271958112716675\n",
      "Epoch: 392 Loss: 0.1281084418296814\n",
      "Epoch: 393 Loss: 0.13688500225543976\n",
      "Epoch: 394 Loss: 0.3523315489292145\n",
      "Epoch: 395 Loss: 0.0877993181347847\n",
      "Epoch: 396 Loss: 0.07214546948671341\n",
      "Epoch: 397 Loss: 0.10160401463508606\n",
      "Epoch: 398 Loss: 0.03454239293932915\n",
      "Epoch: 399 Loss: 0.05950136110186577\n",
      "Epoch: 400 Loss: 0.06881031394004822\n",
      "Epoch: 401 Loss: 0.0927048847079277\n",
      "Epoch: 402 Loss: 0.14935214817523956\n",
      "Epoch: 403 Loss: 0.08339948207139969\n",
      "Epoch: 404 Loss: 0.05899237096309662\n",
      "Epoch: 405 Loss: 0.14916691184043884\n",
      "Epoch: 406 Loss: 0.034170962870121\n",
      "Epoch: 407 Loss: 0.12680241465568542\n",
      "Epoch: 408 Loss: 0.11251912266016006\n",
      "Epoch: 409 Loss: 0.08934788405895233\n",
      "Epoch: 410 Loss: 0.29966598749160767\n",
      "Epoch: 411 Loss: 0.05937526375055313\n",
      "Epoch: 412 Loss: 0.08208290487527847\n",
      "Epoch: 413 Loss: 0.0891181007027626\n",
      "Epoch: 414 Loss: 0.16334356367588043\n",
      "Epoch: 415 Loss: 0.0431157648563385\n",
      "Epoch: 416 Loss: 0.08721355348825455\n",
      "Epoch: 417 Loss: 0.05611693859100342\n",
      "Epoch: 418 Loss: 0.0730665922164917\n",
      "Epoch: 419 Loss: 0.09254659712314606\n",
      "Epoch: 420 Loss: 0.10875250399112701\n",
      "Epoch: 421 Loss: 0.10250134766101837\n",
      "Epoch: 422 Loss: 0.054094959050416946\n",
      "Epoch: 423 Loss: 0.09873140603303909\n",
      "Epoch: 424 Loss: 0.0575065016746521\n",
      "Epoch: 425 Loss: 0.09557463973760605\n",
      "Epoch: 426 Loss: 0.14164747297763824\n",
      "Epoch: 427 Loss: 0.13119328022003174\n",
      "Epoch: 428 Loss: 0.20229892432689667\n",
      "Epoch: 429 Loss: 0.15458421409130096\n",
      "Epoch: 430 Loss: 0.09982370585203171\n",
      "Epoch: 431 Loss: 0.16799019277095795\n",
      "Epoch: 432 Loss: 0.12587644159793854\n",
      "Epoch: 433 Loss: 0.09474509209394455\n",
      "Epoch: 434 Loss: 0.052995309233665466\n",
      "Epoch: 435 Loss: 0.06920769065618515\n",
      "Epoch: 436 Loss: 0.05780532956123352\n",
      "Epoch: 437 Loss: 0.058323703706264496\n",
      "Epoch: 438 Loss: 0.1260107457637787\n",
      "Epoch: 439 Loss: 0.06833236664533615\n",
      "Epoch: 440 Loss: 0.07857407629489899\n",
      "Epoch: 441 Loss: 0.09211322665214539\n",
      "Epoch: 442 Loss: 0.2599199712276459\n",
      "Epoch: 443 Loss: 0.15498089790344238\n",
      "Epoch: 444 Loss: 0.1278773546218872\n",
      "Epoch: 445 Loss: 0.14838960766792297\n",
      "Epoch: 446 Loss: 0.1541234403848648\n",
      "Epoch: 447 Loss: 0.13735412061214447\n",
      "Epoch: 448 Loss: 0.17827758193016052\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 449 Loss: 0.09687129408121109\n",
      "Epoch: 450 Loss: 0.08442381024360657\n",
      "Epoch: 451 Loss: 0.052772242575883865\n",
      "Epoch: 452 Loss: 0.07156907021999359\n",
      "Epoch: 453 Loss: 0.25847864151000977\n",
      "Epoch: 454 Loss: 0.08471488952636719\n",
      "Epoch: 455 Loss: 0.09775541722774506\n",
      "Epoch: 456 Loss: 0.1307990849018097\n",
      "Epoch: 457 Loss: 0.5176584124565125\n",
      "Epoch: 458 Loss: 0.08972346037626266\n",
      "Epoch: 459 Loss: 0.14992888271808624\n",
      "Epoch: 460 Loss: 0.1760289967060089\n",
      "Epoch: 461 Loss: 0.04706466197967529\n",
      "Epoch: 462 Loss: 0.05434403195977211\n",
      "Epoch: 463 Loss: 0.06625019758939743\n",
      "Epoch: 464 Loss: 0.14593683183193207\n",
      "Epoch: 465 Loss: 0.03526253625750542\n",
      "Epoch: 466 Loss: 0.08757919073104858\n",
      "Epoch: 467 Loss: 0.039514489471912384\n",
      "Epoch: 468 Loss: 0.24583576619625092\n",
      "Epoch: 469 Loss: 0.14789628982543945\n",
      "Epoch: 470 Loss: 0.06588129699230194\n",
      "Epoch: 471 Loss: 0.08690531551837921\n",
      "Epoch: 472 Loss: 0.21251656115055084\n",
      "Epoch: 473 Loss: 0.22445231676101685\n",
      "Epoch: 474 Loss: 0.11273716390132904\n",
      "Epoch: 475 Loss: 0.054199978709220886\n",
      "Epoch: 476 Loss: 0.09253256767988205\n",
      "Epoch: 477 Loss: 0.03491106256842613\n",
      "Epoch: 478 Loss: 0.12353446334600449\n",
      "Epoch: 479 Loss: 0.04055488482117653\n",
      "Epoch: 480 Loss: 0.06049619987607002\n",
      "Epoch: 481 Loss: 0.10638464242219925\n",
      "Epoch: 482 Loss: 0.030071847140789032\n",
      "Epoch: 483 Loss: 0.07046758383512497\n",
      "Epoch: 484 Loss: 0.07426422089338303\n",
      "Epoch: 485 Loss: 0.14894655346870422\n",
      "Epoch: 486 Loss: 0.13759417831897736\n",
      "Epoch: 487 Loss: 0.05355973169207573\n",
      "Epoch: 488 Loss: 0.10672133415937424\n",
      "Epoch: 489 Loss: 0.11581718176603317\n",
      "Epoch: 490 Loss: 0.05707439035177231\n",
      "Epoch: 491 Loss: 0.2011069506406784\n",
      "Epoch: 492 Loss: 0.08839144557714462\n",
      "Epoch: 493 Loss: 0.10529980808496475\n",
      "Epoch: 494 Loss: 0.048967037349939346\n",
      "Epoch: 495 Loss: 0.05647312477231026\n",
      "Epoch: 496 Loss: 0.1378534883260727\n",
      "Epoch: 497 Loss: 0.067542664706707\n",
      "Epoch: 498 Loss: 0.17485611140727997\n",
      "Epoch: 499 Loss: 0.1547335982322693\n",
      "Epoch: 500 Loss: 0.16904577612876892\n",
      "Epoch: 501 Loss: 0.1487504243850708\n",
      "Epoch: 502 Loss: 0.08206114172935486\n",
      "Epoch: 503 Loss: 0.07202646136283875\n",
      "Epoch: 504 Loss: 0.12500840425491333\n",
      "Epoch: 505 Loss: 0.14374670386314392\n",
      "Epoch: 506 Loss: 0.03922548517584801\n",
      "Epoch: 507 Loss: 0.1073981449007988\n",
      "Epoch: 508 Loss: 0.1405344158411026\n",
      "Epoch: 509 Loss: 0.04049191251397133\n",
      "Epoch: 510 Loss: 0.1375562995672226\n",
      "Epoch: 511 Loss: 0.1159593015909195\n",
      "Epoch: 512 Loss: 0.094075508415699\n",
      "Epoch: 513 Loss: 0.0876946672797203\n",
      "Epoch: 514 Loss: 0.19677774608135223\n",
      "Epoch: 515 Loss: 0.22125521302223206\n",
      "Epoch: 516 Loss: 0.2717324495315552\n",
      "Epoch: 517 Loss: 0.10590609908103943\n",
      "Epoch: 518 Loss: 0.0897819846868515\n",
      "Epoch: 519 Loss: 0.05785404145717621\n",
      "Epoch: 520 Loss: 0.0604945570230484\n",
      "Epoch: 521 Loss: 0.05882440507411957\n",
      "Epoch: 522 Loss: 0.0630088597536087\n",
      "Epoch: 523 Loss: 0.14977845549583435\n",
      "Epoch: 524 Loss: 0.042644090950489044\n",
      "Epoch: 525 Loss: 0.08686549961566925\n",
      "Epoch: 526 Loss: 0.1075771376490593\n",
      "Epoch: 527 Loss: 0.15672074258327484\n",
      "Epoch: 528 Loss: 0.19834919273853302\n",
      "Epoch: 529 Loss: 0.15840740501880646\n",
      "Epoch: 530 Loss: 0.08471424877643585\n",
      "Epoch: 531 Loss: 0.07347163558006287\n",
      "Epoch: 532 Loss: 0.09001567959785461\n",
      "Epoch: 533 Loss: 0.0931737869977951\n",
      "Epoch: 534 Loss: 0.10186724364757538\n",
      "Epoch: 535 Loss: 0.07639090716838837\n",
      "Epoch: 536 Loss: 0.06293538957834244\n",
      "Epoch: 537 Loss: 0.21710769832134247\n",
      "Epoch: 538 Loss: 0.11097203195095062\n",
      "Epoch: 539 Loss: 0.35216304659843445\n",
      "Epoch: 540 Loss: 0.1801459640264511\n",
      "Epoch: 541 Loss: 0.16264945268630981\n",
      "Epoch: 542 Loss: 0.03594077378511429\n",
      "Epoch: 543 Loss: 0.12054633349180222\n",
      "Epoch: 544 Loss: 0.10158472508192062\n",
      "Epoch: 545 Loss: 0.03570476919412613\n",
      "Epoch: 546 Loss: 0.13569197058677673\n",
      "Epoch: 547 Loss: 0.1210540235042572\n",
      "Epoch: 548 Loss: 0.10818696767091751\n",
      "Epoch: 549 Loss: 0.09598703682422638\n",
      "Epoch: 550 Loss: 0.1273285448551178\n",
      "Epoch: 551 Loss: 0.0659198984503746\n",
      "Epoch: 552 Loss: 0.07861173897981644\n",
      "Epoch: 553 Loss: 0.2432110756635666\n",
      "Epoch: 554 Loss: 0.043908149003982544\n",
      "Epoch: 555 Loss: 0.12889304757118225\n",
      "Epoch: 556 Loss: 0.08368749916553497\n",
      "Epoch: 557 Loss: 0.08807554095983505\n",
      "Epoch: 558 Loss: 0.07827335596084595\n",
      "Epoch: 559 Loss: 0.1415652334690094\n",
      "Epoch: 560 Loss: 0.12407365441322327\n",
      "Epoch: 561 Loss: 0.09224920719861984\n",
      "Epoch: 562 Loss: 0.09777748584747314\n",
      "Epoch: 563 Loss: 0.20690211653709412\n",
      "Epoch: 564 Loss: 0.1357801854610443\n",
      "Epoch: 565 Loss: 0.10436460375785828\n",
      "Epoch: 566 Loss: 0.07802402973175049\n",
      "Epoch: 567 Loss: 0.09929089993238449\n",
      "Epoch: 568 Loss: 0.08827970176935196\n",
      "Epoch: 569 Loss: 0.600729763507843\n",
      "Epoch: 570 Loss: 0.0406951904296875\n",
      "Epoch: 571 Loss: 0.06945336610078812\n",
      "Epoch: 572 Loss: 0.06465920805931091\n",
      "Epoch: 573 Loss: 0.08633238077163696\n",
      "Epoch: 574 Loss: 0.05349034070968628\n",
      "Epoch: 575 Loss: 0.07073184102773666\n",
      "Epoch: 576 Loss: 0.1242559403181076\n",
      "Epoch: 577 Loss: 0.04956812411546707\n",
      "Epoch: 578 Loss: 0.14216114580631256\n",
      "Epoch: 579 Loss: 0.06823868304491043\n",
      "Epoch: 580 Loss: 0.049067385494709015\n",
      "Epoch: 581 Loss: 0.08526623994112015\n",
      "Epoch: 582 Loss: 0.039179738610982895\n",
      "Epoch: 583 Loss: 0.08545389771461487\n",
      "Epoch: 584 Loss: 0.15609383583068848\n",
      "Epoch: 585 Loss: 0.04621283710002899\n",
      "Epoch: 586 Loss: 0.06991168856620789\n",
      "Epoch: 587 Loss: 0.15714146196842194\n",
      "Epoch: 588 Loss: 0.1255975067615509\n",
      "Epoch: 589 Loss: 0.057976726442575455\n",
      "Epoch: 590 Loss: 0.08522941917181015\n",
      "Epoch: 591 Loss: 0.03518737852573395\n",
      "Epoch: 592 Loss: 0.06581997871398926\n",
      "Epoch: 593 Loss: 0.08125490695238113\n",
      "Epoch: 594 Loss: 0.04609247297048569\n",
      "Epoch: 595 Loss: 0.06723880022764206\n",
      "Epoch: 596 Loss: 0.16231417655944824\n",
      "Epoch: 597 Loss: 0.03790653124451637\n",
      "Epoch: 598 Loss: 0.13160909712314606\n",
      "Epoch: 599 Loss: 0.0908539742231369\n",
      "Epoch: 600 Loss: 0.05593281239271164\n",
      "Epoch: 601 Loss: 0.04128148779273033\n",
      "Epoch: 602 Loss: 0.07599084824323654\n",
      "Epoch: 603 Loss: 0.06645414978265762\n",
      "Epoch: 604 Loss: 0.047386884689331055\n",
      "Epoch: 605 Loss: 0.11643792688846588\n",
      "Epoch: 606 Loss: 0.04943482577800751\n",
      "Epoch: 607 Loss: 0.17327195405960083\n",
      "Epoch: 608 Loss: 0.1268172264099121\n",
      "Epoch: 609 Loss: 0.1148461252450943\n",
      "Epoch: 610 Loss: 0.04526197165250778\n",
      "Epoch: 611 Loss: 0.2236393690109253\n",
      "Epoch: 612 Loss: 0.12797734141349792\n",
      "Epoch: 613 Loss: 0.1083497703075409\n",
      "Epoch: 614 Loss: 0.029902450740337372\n",
      "Epoch: 615 Loss: 0.11200238019227982\n",
      "Epoch: 616 Loss: 0.15480342507362366\n",
      "Epoch: 617 Loss: 0.056192126125097275\n",
      "Epoch: 618 Loss: 0.07988766580820084\n",
      "Epoch: 619 Loss: 0.1074313074350357\n",
      "Epoch: 620 Loss: 0.1690690964460373\n",
      "Epoch: 621 Loss: 0.04557371139526367\n",
      "Epoch: 622 Loss: 0.06658019125461578\n",
      "Epoch: 623 Loss: 0.17106904089450836\n",
      "Epoch: 624 Loss: 0.057021789252758026\n",
      "Epoch: 625 Loss: 0.06451652944087982\n",
      "Epoch: 626 Loss: 0.10343535989522934\n",
      "Epoch: 627 Loss: 0.10495263338088989\n",
      "Epoch: 628 Loss: 0.07749591767787933\n",
      "Epoch: 629 Loss: 0.10195936262607574\n",
      "Epoch: 630 Loss: 0.03798110410571098\n",
      "Epoch: 631 Loss: 0.04745887219905853\n",
      "Epoch: 632 Loss: 0.1120065450668335\n",
      "Epoch: 633 Loss: 0.10189131647348404\n",
      "Epoch: 634 Loss: 0.17478540539741516\n",
      "Epoch: 635 Loss: 0.046819210052490234\n",
      "Epoch: 636 Loss: 0.07935784012079239\n",
      "Epoch: 637 Loss: 0.03040655516088009\n",
      "Epoch: 638 Loss: 0.06171887367963791\n",
      "Epoch: 639 Loss: 0.11363915354013443\n",
      "Epoch: 640 Loss: 0.059113990515470505\n",
      "Epoch: 641 Loss: 0.1580245941877365\n",
      "Epoch: 642 Loss: 0.1139989048242569\n",
      "Epoch: 643 Loss: 0.04484689235687256\n",
      "Epoch: 644 Loss: 0.10245129466056824\n",
      "Epoch: 645 Loss: 0.1503446400165558\n",
      "Epoch: 646 Loss: 0.05789387971162796\n",
      "Epoch: 647 Loss: 0.12671492993831635\n",
      "Epoch: 648 Loss: 0.04911627247929573\n",
      "Epoch: 649 Loss: 0.058629363775253296\n",
      "Epoch: 650 Loss: 0.06632433831691742\n",
      "Epoch: 651 Loss: 0.13855662941932678\n",
      "Epoch: 652 Loss: 0.13258308172225952\n",
      "Epoch: 653 Loss: 0.09995918720960617\n",
      "Epoch: 654 Loss: 0.09194010496139526\n",
      "Epoch: 655 Loss: 0.08157842606306076\n",
      "Epoch: 656 Loss: 0.04847913607954979\n",
      "Epoch: 657 Loss: 0.0808941125869751\n",
      "Epoch: 658 Loss: 0.06727336347103119\n",
      "Epoch: 659 Loss: 0.44495445489883423\n",
      "Epoch: 660 Loss: 0.14639754593372345\n",
      "Epoch: 661 Loss: 0.13796444237232208\n",
      "Epoch: 662 Loss: 0.04157765209674835\n",
      "Epoch: 663 Loss: 0.12511879205703735\n",
      "Epoch: 664 Loss: 0.06469080597162247\n",
      "Epoch: 665 Loss: 0.08018244057893753\n",
      "Epoch: 666 Loss: 0.04982765391469002\n",
      "Epoch: 667 Loss: 0.03648125380277634\n",
      "Epoch: 668 Loss: 0.08384604752063751\n",
      "Epoch: 669 Loss: 0.06470253318548203\n",
      "Epoch: 670 Loss: 0.1133502721786499\n",
      "Epoch: 671 Loss: 0.05763772502541542\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 672 Loss: 0.14631350338459015\n",
      "Epoch: 673 Loss: 0.05589237064123154\n",
      "Epoch: 674 Loss: 0.41983678936958313\n",
      "Epoch: 675 Loss: 0.04169130697846413\n",
      "Epoch: 676 Loss: 0.1139734759926796\n",
      "Epoch: 677 Loss: 0.030671358108520508\n",
      "Epoch: 678 Loss: 0.05530236288905144\n",
      "Epoch: 679 Loss: 0.20636746287345886\n",
      "Epoch: 680 Loss: 0.09931101649999619\n",
      "Epoch: 681 Loss: 0.0667450949549675\n",
      "Epoch: 682 Loss: 0.036268141120672226\n",
      "Epoch: 683 Loss: 0.05553843080997467\n",
      "Epoch: 684 Loss: 0.05662648007273674\n",
      "Epoch: 685 Loss: 0.08802854269742966\n",
      "Epoch: 686 Loss: 0.043859273195266724\n",
      "Epoch: 687 Loss: 0.0686684176325798\n",
      "Epoch: 688 Loss: 0.06345637142658234\n",
      "Epoch: 689 Loss: 0.04076417163014412\n",
      "Epoch: 690 Loss: 0.07057951390743256\n",
      "Epoch: 691 Loss: 0.09462833404541016\n",
      "Epoch: 692 Loss: 0.05591919273138046\n",
      "Epoch: 693 Loss: 0.1807451844215393\n",
      "Epoch: 694 Loss: 0.0746125802397728\n",
      "Epoch: 695 Loss: 0.11390163749456406\n",
      "Epoch: 696 Loss: 0.06760790944099426\n",
      "Epoch: 697 Loss: 0.1508379876613617\n",
      "Epoch: 698 Loss: 0.07966789603233337\n",
      "Epoch: 699 Loss: 0.059294700622558594\n",
      "Epoch: 700 Loss: 0.038073062896728516\n",
      "Epoch: 701 Loss: 0.1325337141752243\n",
      "Epoch: 702 Loss: 0.12776288390159607\n",
      "Epoch: 703 Loss: 0.059225499629974365\n",
      "Epoch: 704 Loss: 0.06642935425043106\n",
      "Epoch: 705 Loss: 0.05843866989016533\n",
      "Epoch: 706 Loss: 0.051011353731155396\n",
      "Epoch: 707 Loss: 0.15598103404045105\n",
      "Epoch: 708 Loss: 0.02589503675699234\n",
      "Epoch: 709 Loss: 0.0778275579214096\n",
      "Epoch: 710 Loss: 0.05321018770337105\n",
      "Epoch: 711 Loss: 0.05115523934364319\n",
      "Epoch: 712 Loss: 0.1194949522614479\n",
      "Epoch: 713 Loss: 0.06708960980176926\n",
      "Epoch: 714 Loss: 0.0545487217605114\n",
      "Epoch: 715 Loss: 0.04909661039710045\n",
      "Epoch: 716 Loss: 0.08079767227172852\n",
      "Epoch: 717 Loss: 0.09115754812955856\n",
      "Epoch: 718 Loss: 0.07597596943378448\n",
      "Epoch: 719 Loss: 0.04794183373451233\n",
      "Epoch: 720 Loss: 0.14995884895324707\n",
      "Epoch: 721 Loss: 0.11260785907506943\n",
      "Epoch: 722 Loss: 0.05286477506160736\n",
      "Epoch: 723 Loss: 0.0927857980132103\n",
      "Epoch: 724 Loss: 0.034829962998628616\n",
      "Epoch: 725 Loss: 0.04975363612174988\n",
      "Epoch: 726 Loss: 0.041252825409173965\n",
      "Epoch: 727 Loss: 0.05967913195490837\n",
      "Epoch: 728 Loss: 0.04514196515083313\n",
      "Epoch: 729 Loss: 0.04012933373451233\n",
      "Epoch: 730 Loss: 0.07915815711021423\n",
      "Epoch: 731 Loss: 0.08888460695743561\n",
      "Epoch: 732 Loss: 0.09105668216943741\n",
      "Epoch: 733 Loss: 0.07554437965154648\n",
      "Epoch: 734 Loss: 0.1484726071357727\n",
      "Epoch: 735 Loss: 0.0709332749247551\n",
      "Epoch: 736 Loss: 0.06336796283721924\n",
      "Epoch: 737 Loss: 0.20322830975055695\n",
      "Epoch: 738 Loss: 0.03301326185464859\n",
      "Epoch: 739 Loss: 0.07526188343763351\n",
      "Epoch: 740 Loss: 0.056741923093795776\n",
      "Epoch: 741 Loss: 0.054032016545534134\n",
      "Epoch: 742 Loss: 0.04823485016822815\n",
      "Epoch: 743 Loss: 0.05043869838118553\n",
      "Epoch: 744 Loss: 0.07823310792446136\n",
      "Epoch: 745 Loss: 0.4976296126842499\n",
      "Epoch: 746 Loss: 0.11796879768371582\n",
      "Epoch: 747 Loss: 0.062425561249256134\n",
      "Epoch: 748 Loss: 0.08798246085643768\n",
      "Epoch: 749 Loss: 0.09310644119977951\n",
      "Epoch: 750 Loss: 0.06793074309825897\n",
      "Epoch: 751 Loss: 0.04943639412522316\n",
      "Epoch: 752 Loss: 0.06821177899837494\n",
      "Epoch: 753 Loss: 0.06682334095239639\n",
      "Epoch: 754 Loss: 0.06531931459903717\n",
      "Epoch: 755 Loss: 0.04222968965768814\n",
      "Epoch: 756 Loss: 0.13839754462242126\n",
      "Epoch: 757 Loss: 0.04522473365068436\n",
      "Epoch: 758 Loss: 0.10212826728820801\n",
      "Epoch: 759 Loss: 0.12425586581230164\n",
      "Epoch: 760 Loss: 0.054171979427337646\n",
      "Epoch: 761 Loss: 0.1456349492073059\n",
      "Epoch: 762 Loss: 0.07217475026845932\n",
      "Epoch: 763 Loss: 0.04134536534547806\n",
      "Epoch: 764 Loss: 0.0653044730424881\n",
      "Epoch: 765 Loss: 0.11926990747451782\n",
      "Epoch: 766 Loss: 0.1254734843969345\n",
      "Epoch: 767 Loss: 0.04656161740422249\n",
      "Epoch: 768 Loss: 0.10692499577999115\n",
      "Epoch: 769 Loss: 0.04309952259063721\n",
      "Epoch: 770 Loss: 0.03865939751267433\n",
      "Epoch: 771 Loss: 0.10213105380535126\n",
      "Epoch: 772 Loss: 0.1059686467051506\n",
      "Epoch: 773 Loss: 0.03897976502776146\n",
      "Epoch: 774 Loss: 0.06871683150529861\n",
      "Epoch: 775 Loss: 0.03225869685411453\n",
      "Epoch: 776 Loss: 0.07430893182754517\n",
      "Epoch: 777 Loss: 0.04743046686053276\n",
      "Epoch: 778 Loss: 0.08399692177772522\n",
      "Epoch: 779 Loss: 0.12969675660133362\n",
      "Epoch: 780 Loss: 0.0634521096944809\n",
      "Epoch: 781 Loss: 0.047283075749874115\n",
      "Epoch: 782 Loss: 0.05404733121395111\n",
      "Epoch: 783 Loss: 0.060204654932022095\n",
      "Epoch: 784 Loss: 0.041677817702293396\n",
      "Epoch: 785 Loss: 0.0704449713230133\n",
      "Epoch: 786 Loss: 0.05238821357488632\n",
      "Epoch: 787 Loss: 0.07628355175256729\n",
      "Epoch: 788 Loss: 0.07597708702087402\n",
      "Epoch: 789 Loss: 0.038594432175159454\n",
      "Epoch: 790 Loss: 0.051343224942684174\n",
      "Epoch: 791 Loss: 0.1332462877035141\n",
      "Epoch: 792 Loss: 0.04912027716636658\n",
      "Epoch: 793 Loss: 0.03947412967681885\n",
      "Epoch: 794 Loss: 0.08805782347917557\n",
      "Epoch: 795 Loss: 0.05026374012231827\n",
      "Epoch: 796 Loss: 0.06921200454235077\n",
      "Epoch: 797 Loss: 0.05367117002606392\n",
      "Epoch: 798 Loss: 0.16413894295692444\n",
      "Epoch: 799 Loss: 0.09350098669528961\n",
      "Epoch: 800 Loss: 0.13246068358421326\n",
      "Epoch: 801 Loss: 0.06864237785339355\n",
      "Epoch: 802 Loss: 0.1452624350786209\n",
      "Epoch: 803 Loss: 0.062181711196899414\n",
      "Epoch: 804 Loss: 0.0449792817234993\n",
      "Epoch: 805 Loss: 0.03154883161187172\n",
      "Epoch: 806 Loss: 0.041649382561445236\n",
      "Epoch: 807 Loss: 0.05843157321214676\n",
      "Epoch: 808 Loss: 0.09700681269168854\n",
      "Epoch: 809 Loss: 0.09650972485542297\n",
      "Epoch: 810 Loss: 0.12545420229434967\n",
      "Epoch: 811 Loss: 0.2678244709968567\n",
      "Epoch: 812 Loss: 0.1418408453464508\n",
      "Epoch: 813 Loss: 0.06167331337928772\n",
      "Epoch: 814 Loss: 0.051522091031074524\n",
      "Epoch: 815 Loss: 0.06715907901525497\n",
      "Epoch: 816 Loss: 0.0915105938911438\n",
      "Epoch: 817 Loss: 0.04581092298030853\n",
      "Epoch: 818 Loss: 0.03245103359222412\n",
      "Epoch: 819 Loss: 0.11741750687360764\n",
      "Epoch: 820 Loss: 0.05542496591806412\n",
      "Epoch: 821 Loss: 0.05893317610025406\n",
      "Epoch: 822 Loss: 0.09895443171262741\n",
      "Epoch: 823 Loss: 0.04025743901729584\n",
      "Epoch: 824 Loss: 0.03605804592370987\n",
      "Epoch: 825 Loss: 0.05381716787815094\n",
      "Epoch: 826 Loss: 0.046526212245225906\n",
      "Epoch: 827 Loss: 0.055763423442840576\n",
      "Epoch: 828 Loss: 0.09145549684762955\n",
      "Epoch: 829 Loss: 0.05135031417012215\n",
      "Epoch: 830 Loss: 0.0664082020521164\n",
      "Epoch: 831 Loss: 0.0499541312456131\n",
      "Epoch: 832 Loss: 0.04125579819083214\n",
      "Epoch: 833 Loss: 0.04108057916164398\n",
      "Epoch: 834 Loss: 0.027494624257087708\n",
      "Epoch: 835 Loss: 0.04339360073208809\n",
      "Epoch: 836 Loss: 0.1485547125339508\n",
      "Epoch: 837 Loss: 0.11054061353206635\n",
      "Epoch: 838 Loss: 0.13386119902133942\n",
      "Epoch: 839 Loss: 0.06674955785274506\n",
      "Epoch: 840 Loss: 0.0725092962384224\n",
      "Epoch: 841 Loss: 0.038506098091602325\n",
      "Epoch: 842 Loss: 0.0622713565826416\n",
      "Epoch: 843 Loss: 0.1512949913740158\n",
      "Epoch: 844 Loss: 0.09620758891105652\n",
      "Epoch: 845 Loss: 0.04061330109834671\n",
      "Epoch: 846 Loss: 0.1527838408946991\n",
      "Epoch: 847 Loss: 0.1085297018289566\n",
      "Epoch: 848 Loss: 0.06156734749674797\n",
      "Epoch: 849 Loss: 0.08512069284915924\n",
      "Epoch: 850 Loss: 0.06281928718090057\n",
      "Epoch: 851 Loss: 0.10412946343421936\n",
      "Epoch: 852 Loss: 0.05286773666739464\n",
      "Epoch: 853 Loss: 0.03220964968204498\n",
      "Epoch: 854 Loss: 0.06326073408126831\n",
      "Epoch: 855 Loss: 0.04997236654162407\n",
      "Epoch: 856 Loss: 0.04764788597822189\n",
      "Epoch: 857 Loss: 0.06483408808708191\n",
      "Epoch: 858 Loss: 0.12097395956516266\n",
      "Epoch: 859 Loss: 0.06583128869533539\n",
      "Epoch: 860 Loss: 0.10322031378746033\n",
      "Epoch: 861 Loss: 0.07305908203125\n",
      "Epoch: 862 Loss: 0.058516860008239746\n",
      "Epoch: 863 Loss: 0.11766008287668228\n",
      "Epoch: 864 Loss: 0.10120198875665665\n",
      "Epoch: 865 Loss: 0.033458463847637177\n",
      "Epoch: 866 Loss: 0.08067996799945831\n",
      "Epoch: 867 Loss: 0.08362293988466263\n",
      "Epoch: 868 Loss: 0.043058641254901886\n",
      "Epoch: 869 Loss: 0.06885308772325516\n",
      "Epoch: 870 Loss: 0.11786840856075287\n",
      "Epoch: 871 Loss: 0.07079987227916718\n",
      "Epoch: 872 Loss: 0.10769601911306381\n",
      "Epoch: 873 Loss: 0.0725482776761055\n",
      "Epoch: 874 Loss: 0.041637811809778214\n",
      "Epoch: 875 Loss: 0.07374988496303558\n",
      "Epoch: 876 Loss: 0.06977903842926025\n",
      "Epoch: 877 Loss: 0.04332888498902321\n",
      "Epoch: 878 Loss: 0.03640003502368927\n",
      "Epoch: 879 Loss: 0.03706859424710274\n",
      "Epoch: 880 Loss: 0.03981635347008705\n",
      "Epoch: 881 Loss: 0.13651223480701447\n",
      "Epoch: 882 Loss: 0.0701543316245079\n",
      "Epoch: 883 Loss: 0.18231593072414398\n",
      "Epoch: 884 Loss: 0.028698835521936417\n",
      "Epoch: 885 Loss: 0.050951436161994934\n",
      "Epoch: 886 Loss: 0.07954924553632736\n",
      "Epoch: 887 Loss: 0.0854259803891182\n",
      "Epoch: 888 Loss: 0.06293556839227676\n",
      "Epoch: 889 Loss: 0.05619222670793533\n",
      "Epoch: 890 Loss: 0.07392647117376328\n",
      "Epoch: 891 Loss: 0.03091481328010559\n",
      "Epoch: 892 Loss: 0.03692389652132988\n",
      "Epoch: 893 Loss: 0.07434168457984924\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 894 Loss: 0.09704270213842392\n",
      "Epoch: 895 Loss: 0.022287879139184952\n",
      "Epoch: 896 Loss: 0.0997827872633934\n",
      "Epoch: 897 Loss: 0.042692363262176514\n",
      "Epoch: 898 Loss: 0.06728507578372955\n",
      "Epoch: 899 Loss: 0.095695361495018\n",
      "Epoch: 900 Loss: 0.121686652302742\n",
      "Epoch: 901 Loss: 0.13695138692855835\n",
      "Epoch: 902 Loss: 0.051498446613550186\n",
      "Epoch: 903 Loss: 0.07205960154533386\n",
      "Epoch: 904 Loss: 0.04063580557703972\n",
      "Epoch: 905 Loss: 0.11610321700572968\n",
      "Epoch: 906 Loss: 0.04035894200205803\n",
      "Epoch: 907 Loss: 0.050799254328012466\n",
      "Epoch: 908 Loss: 0.04907505214214325\n",
      "Epoch: 909 Loss: 0.035697318613529205\n",
      "Epoch: 910 Loss: 0.1478690654039383\n",
      "Epoch: 911 Loss: 0.1593240350484848\n",
      "Epoch: 912 Loss: 0.0445941686630249\n",
      "Epoch: 913 Loss: 0.042632702738046646\n",
      "Epoch: 914 Loss: 0.06231978163123131\n",
      "Epoch: 915 Loss: 0.21416528522968292\n",
      "Epoch: 916 Loss: 0.10622606426477432\n",
      "Epoch: 917 Loss: 0.06914573907852173\n",
      "Epoch: 918 Loss: 0.07610809803009033\n",
      "Epoch: 919 Loss: 0.05252814292907715\n",
      "Epoch: 920 Loss: 0.04543030634522438\n",
      "Epoch: 921 Loss: 0.03342555835843086\n",
      "Epoch: 922 Loss: 0.02431504614651203\n",
      "Epoch: 923 Loss: 0.13370844721794128\n",
      "Epoch: 924 Loss: 0.0847809836268425\n",
      "Epoch: 925 Loss: 0.03986793011426926\n",
      "Epoch: 926 Loss: 0.05558764562010765\n",
      "Epoch: 927 Loss: 0.17597301304340363\n",
      "Epoch: 928 Loss: 0.03509677201509476\n",
      "Epoch: 929 Loss: 0.06689224392175674\n",
      "Epoch: 930 Loss: 0.05312217399477959\n",
      "Epoch: 931 Loss: 0.03945081681013107\n",
      "Epoch: 932 Loss: 0.050617702305316925\n",
      "Epoch: 933 Loss: 0.049086619168519974\n",
      "Epoch: 934 Loss: 0.035861384123563766\n",
      "Epoch: 935 Loss: 0.03159454092383385\n",
      "Epoch: 936 Loss: 0.06573109328746796\n",
      "Epoch: 937 Loss: 0.07113964855670929\n",
      "Epoch: 938 Loss: 0.06866416335105896\n",
      "Epoch: 939 Loss: 0.08449821919202805\n",
      "Epoch: 940 Loss: 0.05345489829778671\n",
      "Epoch: 941 Loss: 0.0875714048743248\n",
      "Epoch: 942 Loss: 0.07573098689317703\n",
      "Epoch: 943 Loss: 0.08980564773082733\n",
      "Epoch: 944 Loss: 0.03269825130701065\n",
      "Epoch: 945 Loss: 0.06221172958612442\n",
      "Epoch: 946 Loss: 0.07646197825670242\n",
      "Epoch: 947 Loss: 0.11330298334360123\n",
      "Epoch: 948 Loss: 0.07907111197710037\n",
      "Epoch: 949 Loss: 0.1305260956287384\n",
      "Epoch: 950 Loss: 0.02964891493320465\n",
      "Epoch: 951 Loss: 0.04353258013725281\n",
      "Epoch: 952 Loss: 0.04092731326818466\n",
      "Epoch: 953 Loss: 0.06756728887557983\n",
      "Epoch: 954 Loss: 0.05375439673662186\n",
      "Epoch: 955 Loss: 0.09903072565793991\n",
      "Epoch: 956 Loss: 0.055755410343408585\n",
      "Epoch: 957 Loss: 0.10419052839279175\n",
      "Epoch: 958 Loss: 0.07724125683307648\n",
      "Epoch: 959 Loss: 0.03884018212556839\n",
      "Epoch: 960 Loss: 0.0608610138297081\n",
      "Epoch: 961 Loss: 0.08272626250982285\n",
      "Epoch: 962 Loss: 0.03745150566101074\n",
      "Epoch: 963 Loss: 0.03527507185935974\n",
      "Epoch: 964 Loss: 0.062442515045404434\n",
      "Epoch: 965 Loss: 0.07408136874437332\n",
      "Epoch: 966 Loss: 0.027216719463467598\n",
      "Epoch: 967 Loss: 0.1650913804769516\n",
      "Epoch: 968 Loss: 0.04155539348721504\n",
      "Epoch: 969 Loss: 0.09288948774337769\n",
      "Epoch: 970 Loss: 0.08435562998056412\n",
      "Epoch: 971 Loss: 0.06348466128110886\n",
      "Epoch: 972 Loss: 0.05118155851960182\n",
      "Epoch: 973 Loss: 0.06662040948867798\n",
      "Epoch: 974 Loss: 0.028617706149816513\n",
      "Epoch: 975 Loss: 0.06373413652181625\n",
      "Epoch: 976 Loss: 0.09662830084562302\n",
      "Epoch: 977 Loss: 0.04839325696229935\n",
      "Epoch: 978 Loss: 0.05629757046699524\n",
      "Epoch: 979 Loss: 0.07647300511598587\n",
      "Epoch: 980 Loss: 0.08911904692649841\n",
      "Epoch: 981 Loss: 0.06869950890541077\n",
      "Epoch: 982 Loss: 0.060219839215278625\n",
      "Epoch: 983 Loss: 0.03593313694000244\n",
      "Epoch: 984 Loss: 0.146468847990036\n",
      "Epoch: 985 Loss: 0.07351621985435486\n",
      "Epoch: 986 Loss: 0.04270724207162857\n",
      "Epoch: 987 Loss: 0.0845620185136795\n",
      "Epoch: 988 Loss: 0.06244506314396858\n",
      "Epoch: 989 Loss: 0.06837883591651917\n",
      "Epoch: 990 Loss: 0.16743507981300354\n",
      "Epoch: 991 Loss: 0.055558495223522186\n",
      "Epoch: 992 Loss: 0.09130145609378815\n",
      "Epoch: 993 Loss: 0.03685900941491127\n",
      "Epoch: 994 Loss: 0.03557103872299194\n",
      "Epoch: 995 Loss: 0.10672715306282043\n",
      "Epoch: 996 Loss: 0.0382208526134491\n",
      "Epoch: 997 Loss: 0.08095625042915344\n",
      "Epoch: 998 Loss: 0.0706862285733223\n",
      "Epoch: 999 Loss: 0.04241184890270233\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(1000):\n",
    "    losses = []\n",
    "    for batch_idx, (data1, data2, targets) in enumerate(train_loader):\n",
    "        data1 = data1.to(device=device)\n",
    "        data2 = data2.to(device=device)\n",
    "        targets = targets.to(device=device)\n",
    "        output, present_key_value_states, all_hidden_states, all_attentions, all_cross_attentions, all_router_probs = model(input_ids=data1, decoder_input_ids=data2, output_router_logits=True)\n",
    "        loss = 10*criterion(output, targets)\n",
    "        losses.append(loss.item())\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1)\n",
    "        optimizer.step()\n",
    "        \n",
    "    mean_loss = sum(losses) / len(losses)\n",
    "    scheduler.step(mean_loss)\n",
    "    print('Epoch:', epoch, 'Loss:', loss.item())\n",
    "    \n",
    "    if mean_loss<min_val_acc:\n",
    "        min_val_acc =mean_loss\n",
    "        torch.save(model.state_dict(), 'best_cos_3-3.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data1 = torch.from_numpy(trainX1_copy).float()\n",
    "test_data2 = torch.from_numpy(trainX2_copy).float()\n",
    "test_label = torch.from_numpy(trainY_copy).float()\n",
    "test_dataset = TensorDataset(test_data1, test_data2, test_label)\n",
    "test_loader = DataLoader(test_dataset, batch_size=128, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions=[]\n",
    "for batch_idx, (data1, data2, targets) in enumerate(test_loader):\n",
    "    data1 = data1.to(device=device)\n",
    "    data2 = data2.to(device=device)\n",
    "    output, present_key_value_states, all_hidden_states, all_attentions, all_cross_attentions, all_router_probs=model(input_ids=data1, decoder_input_ids=data2, output_router_logits=True)\n",
    "    targets = targets.to(device=device)\n",
    "    predictions+=output.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = np.array(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_copies1 = np.repeat(predictions[:,0].reshape(-1,1), df_for_training.shape[1], axis=-1) \n",
    "predict_1 = scaler.inverse_transform(predict_copies1)[:,21]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainY_copies1 = np.repeat(trainY_copy[:,0].reshape(-1,1), df_for_training.shape[1], axis=-1)\n",
    "trainY_1 = scaler.inverse_transform(trainY_copies1)[:,21]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(20,10))\n",
    "plt.rcParams['font.sans-serif']=['SimHei']\n",
    "plt.rcParams['axes.unicode_minus']=False\n",
    "plt.xlabel(' /',fontdict={ 'size'   : 30})\n",
    "plt.ylabel(' /N',fontdict={ 'size'   : 30})\n",
    "plt.plot(trainY_1[200:11000],marker='.',label='true')\n",
    "plt.plot(predict_1[200:11000],'r',marker='.',label='predicted')                  #sample\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
